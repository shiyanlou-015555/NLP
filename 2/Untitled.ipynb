{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here are many cities of china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordination_source = \"\"\"\n",
    "{name:'兰州', geoCoord:[103.73, 36.03]},\n",
    "{name:'嘉峪关', geoCoord:[98.17, 39.47]},\n",
    "{name:'西宁', geoCoord:[101.74, 36.56]},\n",
    "{name:'成都', geoCoord:[104.06, 30.67]},\n",
    "{name:'石家庄', geoCoord:[114.48, 38.03]},\n",
    "{name:'拉萨', geoCoord:[102.73, 25.04]},\n",
    "{name:'贵阳', geoCoord:[106.71, 26.57]},\n",
    "{name:'武汉', geoCoord:[114.31, 30.52]},\n",
    "{name:'郑州', geoCoord:[113.65, 34.76]},\n",
    "{name:'济南', geoCoord:[117, 36.65]},\n",
    "{name:'南京', geoCoord:[118.78, 32.04]},\n",
    "{name:'合肥', geoCoord:[117.27, 31.86]},\n",
    "{name:'杭州', geoCoord:[120.19, 30.26]},\n",
    "{name:'南昌', geoCoord:[115.89, 28.68]},\n",
    "{name:'福州', geoCoord:[119.3, 26.08]},\n",
    "{name:'广州', geoCoord:[113.23, 23.16]},\n",
    "{name:'长沙', geoCoord:[113, 28.21]},\n",
    "//{name:'海口', geoCoord:[110.35, 20.02]},\n",
    "{name:'沈阳', geoCoord:[123.38, 41.8]},\n",
    "{name:'长春', geoCoord:[125.35, 43.88]},\n",
    "{name:'哈尔滨', geoCoord:[126.63, 45.75]},\n",
    "{name:'太原', geoCoord:[112.53, 37.87]},\n",
    "{name:'西安', geoCoord:[108.95, 34.27]},\n",
    "//{name:'台湾', geoCoord:[121.30, 25.03]},\n",
    "{name:'北京', geoCoord:[116.46, 39.92]},\n",
    "{name:'上海', geoCoord:[121.48, 31.22]},\n",
    "{name:'重庆', geoCoord:[106.54, 29.59]},\n",
    "{name:'天津', geoCoord:[117.2, 39.13]},\n",
    "{name:'呼和浩特', geoCoord:[111.65, 40.82]},\n",
    "{name:'南宁', geoCoord:[108.33, 22.84]},\n",
    "//{name:'西藏', geoCoord:[91.11, 29.97]},\n",
    "{name:'银川', geoCoord:[106.27, 38.47]},\n",
    "{name:'乌鲁木齐', geoCoord:[87.68, 43.77]},\n",
    "{name:'香港', geoCoord:[114.17, 22.28]},\n",
    "{name:'澳门', geoCoord:[113.54, 22.19]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l =  \"color and colour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color', 'colour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"colou?r\")\n",
    "pattern.findall(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_info(city_coordination):\n",
    "    city_location = {}\n",
    "    for line in city_coordination.split(\"\\n\"):\n",
    "            if line.startswith(\"//\"):continue\n",
    "            if line.strip()==\"\": continue\n",
    "            # find city\n",
    "            city = re.findall(\"name:'(\\w+)'\",line)[0]\n",
    "            x_y = re.findall(\"Coord:\\[(\\d+.\\d+),\\s(\\d+.\\d+)\\]\",line)[0]\n",
    "            print(x_y)\n",
    "            x_y = tuple(map(float,x_y))\n",
    "            city_location[city] = x_y;\n",
    "    return city_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('103.73', '36.03')\n",
      "('98.17', '39.47')\n",
      "('101.74', '36.56')\n",
      "('104.06', '30.67')\n",
      "('114.48', '38.03')\n",
      "('102.73', '25.04')\n",
      "('106.71', '26.57')\n",
      "('114.31', '30.52')\n",
      "('113.65', '34.76')\n",
      "('117', '36.65')\n",
      "('118.78', '32.04')\n",
      "('117.27', '31.86')\n",
      "('120.19', '30.26')\n",
      "('115.89', '28.68')\n",
      "('119.3', '26.08')\n",
      "('113.23', '23.16')\n",
      "('113', '28.21')\n",
      "('123.38', '41.8')\n",
      "('125.35', '43.88')\n",
      "('126.63', '45.75')\n",
      "('112.53', '37.87')\n",
      "('108.95', '34.27')\n",
      "('116.46', '39.92')\n",
      "('121.48', '31.22')\n",
      "('106.54', '29.59')\n",
      "('117.2', '39.13')\n",
      "('111.65', '40.82')\n",
      "('108.33', '22.84')\n",
      "('106.27', '38.47')\n",
      "('87.68', '43.77')\n",
      "('114.17', '22.28')\n",
      "('113.54', '22.19')\n"
     ]
    }
   ],
   "source": [
    "city_info = get_city_info(coordination_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'兰州': (103.73, 36.03),\n",
       " '嘉峪关': (98.17, 39.47),\n",
       " '西宁': (101.74, 36.56),\n",
       " '成都': (104.06, 30.67),\n",
       " '石家庄': (114.48, 38.03),\n",
       " '拉萨': (102.73, 25.04),\n",
       " '贵阳': (106.71, 26.57),\n",
       " '武汉': (114.31, 30.52),\n",
       " '郑州': (113.65, 34.76),\n",
       " '济南': (117.0, 36.65),\n",
       " '南京': (118.78, 32.04),\n",
       " '合肥': (117.27, 31.86),\n",
       " '杭州': (120.19, 30.26),\n",
       " '南昌': (115.89, 28.68),\n",
       " '福州': (119.3, 26.08),\n",
       " '广州': (113.23, 23.16),\n",
       " '长沙': (113.0, 28.21),\n",
       " '沈阳': (123.38, 41.8),\n",
       " '长春': (125.35, 43.88),\n",
       " '哈尔滨': (126.63, 45.75),\n",
       " '太原': (112.53, 37.87),\n",
       " '西安': (108.95, 34.27),\n",
       " '北京': (116.46, 39.92),\n",
       " '上海': (121.48, 31.22),\n",
       " '重庆': (106.54, 29.59),\n",
       " '天津': (117.2, 39.13),\n",
       " '呼和浩特': (111.65, 40.82),\n",
       " '南宁': (108.33, 22.84),\n",
       " '银川': (106.27, 38.47),\n",
       " '乌鲁木齐': (87.68, 43.77),\n",
       " '香港': (114.17, 22.28),\n",
       " '澳门': (113.54, 22.19)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute distance between city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def geo_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    origin : tuple of float\n",
    "        (lat, long)\n",
    "    destination : tuple of float\n",
    "        (lat, long)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance_in_km : float\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> origin = (48.1372, 11.5756)  # Munich\n",
    "    >>> destination = (52.5186, 13.4083)  # Berlin\n",
    "    >>> round(distance(origin, destination), 1)\n",
    "    504.2\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
    "         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
    "         math.sin(dlon / 2) * math.sin(dlon / 2))\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写一个判断两个城市的距离\n",
    "def get_city_distance(city1,city2):\n",
    "    return geo_distance(city_info[city1],city_info[city2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.5185697155768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_city_distance(\"杭州\",\"上海\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  draw the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#导入字体库，并设置\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['兰州', '嘉峪关', '西宁', '成都', '石家庄', '拉萨', '贵阳', '武汉', '郑州', '济南', '南京', '合肥', '杭州', '南昌', '福州', '广州', '长沙', '沈阳', '长春', '哈尔滨', '太原', '西安', '北京', '上海', '重庆', '天津', '呼和浩特', '南宁', '银川', '乌鲁木齐', '香港', '澳门'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_graph = nx.Graph()\n",
    "\n",
    "city_graph.add_nodes_from(list(city_info.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(city_graph,city_info,with_labels=True,node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 700 #define the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_connection(city_info):\n",
    "    cities_connection = defaultdict(list)\n",
    "    cities = list(city_info.keys())\n",
    "    for c1 in cities:\n",
    "        for c2 in cities:\n",
    "            if c1==c2:continue\n",
    "            if get_city_distance(c1,c2) < threshold:\n",
    "                cities_connection[c1].append(c2)\n",
    "    return cities_connection\n",
    "cities_connection = build_connection(city_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'兰州': ['嘉峪关', '西宁', '成都', '拉萨', '贵阳', '西安', '重庆', '南宁', '银川'],\n",
       "             '嘉峪关': ['兰州', '西宁', '成都', '拉萨'],\n",
       "             '西宁': ['兰州', '嘉峪关', '成都', '拉萨', '贵阳', '重庆', '银川'],\n",
       "             '成都': ['兰州', '嘉峪关', '西宁', '拉萨', '贵阳', '西安', '重庆', '南宁', '银川'],\n",
       "             '石家庄': ['武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '南昌',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '西安',\n",
       "              '北京',\n",
       "              '天津',\n",
       "              '呼和浩特'],\n",
       "             '拉萨': ['兰州', '嘉峪关', '西宁', '成都', '贵阳', '重庆', '南宁', '银川'],\n",
       "             '贵阳': ['兰州', '西宁', '成都', '拉萨', '西安', '重庆', '南宁', '银川'],\n",
       "             '武汉': ['石家庄',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '杭州',\n",
       "              '南昌',\n",
       "              '福州',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '西安',\n",
       "              '北京',\n",
       "              '天津',\n",
       "              '呼和浩特',\n",
       "              '香港',\n",
       "              '澳门'],\n",
       "             '郑州': ['石家庄',\n",
       "              '武汉',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '南昌',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '西安',\n",
       "              '北京',\n",
       "              '天津',\n",
       "              '呼和浩特',\n",
       "              '香港',\n",
       "              '澳门'],\n",
       "             '济南': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '杭州',\n",
       "              '南昌',\n",
       "              '福州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '北京',\n",
       "              '上海',\n",
       "              '天津',\n",
       "              '呼和浩特'],\n",
       "             '南京': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '合肥',\n",
       "              '杭州',\n",
       "              '南昌',\n",
       "              '福州',\n",
       "              '长沙',\n",
       "              '北京',\n",
       "              '上海',\n",
       "              '天津'],\n",
       "             '合肥': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '杭州',\n",
       "              '南昌',\n",
       "              '福州',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '北京',\n",
       "              '上海',\n",
       "              '天津',\n",
       "              '香港',\n",
       "              '澳门'],\n",
       "             '杭州': ['武汉', '济南', '南京', '合肥', '南昌', '福州', '北京', '上海', '天津'],\n",
       "             '南昌': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '杭州',\n",
       "              '福州',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '北京',\n",
       "              '上海',\n",
       "              '天津',\n",
       "              '香港',\n",
       "              '澳门'],\n",
       "             '福州': ['武汉',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '杭州',\n",
       "              '南昌',\n",
       "              '广州',\n",
       "              '上海',\n",
       "              '香港',\n",
       "              '澳门'],\n",
       "             '广州': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '合肥',\n",
       "              '南昌',\n",
       "              '福州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '西安',\n",
       "              '南宁',\n",
       "              '香港',\n",
       "              '澳门'],\n",
       "             '长沙': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '南昌',\n",
       "              '广州',\n",
       "              '太原',\n",
       "              '西安',\n",
       "              '北京',\n",
       "              '天津',\n",
       "              '呼和浩特',\n",
       "              '南宁',\n",
       "              '香港',\n",
       "              '澳门'],\n",
       "             '沈阳': ['长春', '哈尔滨', '上海'],\n",
       "             '长春': ['沈阳', '哈尔滨'],\n",
       "             '哈尔滨': ['沈阳', '长春'],\n",
       "             '太原': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '合肥',\n",
       "              '南昌',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '西安',\n",
       "              '北京',\n",
       "              '天津',\n",
       "              '呼和浩特',\n",
       "              '银川',\n",
       "              '澳门'],\n",
       "             '西安': ['兰州',\n",
       "              '成都',\n",
       "              '石家庄',\n",
       "              '贵阳',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '重庆',\n",
       "              '呼和浩特',\n",
       "              '南宁',\n",
       "              '银川'],\n",
       "             '北京': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '杭州',\n",
       "              '南昌',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '天津',\n",
       "              '呼和浩特'],\n",
       "             '上海': ['济南', '南京', '合肥', '杭州', '南昌', '福州', '沈阳', '天津'],\n",
       "             '重庆': ['兰州', '西宁', '成都', '拉萨', '贵阳', '西安', '呼和浩特', '南宁', '银川'],\n",
       "             '天津': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '南京',\n",
       "              '合肥',\n",
       "              '杭州',\n",
       "              '南昌',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '北京',\n",
       "              '上海',\n",
       "              '呼和浩特'],\n",
       "             '呼和浩特': ['石家庄',\n",
       "              '武汉',\n",
       "              '郑州',\n",
       "              '济南',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '西安',\n",
       "              '北京',\n",
       "              '重庆',\n",
       "              '天津',\n",
       "              '银川'],\n",
       "             '南宁': ['兰州',\n",
       "              '成都',\n",
       "              '拉萨',\n",
       "              '贵阳',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '西安',\n",
       "              '重庆',\n",
       "              '银川',\n",
       "              '香港',\n",
       "              '澳门'],\n",
       "             '银川': ['兰州',\n",
       "              '西宁',\n",
       "              '成都',\n",
       "              '拉萨',\n",
       "              '贵阳',\n",
       "              '太原',\n",
       "              '西安',\n",
       "              '重庆',\n",
       "              '呼和浩特',\n",
       "              '南宁'],\n",
       "             '香港': ['武汉', '郑州', '合肥', '南昌', '福州', '广州', '长沙', '南宁', '澳门'],\n",
       "             '澳门': ['武汉',\n",
       "              '郑州',\n",
       "              '合肥',\n",
       "              '南昌',\n",
       "              '福州',\n",
       "              '广州',\n",
       "              '长沙',\n",
       "              '太原',\n",
       "              '南宁',\n",
       "              '香港']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.defaultdict'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(cities_connection))\n",
    "cities_connection_graph = nx.Graph(cities_connection)\n",
    "print(cities_connection_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(cities_connection_graph,city_info,with_labels=True,node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph,start,destination):\n",
    "    pathes = [[start]]\n",
    "    visited = set()\n",
    "    while pathes:\n",
    "        path = pathes.pop(0)\n",
    "        froniter = path[-1]\n",
    "        if froniter in visited:continue\n",
    "        successors = graph[froniter]\n",
    "        for city in successors:\n",
    "            if city in path: continue #check up\n",
    "            new_path = path + [city]\n",
    "            print(new_path)\n",
    "            pathes.append(new_path)\n",
    "            if city == destination:\n",
    "                return new_path\n",
    "        visited.add(froniter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['上海', '济南']\n",
      "['上海', '南京']\n",
      "['上海', '合肥']\n",
      "['上海', '杭州']\n",
      "['上海', '南昌']\n",
      "['上海', '福州']\n",
      "['上海', '沈阳']\n",
      "['上海', '天津']\n",
      "['上海', '济南', '石家庄']\n",
      "['上海', '济南', '武汉']\n",
      "['上海', '济南', '郑州']\n",
      "['上海', '济南', '南京']\n",
      "['上海', '济南', '合肥']\n",
      "['上海', '济南', '杭州']\n",
      "['上海', '济南', '南昌']\n",
      "['上海', '济南', '福州']\n",
      "['上海', '济南', '长沙']\n",
      "['上海', '济南', '太原']\n",
      "['上海', '济南', '北京']\n",
      "['上海', '济南', '天津']\n",
      "['上海', '济南', '呼和浩特']\n",
      "['上海', '南京', '石家庄']\n",
      "['上海', '南京', '武汉']\n",
      "['上海', '南京', '郑州']\n",
      "['上海', '南京', '济南']\n",
      "['上海', '南京', '合肥']\n",
      "['上海', '南京', '杭州']\n",
      "['上海', '南京', '南昌']\n",
      "['上海', '南京', '福州']\n",
      "['上海', '南京', '长沙']\n",
      "['上海', '南京', '北京']\n",
      "['上海', '南京', '天津']\n",
      "['上海', '合肥', '石家庄']\n",
      "['上海', '合肥', '武汉']\n",
      "['上海', '合肥', '郑州']\n",
      "['上海', '合肥', '济南']\n",
      "['上海', '合肥', '南京']\n",
      "['上海', '合肥', '杭州']\n",
      "['上海', '合肥', '南昌']\n",
      "['上海', '合肥', '福州']\n",
      "['上海', '合肥', '广州']\n",
      "['上海', '合肥', '长沙']\n",
      "['上海', '合肥', '太原']\n",
      "['上海', '合肥', '北京']\n",
      "['上海', '合肥', '天津']\n",
      "['上海', '合肥', '香港']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['上海', '合肥', '香港']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfs(cities_connection,\"上海\",\"香港\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['拉萨', '兰州']\n",
      "['拉萨', '嘉峪关']\n",
      "['拉萨', '西宁']\n",
      "['拉萨', '成都']\n",
      "['拉萨', '贵阳']\n",
      "['拉萨', '重庆']\n",
      "['拉萨', '南宁']\n",
      "['拉萨', '银川']\n",
      "['拉萨', '兰州', '嘉峪关']\n",
      "['拉萨', '兰州', '西宁']\n",
      "['拉萨', '兰州', '成都']\n",
      "['拉萨', '兰州', '贵阳']\n",
      "['拉萨', '兰州', '西安']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['拉萨', '兰州', '西安']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfs(cities_connection,\"拉萨\",\"西安\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(graph,start,destination):\n",
    "    pathes = [[start]]\n",
    "    visited = set()\n",
    "    while pathes:\n",
    "        path = pathes.pop(0)\n",
    "        froniter = path[-1]\n",
    "        if froniter in visited:continue\n",
    "        successors = graph[froniter]\n",
    "        for city in successors:\n",
    "            if city in path: continue #check up\n",
    "            new_path = path + [city]\n",
    "            #print(path)\n",
    "            pathes = [new_path]+pathes\n",
    "            #print(pathes) Keep adding small paths in, and the longer the path is in front\n",
    "            if city == destination:\n",
    "                print(pathes)\n",
    "                return new_path\n",
    "        visited.add(froniter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '北京'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '西安'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '太原'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '广州'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '南昌'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '合肥'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '南京'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '济南'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '郑州'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '武汉'], ['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '石家庄'], ['拉萨', '银川', '南宁', '澳门', '香港', '广州'], ['拉萨', '银川', '南宁', '澳门', '香港', '福州'], ['拉萨', '银川', '南宁', '澳门', '香港', '南昌'], ['拉萨', '银川', '南宁', '澳门', '香港', '合肥'], ['拉萨', '银川', '南宁', '澳门', '香港', '郑州'], ['拉萨', '银川', '南宁', '澳门', '香港', '武汉'], ['拉萨', '银川', '南宁', '澳门', '太原'], ['拉萨', '银川', '南宁', '澳门', '长沙'], ['拉萨', '银川', '南宁', '澳门', '广州'], ['拉萨', '银川', '南宁', '澳门', '福州'], ['拉萨', '银川', '南宁', '澳门', '南昌'], ['拉萨', '银川', '南宁', '澳门', '合肥'], ['拉萨', '银川', '南宁', '澳门', '郑州'], ['拉萨', '银川', '南宁', '澳门', '武汉'], ['拉萨', '银川', '南宁', '香港'], ['拉萨', '银川', '南宁', '重庆'], ['拉萨', '银川', '南宁', '西安'], ['拉萨', '银川', '南宁', '长沙'], ['拉萨', '银川', '南宁', '广州'], ['拉萨', '银川', '南宁', '贵阳'], ['拉萨', '银川', '南宁', '成都'], ['拉萨', '银川', '南宁', '兰州'], ['拉萨', '银川', '呼和浩特'], ['拉萨', '银川', '重庆'], ['拉萨', '银川', '西安'], ['拉萨', '银川', '太原'], ['拉萨', '银川', '贵阳'], ['拉萨', '银川', '成都'], ['拉萨', '银川', '西宁'], ['拉萨', '银川', '兰州'], ['拉萨', '南宁'], ['拉萨', '重庆'], ['拉萨', '贵阳'], ['拉萨', '成都'], ['拉萨', '西宁'], ['拉萨', '嘉峪关'], ['拉萨', '兰州']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['拉萨', '银川', '南宁', '澳门', '香港', '长沙', '北京']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs(cities_connection,\"拉萨\",\"北京\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI the less distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_2(graph,start,destination,search_strategy):\n",
    "        pathes = [[start]]\n",
    "        while pathes:\n",
    "            path = pathes.pop(0)\n",
    "            froniter = path[-1]\n",
    "            successors = graph[froniter]\n",
    "            for city in successors:\n",
    "                if city in path: continue\n",
    "                new_path = path+[city]\n",
    "                pathes.append(new_path)\n",
    "\n",
    "            pathes = search_strategy(pathes)\n",
    "            # visit add\n",
    "            if pathes and pathes[0][-1] == destination:# 这条路径经过重排序之后是最短的，\n",
    "                print(pathes)\n",
    "                print(\"--------------------------------------\")\n",
    "                return pathes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_distance(pathes):\n",
    "    def get_distance_of_path(path):\n",
    "        distance = 0\n",
    "        for i,_ in enumerate(path[:-1]):\n",
    "            distance += get_city_distance(path[i],path[i+1])\n",
    "        return distance\n",
    "    return sorted(pathes,key=get_distance_of_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_of_path(path):\n",
    "    distance = 0\n",
    "    for i,_ in enumerate(path[:-1]):\n",
    "        distance += get_city_distance(path[i],path[i+1])\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752.66259009181"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distance_of_path([\"北京\",\"济南\",\"上海\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['北京', '天津', '上海'], ['北京', '石家庄', '呼和浩特', '太原'], ['北京', '天津', '石家庄', '呼和浩特'], ['北京', '郑州', '呼和浩特'], ['北京', '郑州', '太原', '呼和浩特'], ['北京', '济南', '郑州', '太原'], ['北京', '天津', '郑州', '武汉'], ['北京', '天津', '石家庄', '武汉'], ['北京', '济南', '天津', '郑州'], ['北京', '合肥', '武汉'], ['北京', '南昌', '武汉'], ['北京', '合肥', '杭州'], ['北京', '济南', '上海'], ['北京', '石家庄', '郑州', '呼和浩特'], ['北京', '石家庄', '郑州', '太原', '呼和浩特'], ['北京', '济南', '合肥', '武汉'], ['北京', '济南', '合肥', '杭州'], ['北京', '天津', '石家庄', '郑州', '太原'], ['北京', '石家庄', '武汉', '长沙'], ['北京', '济南', '郑州', '武汉'], ['北京', '合肥', '南京', '杭州'], ['北京', '济南', '长沙'], ['北京', '济南', '石家庄', '天津'], ['北京', '石家庄', '济南', '合肥'], ['北京', '天津', '太原', '呼和浩特'], ['北京', '济南', '合肥', '南京', '杭州'], ['北京', '济南', '武汉', '长沙'], ['北京', '郑州', '南昌'], ['北京', '天津', '石家庄', '太原', '呼和浩特'], ['北京', '南昌', '合肥'], ['北京', '天津', '济南', '郑州', '石家庄'], ['北京', '天津', '石家庄', '郑州', '武汉'], ['北京', '郑州', '济南'], ['北京', '郑州', '武汉', '长沙'], ['北京', '石家庄', '武汉', '南昌'], ['北京', '济南', '南昌', '武汉'], ['北京', '济南', '天津', '石家庄', '郑州'], ['北京', '济南', '福州'], ['北京', '南京', '上海'], ['北京', '合肥', '天津'], ['北京', '天津', '长沙'], ['北京', '天津', '济南', '郑州', '太原'], ['北京', '合肥', '济南', '天津'], ['北京', '郑州', '石家庄', '太原'], ['北京', '石家庄', '武汉', '郑州'], ['北京', '济南', '南京', '上海'], ['北京', '济南', '合肥', '天津'], ['北京', '石家庄', '郑州', '南昌'], ['北京', '济南', '武汉', '南昌'], ['北京', '南京', '济南'], ['北京', '合肥', '福州'], ['北京', '天津', '武汉', '长沙'], ['北京', '石家庄', '郑州', '济南'], ['北京', '石家庄', '郑州', '武汉', '长沙'], ['北京', '郑州', '太原', '石家庄'], ['北京', '天津', '合肥', '武汉'], ['北京', '郑州', '武汉', '南昌'], ['北京', '天津', '合肥', '杭州'], ['北京', '天津', '济南', '上海'], ['北京', '济南', '合肥', '福州'], ['北京', '天津', '太原', '郑州'], ['北京', '济南', '呼和浩特'], ['北京', '天津', '济南', '合肥', '武汉'], ['北京', '济南', '武汉', '郑州'], ['北京', '天津', '济南', '合肥', '杭州'], ['北京', '济南', '石家庄', '呼和浩特'], ['北京', '天津', '石家庄', '太原', '郑州'], ['北京', '石家庄', '南京'], ['北京', '天津', '南京', '上海'], ['北京', '太原', '郑州', '石家庄'], ['北京', '天津', '济南', '郑州', '武汉'], ['北京', '济南', '石家庄', '武汉'], ['北京', '南京', '福州'], ['北京', '济南', '南昌', '合肥'], ['北京', '杭州', '上海'], ['北京', '天津', '南京', '济南'], ['北京', '济南', '南京', '福州'], ['北京', '天津', '武汉', '南昌'], ['北京', '石家庄', '郑州', '武汉', '南昌'], ['北京', '天津', '济南', '长沙'], ['北京', '天津', '合肥', '南京', '杭州'], ['北京', '天津', '济南', '合肥', '南京', '杭州'], ['北京', '天津', '济南', '武汉', '长沙'], ['北京', '济南', '杭州', '上海'], ['北京', '南京', '杭州', '上海'], ['北京', '济南', '石家庄', '郑州', '太原'], ['北京', '郑州', '合肥'], ['北京', '天津', '武汉', '郑州'], ['北京', '天津', '杭州', '上海'], ['北京', '济南', '南京', '杭州', '上海'], ['北京', '济南', '天津', '太原'], ['北京', '济南', '天津', '石家庄', '太原'], ['北京', '天津', '南昌', '武汉'], ['北京', '济南', '天津', '武汉'], ['北京', '太原', '武汉'], ['北京', '天津', '南京', '福州'], ['北京', '天津', '济南', '南昌', '武汉'], ['北京', '天津', '济南', '福州'], ['北京', '天津', '石家庄', '合肥'], ['北京', '天津', '太原', '石家庄'], ['北京', '合肥', '南昌', '武汉'], ['北京', '济南', '太原', '呼和浩特'], ['北京', '天津', '济南', '南京', '上海'], ['北京', '天津', '济南', '武汉', '南昌'], ['北京', '天津', '郑州', '长沙'], ['北京', '石家庄', '太原', '武汉'], ['北京', '济南', '合肥', '南昌', '武汉'], ['北京', '太原', '郑州', '武汉'], ['北京', '济南', '石家庄', '太原', '呼和浩特'], ['北京', '石家庄', '济南', '南京'], ['北京', '石家庄', '合肥', '南京'], ['北京', '石家庄', '郑州', '合肥'], ['北京', '太原', '石家庄', '郑州'], ['北京', '天津', '南京', '杭州', '上海'], ['北京', '济南', '天津', '合肥', '南京'], ['北京', '天津', '合肥', '福州'], ['北京', '合肥', '郑州'], ['北京', '济南', '天津', '南昌'], ['北京', '杭州', '南京'], ['北京', '郑州', '天津'], ['北京', '济南', '石家庄', '郑州', '武汉'], ['北京', '天津', '济南', '合肥', '福州'], ['北京', '武汉', '合肥'], ['北京', '天津', '济南', '呼和浩特'], ['北京', '长沙', '武汉'], ['北京', '天津', '济南', '武汉', '郑州'], ['北京', '石家庄', '太原', '郑州', '武汉'], ['北京', '天津', '济南', '石家庄', '呼和浩特'], ['北京', '济南', '合肥', '郑州'], ['北京', '南京', '南昌'], ['北京', '合肥', '石家庄'], ['北京', '济南', '南京', '南昌'], ['北京', '济南', '合肥', '石家庄'], ['北京', '济南', '杭州', '南京'], ['北京', '天津', '南昌', '合肥'], ['北京', '天津', '济南', '石家庄', '武汉'], ['北京', '武汉', '石家庄'], ['北京', '天津', '济南', '南昌', '合肥'], ['北京', '天津', '杭州', '南京'], ['北京', '济南', '郑州', '长沙'], ['北京', '天津', '济南', '南京', '福州'], ['北京', '武汉', '广州'], ['北京', '郑州', '石家庄', '济南'], ['北京', '济南', '太原', '郑州'], ['北京', '石家庄', '郑州', '天津'], ['北京', '济南', '石家庄', '太原', '郑州'], ['北京', '天津', '济南', '杭州', '上海'], ['北京', '天津', '南京', '南昌'], ['北京', '太原', '长沙'], ['北京', '天津', '济南', '石家庄', '郑州', '太原'], ['北京', '天津', '石家庄', '长沙'], ['北京', '天津', '石家庄', '南昌'], ['北京', '天津', '济南', '南京', '杭州', '上海'], ['北京', '南京', '合肥', '南昌'], ['北京', '太原', '西安'], ['北京', '天津', '石家庄', '郑州', '长沙'], ['北京', '天津', '呼和浩特', '太原'], ['北京', '郑州', '长沙', '武汉'], ['北京', '石家庄', '西安'], ['北京', '石家庄', '太原', '长沙'], ['北京', '济南', '南京', '合肥', '南昌'], ['北京', '呼和浩特', '石家庄'], ['北京', '南昌', '长沙'], ['北京', '天津', '济南', '太原', '呼和浩特'], ['北京', '郑州', '石家庄', '天津'], ['北京', '石家庄', '太原', '西安'], ['北京', '天津', '合肥', '南昌', '武汉'], ['北京', '呼和浩特', '郑州'], ['北京', '呼和浩特', '太原', '郑州'], ['北京', '天津', '郑州', '呼和浩特'], ['北京', '天津', '郑州', '太原', '呼和浩特'], ['北京', '济南', '天津', '南京', '合肥'], ['北京', '济南', '天津', '杭州'], ['北京', '天津', '济南', '合肥', '南昌', '武汉'], ['北京', '天津', '济南', '石家庄', '太原', '呼和浩特'], ['北京', '武汉', '香港'], ['北京', '合肥', '上海'], ['北京', '石家庄', '长沙', '武汉'], ['北京', '合肥', '南京', '上海'], ['北京', '天津', '济南', '石家庄', '郑州', '武汉'], ['北京', '天津', '合肥', '郑州'], ['北京', '武汉', '郑州', '石家庄'], ['北京', '长沙', '广州'], ['北京', '武汉', '太原'], ['北京', '石家庄', '郑州', '长沙', '武汉'], ['北京', '济南', '合肥', '上海'], ['北京', '石家庄', '合肥', '南昌'], ['北京', '天津', '南京', '合肥', '南昌'], ['北京', '天津', '济南', '合肥', '郑州'], ['北京', '南京', '天津'], ['北京', '济南', '合肥', '南京', '上海'], ['北京', '济南', '太原', '石家庄'], ['北京', '天津', '合肥', '石家庄'], ['北京', '济南', '天津', '合肥', '南昌'], ['北京', '武汉', '澳门'], ['北京', '济南', '石家庄', '合肥'], ['北京', '合肥', '南京', '济南'], ['北京', '南京', '合肥', '济南'], ['北京', '天津', '济南', '南京', '南昌'], ['北京', '济南', '南京', '天津'], ['北京', '天津', '济南', '合肥', '石家庄'], ['北京', '天津', '济南', '杭州', '南京'], ['北京', '济南', '天津', '南京', '杭州'], ['北京', '武汉', '郑州', '太原'], ['北京', '济南', '郑州', '呼和浩特'], ['北京', '天津', '济南', '郑州', '长沙'], ['北京', '石家庄', '南昌', '武汉'], ['北京', '天津', '济南', '太原', '郑州'], ['北京', '杭州', '福州'], ['北京', '郑州', '石家庄', '呼和浩特'], ['北京', '武汉', '长沙', '广州'], ['北京', '天津', '济南', '石家庄', '太原', '郑州'], ['北京', '石家庄', '济南', '郑州'], ['北京', '济南', '南昌', '长沙'], ['北京', '合肥', '南京', '福州'], ['北京', '郑州', '广州'], ['北京', '南昌', '香港'], ['北京', '呼和浩特', '太原', '石家庄'], ['北京', '石家庄', '合肥', '济南'], ['北京', '天津', '南京', '合肥', '济南'], ['北京', '济南', '合肥', '南京', '福州'], ['北京', '天津', '郑州', '南昌'], ['北京', '天津', '石家庄', '郑州', '呼和浩特'], ['北京', '郑州', '长沙', '广州'], ['北京', '石家庄', '天津', '合肥'], ['北京', '郑州', '石家庄', '武汉'], ['北京', '济南', '杭州', '福州'], ['北京', '南京', '杭州', '福州'], ['北京', '石家庄', '呼和浩特', '郑州'], ['北京', '石家庄', '天津', '济南', '合肥'], ['北京', '天津', '济南', '南京', '合肥', '南昌'], ['北京', '南昌', '南京'], ['北京', '郑州', '西安'], ['北京', '石家庄', '武汉', '合肥'], ['北京', '石家庄', '广州'], ['北京', '合肥', '长沙'], ['北京', '天津', '杭州', '福州'], ['北京', '济南', '南京', '杭州', '福州'], ['北京', '天津', '郑州', '济南'], ['北京', '武汉', '南昌', '合肥'], ['北京', '济南', '天津', '呼和浩特'], ['北京', '济南', '合肥', '长沙'], ['北京', '武汉', '济南'], ['北京', '石家庄', '郑州', '广州'], ['北京', '石家庄', '南昌', '合肥'], ['北京', '太原', '郑州', '长沙'], ['北京', '呼和浩特', '西安'], ['北京', '石家庄', '长沙', '广州'], ['北京', '天津', '郑州', '石家庄', '太原'], ['北京', '济南', '武汉', '合肥'], ['北京', '天津', '合肥', '上海'], ['北京', '济南', '石家庄', '长沙'], ['北京', '济南', '石家庄', '南昌'], ['北京', '南昌', '郑州'], ['北京', '天津', '石家庄', '济南', '合肥'], ['北京', '石家庄', '郑州', '长沙', '广州'], ['北京', '天津', '合肥', '南京', '上海'], ['北京', '天津', '济南', '合肥', '上海'], ['北京', '济南', '石家庄', '郑州', '长沙'], ['北京', '石家庄', '武汉', '广州'], ['北京', '济南', '郑州', '南昌'], ['北京', '天津', '济南', '合肥', '南京', '上海'], ['北京', '石家庄', '郑州', '西安'], ['北京', '天津', '南京', '杭州', '福州'], ['北京', '天津', '济南', '太原', '石家庄'], ['北京', '郑州', '武汉', '合肥'], ['北京', '石家庄', '太原', '郑州', '长沙'], ['北京', '长沙', '澳门'], ['北京', '天津', '济南', '石家庄', '合肥'], ['北京', '天津', '郑州', '太原', '石家庄'], ['北京', '石家庄', '济南', '南昌'], ['北京', '济南', '武汉', '石家庄'], ['北京', '天津', '合肥', '南京', '济南'], ['北京', '太原', '呼和浩特', '石家庄'], ['北京', '济南', '天津', '上海'], ['北京', '天津', '济南', '郑州', '呼和浩特'], ['北京', '济南', '南昌', '香港'], ['北京', '南昌', '广州'], ['北京', '济南', '武汉', '广州'], ['北京', '石家庄', '济南', '武汉'], ['北京', '郑州', '武汉', '石家庄'], ['北京', '太原', '呼和浩特', '郑州'], ['北京', '济南', '天津', '石家庄', '呼和浩特'], ['北京', '合肥', '南京', '南昌'], ['北京', '太原', '济南'], ['北京', '合肥', '济南', '石家庄'], ['北京', '济南', '郑州', '石家庄', '太原'], ['北京', '天津', '石家庄', '郑州', '南昌'], ['北京', '济南', '合肥', '南京', '南昌'], ['北京', '郑州', '武汉', '广州'], ['北京', '济南', '南昌', '南京'], ['北京', '天津', '武汉', '合肥'], ['北京', '太原', '石家庄', '济南'], ['北京', '天津', '南昌', '长沙'], ['北京', '南昌', '澳门'], ['北京', '石家庄', '郑州', '武汉', '合肥'], ['北京', '石家庄', '太原', '呼和浩特', '郑州'], ['北京', '济南', '天津', '石家庄', '武汉'], ['北京', '天津', '济南', '南昌', '长沙'], ['北京', '郑州', '澳门'], ['北京', '石家庄', '天津', '南京'], ['北京', '石家庄', '太原', '济南'], ['北京', '天津', '合肥', '南京', '福州'], ['北京', '天津', '石家庄', '郑州', '济南'], ['北京', '南昌', '福州'], ['北京', '武汉', '长沙', '澳门'], ['北京', '合肥', '南昌', '长沙'], ['北京', '天津', '济南', '合肥', '南京', '福州'], ['北京', '长沙', '香港'], ['北京', '石家庄', '武汉', '香港'], ['北京', '郑州', '太原', '武汉'], ['北京', '郑州', '香港'], ['北京', '天津', '济南', '杭州', '福州'], ['北京', '济南', '合肥', '南昌', '长沙'], ['北京', '天津', '武汉', '石家庄'], ['北京', '天津', '石家庄', '南京'], ['北京', '长沙', '郑州'], ['北京', '天津', '郑州', '合肥'], ['北京', '石家庄', '武汉', '太原'], ['北京', '郑州', '长沙', '澳门'], ['北京', '济南', '南昌', '郑州'], ['北京', '天津', '济南', '南京', '杭州', '福州'], ['北京', '天津', '合肥', '长沙'], ['北京', '天津', '武汉', '广州'], ['北京', '石家庄', '呼和浩特', '西安'], ['北京', '南昌', '济南'], ['北京', '石家庄', '武汉', '澳门'], ['北京', '石家庄', '郑州', '武汉', '广州'], ['北京', '天津', '济南', '合肥', '长沙'], ['北京', '太原', '天津'], ['北京', '合肥', '济南', '南京'], ['北京', '济南', '武汉', '香港'], ['北京', '太原', '石家庄', '天津'], ['北京', '石家庄', '郑州', '澳门'], ['北京', '太原', '郑州', '呼和浩特'], ['北京', '济南', '武汉', '太原'], ['北京', '天津', '济南', '武汉', '合肥'], ['北京', '天津', '济南', '石家庄', '长沙'], ['北京', '天津', '济南', '石家庄', '南昌'], ['北京', '石家庄', '郑州', '太原', '武汉'], ['北京', '郑州', '武汉', '香港'], ['北京', '石家庄', '郑州', '香港'], ['北京', '石家庄', '太原', '天津'], ['北京', '济南', '南昌', '广州'], ['北京', '石家庄', '长沙', '澳门'], ['北京', '济南', '石家庄', '郑州', '呼和浩特'], ['北京', '天津', '济南', '石家庄', '郑州', '长沙'], ['北京', '天津', '济南', '郑州', '南昌'], ['北京', '济南', '武汉', '澳门'], ['北京', '武汉', '长沙', '香港'], ['北京', '石家庄', '太原', '郑州', '呼和浩特'], ['北京', '郑州', '武汉', '太原'], ['北京', '石家庄', '郑州', '长沙', '澳门'], ['北京', '郑州', '南京'], ['北京', '武汉', '长沙', '郑州'], ['北京', '济南', '郑州', '合肥'], ['北京', '南京', '武汉'], ['北京', '石家庄', '天津', '济南', '南京'], ['北京', '天津', '济南', '武汉', '石家庄'], ['北京', '南京', '合肥', '武汉'], ['北京', '南京', '合肥', '杭州'], ['北京', '郑州', '武汉', '澳门'], ['北京', '济南', '南昌', '澳门'], ['北京', '天津', '南昌', '香港'], ['北京', '郑州', '长沙', '香港'], ['北京', '长沙', '南昌'], ['北京', '济南', '南京', '武汉'], ['北京', '天津', '济南', '南昌', '香港'], ['北京', '济南', '南京', '合肥', '武汉'], ['北京', '济南', '南京', '合肥', '杭州'], ['北京', '济南', '南昌', '福州'], ['北京', '天津', '济南', '武汉', '广州'], ['北京', '合肥', '香港'], ['北京', '石家庄', '天津', '郑州'], ['北京', '合肥', '南昌', '香港'], ['北京', '杭州', '合肥'], ['北京', '合肥', '南京', '天津'], ['北京', '天津', '武汉', '香港'], ['北京', '天津', '合肥', '南京', '南昌'], ['北京', '天津', '合肥', '济南', '石家庄'], ['北京', '石家庄', '郑州', '武汉', '香港'], ['北京', '天津', '太原', '武汉'], ['北京', '天津', '南昌', '南京'], ['北京', '济南', '合肥', '香港'], ['北京', '济南', '天津', '长沙'], ['北京', '天津', '石家庄', '太原', '武汉'], ['北京', '济南', '合肥', '南昌', '香港'], ['北京', '天津', '济南', '合肥', '南京', '南昌'], ['北京', '天津', '济南', '南昌', '南京'], ['北京', '天津', '武汉', '太原'], ['北京', '济南', '合肥', '南京', '天津'], ['北京', '太原', '呼和浩特', '西安'], ['北京', '天津', '石家庄', '济南', '南京'], ['北京', '石家庄', '郑州', '武汉', '太原'], ['北京', '郑州', '太原', '长沙'], ['北京', '石家庄', '郑州', '南京'], ['北京', '天津', '石家庄', '郑州', '合肥'], ['北京', '合肥', '南昌', '南京'], ['北京', '天津', '郑州', '石家庄', '济南'], ['北京', '石家庄', '长沙', '香港'], ['北京', '济南', '杭州', '合肥'], ['北京', '郑州', '石家庄', '合肥'], ['北京', '南京', '杭州', '合肥'], ['北京', '天津', '武汉', '澳门'], ['北京', '太原', '石家庄', '呼和浩特'], ['北京', '郑州', '太原', '西安'], ['北京', '石家庄', '郑州', '武汉', '澳门'], ['北京', '石家庄', '武汉', '济南'], ['北京', '天津', '南京', '武汉'], ['北京', '济南', '合肥', '南昌', '南京'], ['北京', '济南', '郑州', '天津'], ['北京', '天津', '合肥', '南昌', '长沙'], ['北京', '石家庄', '郑州', '长沙', '香港'], ['北京', '石家庄', '长沙', '郑州'], ['北京', '石家庄', '合肥', '武汉'], ['北京', '天津', '南京', '合肥', '武汉'], ['北京', '石家庄', '太原', '呼和浩特', '西安'], ['北京', '石家庄', '合肥', '杭州'], ['北京', '天津', '南京', '合肥', '杭州'], ['北京', '天津', '杭州', '合肥'], ['北京', '济南', '南京', '杭州', '合肥'], ['北京', '天津', '济南', '合肥', '南昌', '长沙'], ['北京', '天津', '南昌', '郑州'], ['北京', '济南', '天津', '合肥', '武汉'], ['北京', '济南', '天津', '合肥', '杭州'], ['北京', '太原', '南昌'], ['北京', '武汉', '长沙', '南昌'], ['北京', '太原', '郑州', '南昌'], ['北京', '天津', '济南', '南昌', '郑州'], ['北京', '太原', '石家庄', '武汉'], ['北京', '武汉', '郑州', '长沙'], ['北京', '武汉', '南京'], ['北京', '合肥', '太原'], ['北京', '合肥', '南昌', '郑州'], ['北京', '济南', '石家庄', '郑州', '南昌'], ['北京', '太原', '郑州', '济南'], ['北京', '济南', '天津', '南京', '上海'], ['北京', '郑州', '长沙', '南昌'], ['北京', '天津', '济南', '武汉', '香港'], ['北京', '石家庄', '郑州', '太原', '长沙'], ['北京', '石家庄', '太原', '南昌'], ['北京', '济南', '合肥', '太原'], ['北京', '石家庄', '太原', '郑州', '南昌'], ['北京', '济南', '合肥', '南昌', '郑州'], ['北京', '天津', '合肥', '济南', '南京'], ['北京', '石家庄', '济南', '杭州'], ['北京', '南京', '合肥', '天津'], ['北京', '天津', '济南', '武汉', '太原'], ['北京', '石家庄', '郑州', '太原', '西安'], ['北京', '天津', '南昌', '广州'], ['北京', '郑州', '武汉', '济南'], ['北京', '天津', '南京', '杭州', '合肥'], ['北京', '石家庄', '太原', '郑州', '济南'], ['北京', '天津', '济南', '南昌', '广州'], ['北京', '济南', '南京', '合肥', '天津'], ['北京', '天津', '济南', '石家庄', '郑州', '呼和浩特'], ['北京', '南昌', '石家庄'], ['北京', '石家庄', '济南', '天津', '合肥'], ['北京', '合肥', '广州'], ['北京', '天津', '济南', '武汉', '澳门'], ['北京', '武汉', '南昌', '长沙'], ['北京', '合肥', '南昌', '广州'], ['北京', '济南', '石家庄', '南京'], ['北京', '石家庄', '济南', '太原'], ['北京', '天津', '济南', '郑州', '合肥'], ['北京', '南京', '合肥', '福州'], ['北京', '济南', '合肥', '广州'], ['北京', '天津', '南昌', '澳门'], ['北京', '石家庄', '长沙', '南昌'], ['北京', '石家庄', '南昌', '长沙'], ['北京', '济南', '合肥', '南昌', '广州'], ['北京', '天津', '济南', '南昌', '澳门'], ['北京', '石家庄', '郑州', '长沙', '南昌'], ['北京', '济南', '南京', '合肥', '福州'], ['北京', '天津', '南昌', '福州'], ['北京', '武汉', '天津'], ['北京', '天津', '石家庄', '西安'], ['北京', '天津', '太原', '长沙'], ['北京', '天津', '济南', '南京', '武汉'], ['北京', '天津', '济南', '南京', '合肥', '武汉'], ['北京', '天津', '济南', '南京', '合肥', '杭州'], ['北京', '合肥', '澳门'], ['北京', '合肥', '南昌', '澳门'], ['北京', '天津', '石家庄', '太原', '长沙'], ['北京', '天津', '济南', '南昌', '福州'], ['北京', '天津', '武汉', '济南'], ['北京', '天津', '太原', '西安'], ['北京', '天津', '合肥', '香港'], ['北京', '合肥', '南昌', '福州'], ['北京', '石家庄', '郑州', '武汉', '济南'], ['北京', '天津', '石家庄', '太原', '西安'], ['北京', '济南', '天津', '南京', '福州'], ['北京', '天津', '合肥', '南昌', '香港'], ['北京', '济南', '合肥', '澳门'], ['北京', '济南', '合肥', '南昌', '澳门'], ['北京', '石家庄', '合肥', '天津'], ['北京', '郑州', '石家庄', '长沙'], ['北京', '郑州', '石家庄', '南昌'], ['北京', '济南', '郑州', '石家庄', '天津'], ['北京', '天津', '济南', '合肥', '香港'], ['北京', '南昌', '杭州'], ['北京', '济南', '天津', '石家庄', '合肥'], ['北京', '天津', '济南', '合肥', '南昌', '香港'], ['北京', '济南', '合肥', '南昌', '福州'], ['北京', '武汉', '呼和浩特'], ['北京', '合肥', '济南', '郑州'], ['北京', '天津', '南昌', '济南'], ['北京', '南京', '石家庄'], ['北京', '太原', '合肥'], ['北京', '天津', '济南', '杭州', '合肥'], ['北京', '天津', '合肥', '南昌', '南京'], ['北京', '石家庄', '合肥', '福州'], ['北京', '天津', '南京', '合肥', '福州'], ['北京', '济南', '南京', '石家庄'], ['北京', '天津', '济南', '合肥', '南昌', '南京'], ['北京', '合肥', '南昌', '济南'], ['北京', '天津', '郑州', '石家庄', '呼和浩特'], ['北京', '天津', '济南', '南京', '杭州', '合肥'], ['北京', '济南', '天津', '合肥', '福州'], ['北京', '天津', '呼和浩特', '石家庄'], ['北京', '石家庄', '太原', '合肥'], ['北京', '天津', '郑州', '广州'], ['北京', '武汉', '郑州', '呼和浩特'], ['北京', '济南', '太原', '武汉'], ['北京', '天津', '呼和浩特', '郑州'], ['北京', '石家庄', '天津', '济南', '郑州'], ['北京', '济南', '南昌', '石家庄'], ['北京', '太原', '郑州', '合肥'], ['北京', '天津', '郑州', '石家庄', '武汉'], ['北京', '天津', '合肥', '太原'], ['北京', '天津', '济南', '石家庄', '郑州', '南昌'], ['北京', '天津', '合肥', '南昌', '郑州'], ['北京', '济南', '石家庄', '太原', '武汉'], ['北京', '武汉', '南昌', '香港'], ['北京', '天津', '济南', '合肥', '太原'], ['北京', '天津', '郑州', '西安'], ['北京', '天津', '济南', '合肥', '南昌', '郑州'], ['北京', '济南', '石家庄', '郑州', '合肥'], ['北京', '石家庄', '济南', '天津', '南京'], ['北京', '石家庄', '南昌', '香港'], ['北京', '天津', '南京', '石家庄'], ['北京', '石家庄', '太原', '郑州', '合肥'], ['北京', '南京', '郑州'], ['北京', '武汉', '南昌', '南京'], ['北京', '石家庄', '天津', '太原'], ['北京', '济南', '郑州', '石家庄', '呼和浩特'], ['北京', '天津', '石家庄', '济南', '郑州'], ['北京', '石家庄', '天津', '武汉'], ['北京', '天津', '济南', '石家庄', '南京'], ['北京', '天津', '合肥', '广州'], ['北京', '济南', '南京', '郑州'], ['北京', '石家庄', '南昌', '南京'], ['北京', '呼和浩特', '武汉'], ['北京', '济南', '郑州', '广州'], ['北京', '天津', '合肥', '南昌', '广州'], ['北京', '合肥', '济南', '南昌'], ['北京', '天津', '济南', '合肥', '广州'], ['北京', '济南', '南昌', '杭州'], ['北京', '呼和浩特', '太原', '武汉'], ['北京', '天津', '济南', '合肥', '南昌', '广州'], ['北京', '南京', '合肥', '郑州'], ['北京', '济南', '天津', '南京', '南昌'], ['北京', '天津', '济南', '南京', '合肥', '福州'], ['北京', '济南', '郑州', '石家庄', '武汉'], ['北京', '太原', '郑州', '天津'], ['北京', '济南', '天津', '石家庄', '长沙'], ['北京', '济南', '天津', '石家庄', '南昌'], ['北京', '济南', '南京', '合肥', '郑州'], ['北京', '合肥', '济南', '武汉'], ['北京', '南京', '合肥', '石家庄'], ['北京', '天津', '石家庄', '广州'], ['北京', '郑州', '太原', '济南'], ['北京', '武汉', '南昌', '郑州'], ['北京', '天津', '合肥', '澳门'], ['北京', '济南', '郑州', '西安'], ['北京', '天津', '合肥', '南昌', '澳门'], ['北京', '天津', '济南', '合肥', '澳门'], ['北京', '天津', '济南', '合肥', '南昌', '澳门'], ['北京', '济南', '石家庄', '郑州', '天津'], ['北京', '天津', '合肥', '南昌', '福州'], ['北京', '长沙', '太原'], ['北京', '石家庄', '天津', '南昌'], ['北京', '石家庄', '南昌', '郑州'], ['北京', '济南', '南京', '合肥', '石家庄'], ['北京', '石家庄', '太原', '郑州', '天津'], ['北京', '合肥', '南京', '武汉'], ['北京', '石家庄', '天津', '济南', '南昌'], ['北京', '石家庄', '武汉', '南京'], ['北京', '天津', '济南', '合肥', '南昌', '福州'], ['北京', '太原', '广州'], ['北京', '天津', '南京', '郑州'], ['北京', '天津', '石家庄', '郑州', '广州'], ['北京', '呼和浩特', '长沙'], ['北京', '天津', '合肥', '济南', '郑州'], ['北京', '武汉', '郑州', '南昌'], ['北京', '济南', '合肥', '南京', '武汉'], ['北京', '石家庄', '天津', '济南', '武汉'], ['北京', '天津', '济南', '南京', '石家庄'], ['北京', '南昌', '天津'], ['北京', '济南', '太原', '长沙'], ['北京', '武汉', '南昌', '广州'], ['北京', '石家庄', '太原', '广州'], ['北京', '石家庄', '合肥', '郑州'], ['北京', '天津', '南京', '合肥', '郑州'], ['北京', '天津', '合肥', '南昌', '济南'], ['北京', '太原', '石家庄', '合肥'], ['北京', '武汉', '郑州', '济南'], ['北京', '济南', '石家庄', '西安'], ['北京', '天津', '石家庄', '郑州', '西安'], ['北京', '天津', '郑州', '澳门'], ['北京', '济南', '武汉', '南京'], ['北京', '济南', '太原', '西安'], ['北京', '石家庄', '郑州', '太原', '济南'], ['北京', '石家庄', '南昌', '广州'], ['北京', '济南', '天津', '合肥', '郑州'], ['北京', '济南', '石家庄', '太原', '长沙'], ['北京', '天津', '南昌', '石家庄'], ['北京', '天津', '济南', '太原', '武汉'], ['北京', '天津', '南京', '合肥', '石家庄'], ['北京', '天津', '石家庄', '济南', '南昌'], ['北京', '石家庄', '济南', '天津', '郑州'], ['北京', '天津', '济南', '南昌', '石家庄'], ['北京', '济南', '石家庄', '太原', '西安'], ['北京', '天津', '郑州', '太原', '武汉'], ['北京', '武汉', '南昌', '澳门'], ['北京', '天津', '郑州', '香港'], ['北京', '郑州', '太原', '天津'], ['北京', '济南', '天津', '合肥', '石家庄'], ['北京', '郑州', '武汉', '南京'], ['北京', '合肥', '南昌', '石家庄'], ['北京', '天津', '济南', '石家庄', '太原', '武汉'], ['北京', '武汉', '长沙', '太原'], ['北京', '石家庄', '济南', '上海'], ['北京', '武汉', '福州'], ['北京', '武汉', '南昌', '福州'], ['北京', '天津', '呼和浩特', '西安'], ['北京', '石家庄', '南昌', '澳门'], ['北京', '天津', '石家庄', '济南', '武汉'], ['北京', '天津', '济南', '石家庄', '郑州', '合肥'], ['北京', '济南', '合肥', '南昌', '石家庄'], ['北京', '石家庄', '武汉', '天津'], ['北京', '石家庄', '南昌', '福州'], ['北京', '石家庄', '呼和浩特', '武汉'], ['北京', '郑州', '长沙', '太原'], ['北京', '呼和浩特', '太原', '长沙'], ['北京', '天津', '太原', '济南'], ['北京', '南昌', '太原'], ['北京', '天津', '南昌', '杭州'], ['北京', '天津', '济南', '南京', '郑州'], ['北京', '天津', '石家庄', '太原', '济南'], ['北京', '济南', '郑州', '澳门'], ['北京', '呼和浩特', '太原', '西安'], ['北京', '武汉', '南昌', '济南'], ['北京', '天津', '济南', '郑州', '广州'], ['北京', '天津', '济南', '南昌', '杭州'], ['北京', '石家庄', '武汉', '呼和浩特'], ['北京', '南京', '合肥', '上海'], ['北京', '济南', '武汉', '天津'], ['北京', '天津', '武汉', '南京'], ['北京', '天津', '合肥', '济南', '南昌'], ['北京', '石家庄', '郑州', '太原', '天津'], ['北京', '石家庄', '南昌', '济南'], ['北京', '合肥', '南昌', '杭州'], ['北京', '石家庄', '郑州', '武汉', '南京'], ['北京', '石家庄', '济南', '长沙'], ['北京', '济南', '郑州', '香港'], ['北京', '武汉', '西安'], ['北京', '济南', '南京', '合肥', '上海'], ['北京', '石家庄', '天津', '杭州'], ['北京', '天津', '郑州', '南京'], ['北京', '天津', '济南', '南京', '合肥', '郑州'], ['北京', '济南', '合肥', '南昌', '杭州'], ['北京', '天津', '济南', '郑州', '西安'], ['北京', '石家庄', '长沙', '太原'], ['北京', '郑州', '武汉', '天津'], ['北京', '天津', '合肥', '济南', '武汉'], ['北京', '济南', '南昌', '天津'], ['北京', '石家庄', '呼和浩特', '长沙'], ['北京', '石家庄', '郑州', '长沙', '太原'], ['北京', '天津', '济南', '南京', '合肥', '石家庄'], ['北京', '济南', '武汉', '呼和浩特'], ['北京', '天津', '石家庄', '郑州', '澳门'], ['北京', '天津', '合肥', '南京', '武汉'], ['北京', '太原', '石家庄', '长沙'], ['北京', '太原', '石家庄', '南昌'], ['北京', '郑州', '石家庄', '南京'], ['北京', '长沙', '石家庄'], ['北京', '天津', '济南', '合肥', '南京', '武汉'], ['北京', '石家庄', '济南', '福州'], ['北京', '郑州', '武汉', '呼和浩特'], ['北京', '太原', '澳门'], ['北京', '天津', '石家庄', '郑州', '香港'], ['北京', '天津', '济南', '太原', '长沙'], ['北京', '武汉', '郑州', '合肥'], ['北京', '石家庄', '合肥', '上海'], ['北京', '天津', '南京', '合肥', '上海'], ['北京', '太原', '呼和浩特', '武汉'], ['北京', '郑州', '太原', '南昌'], ['北京', '天津', '郑州', '太原', '长沙'], ['北京', '呼和浩特', '银川'], ['北京', '天津', '济南', '石家庄', '西安'], ['北京', '济南', '天津', '合肥', '上海'], ['北京', '杭州', '南昌'], ['北京', '天津', '济南', '武汉', '南京'], ['北京', '天津', '济南', '太原', '西安'], ['北京', '天津', '济南', '石家庄', '太原', '长沙'], ['北京', '石家庄', '郑州', '武汉', '天津'], ['北京', '天津', '郑州', '石家庄', '合肥'], ['北京', '济南', '郑州', '南京'], ['北京', '济南', '石家庄', '广州'], ['北京', '太原', '银川'], ['北京', '天津', '郑州', '太原', '西安'], ['北京', '石家庄', '太原', '澳门'], ['北京', '太原', '郑州', '广州'], ['北京', '合肥', '南京', '石家庄'], ['北京', '天津', '济南', '石家庄', '太原', '西安'], ['北京', '杭州', '济南'], ['北京', '石家庄', '太原', '呼和浩特', '武汉'], ['北京', '济南', '南昌', '太原'], ['北京', '南京', '长沙'], ['北京', '济南', '合肥', '南京', '石家庄'], ['北京', '合肥', '济南', '杭州'], ['北京', '济南', '杭州', '南昌'], ['北京', '天津', '合肥', '南昌', '石家庄'], ['北京', '石家庄', '济南', '呼和浩特'], ['北京', '南京', '杭州', '南昌'], ['北京', '济南', '石家庄', '郑州', '广州'], ['北京', '石家庄', '太原', '银川'], ['北京', '天津', '武汉', '呼和浩特'], ['北京', '石家庄', '郑州', '武汉', '呼和浩特'], ['北京', '天津', '济南', '合肥', '南昌', '石家庄'], ['北京', '石家庄', '太原', '郑州', '广州'], ['北京', '济南', '南京', '长沙'], ['北京', '南京', '合肥', '长沙'], ['北京', '太原', '郑州', '西安'], ['北京', '天津', '杭州', '南昌'], ['北京', '武汉', '长沙', '石家庄'], ['北京', '济南', '南京', '杭州', '南昌'], ['北京', '南京', '杭州', '济南'], ['北京', '太原', '呼和浩特', '长沙'], ['北京', '石家庄', '郑州', '太原', '南昌'], ['北京', '济南', '南京', '合肥', '长沙'], ['北京', '呼和浩特', '天津'], ['北京', '武汉', '郑州', '天津'], ['北京', '天津', '石家庄', '郑州', '南京'], ['北京', '合肥', '济南', '太原'], ['北京', '济南', '石家庄', '郑州', '西安'], ['北京', '天津', '杭州', '济南'], ['北京', '天津', '济南', '郑州', '澳门'], ['北京', '呼和浩特', '济南'], ['北京', '武汉', '杭州'], ['北京', '郑州', '长沙', '石家庄'], ['北京', '石家庄', '太原', '郑州', '西安'], ['北京', '济南', '郑州', '石家庄', '合肥'], ['北京', '石家庄', '天津', '济南', '杭州'], ['北京', '石家庄', '太原', '呼和浩特', '长沙'], ['北京', '天津', '济南', '郑州', '香港'], ['北京', '天津', '合肥', '南昌', '杭州'], ['北京', '石家庄', '天津', '呼和浩特'], ['北京', '天津', '济南', '南京', '合肥', '上海'], ['北京', '合肥', '南京', '郑州'], ['北京', '天津', '济南', '合肥', '南昌', '杭州'], ['北京', '天津', '南京', '长沙'], ['北京', '长沙', '合肥'], ['北京', '天津', '南京', '杭州', '南昌'], ['北京', '武汉', '南昌', '石家庄'], ['北京', '济南', '天津', '石家庄', '南京'], ['北京', '济南', '合肥', '南京', '郑州'], ['北京', '石家庄', '天津', '济南', '太原'], ['北京', '合肥', '南昌', '天津'], ['北京', '石家庄', '合肥', '长沙'], ['北京', '天津', '南京', '合肥', '长沙'], ['北京', '天津', '济南', '武汉', '呼和浩特'], ['北京', '天津', '太原', '南昌'], ['北京', '长沙', '西安'], ['北京', '天津', '石家庄', '太原', '南昌'], ['北京', '石家庄', '济南', '天津', '太原'], ['北京', '天津', '南京', '杭州', '济南'], ['北京', '郑州', '太原', '合肥'], ['北京', '济南', '天津', '合肥', '长沙'], ['北京', '天津', '石家庄', '济南', '杭州'], ['北京', '济南', '合肥', '南昌', '天津'], ['北京', '石家庄', '济南', '天津', '武汉'], ['北京', '石家庄', '呼和浩特', '银川'], ['北京', '石家庄', '武汉', '福州'], ['北京', '天津', '郑州', '石家庄', '长沙'], ['北京', '天津', '郑州', '石家庄', '南昌'], ['北京', '石家庄', '天津', '上海'], ['北京', '天津', '石家庄', '济南', '太原'], ['北京', '天津', '济南', '郑州', '南京'], ['北京', '天津', '济南', '石家庄', '广州'], ['北京', '武汉', '南昌', '杭州'], ['北京', '太原', '郑州', '澳门'], ['北京', '南昌', '上海'], ['北京', '天津', '南昌', '太原'], ['北京', '武汉', '长沙', '合肥'], ['北京', '济南', '武汉', '福州'], ['北京', '石家庄', '南昌', '杭州'], ['北京', '石家庄', '济南', '天津', '南昌'], ['北京', '天津', '合肥', '南京', '石家庄'], ['北京', '天津', '济南', '南昌', '太原'], ['北京', '石家庄', '郑州', '太原', '合肥'], ['北京', '呼和浩特', '太原', '济南'], ['北京', '天津', '济南', '合肥', '南京', '石家庄'], ['北京', '天津', '济南', '杭州', '南昌'], ['北京', '合肥', '南昌', '太原'], ['北京', '济南', '石家庄', '郑州', '澳门'], ['北京', '太原', '郑州', '香港'], ['北京', '武汉', '长沙', '西安'], ['北京', '天津', '济南', '石家庄', '郑州', '广州'], ['北京', '天津', '合肥', '济南', '杭州'], ['北京', '济南', '太原', '天津'], ['北京', '石家庄', '呼和浩特', '天津'], ['北京', '郑州', '长沙', '合肥'], ['北京', '石家庄', '太原', '郑州', '澳门'], ['北京', '郑州', '武汉', '福州'], ['北京', '石家庄', '武汉', '西安'], ['北京', '天津', '济南', '南京', '长沙'], ['北京', '天津', '济南', '南京', '杭州', '南昌'], ['北京', '石家庄', '呼和浩特', '济南'], ['北京', '济南', '合肥', '南昌', '太原'], ['北京', '济南', '郑州', '石家庄', '长沙'], ['北京', '济南', '郑州', '石家庄', '南昌'], ['北京', '济南', '石家庄', '郑州', '香港'], ['北京', '济南', '石家庄', '太原', '天津'], ['北京', '天津', '济南', '南京', '合肥', '长沙'], ['北京', '郑州', '长沙', '西安'], ['北京', '石家庄', '太原', '郑州', '香港'], ['北京', '郑州', '石家庄', '西安'], ['北京', '天津', '济南', '石家庄', '郑州', '西安'], ['北京', '天津', '合肥', '济南', '太原'], ['北京', '太原', '呼和浩特', '银川'], ['北京', '济南', '武汉', '西安'], ['北京', '天津', '太原', '合肥'], ['北京', '石家庄', '长沙', '合肥'], ['北京', '天津', '石家庄', '太原', '合肥'], ['北京', '济南', '天津', '南京', '武汉'], ['北京', '天津', '武汉', '福州'], ['北京', '石家庄', '郑州', '长沙', '合肥'], ['北京', '天津', '合肥', '南京', '郑州'], ['北京', '石家庄', '郑州', '武汉', '福州'], ['北京', '郑州', '武汉', '西安'], ['北京', '呼和浩特', '太原', '天津'], ['北京', '石家庄', '太原', '呼和浩特', '银川'], ['北京', '太原', '郑州', '南京'], ['北京', '石家庄', '长沙', '西安'], ['北京', '长沙', '呼和浩特'], ['北京', '天津', '济南', '合肥', '南京', '郑州'], ['北京', '郑州', '太原', '广州'], ['北京', '石家庄', '郑州', '长沙', '西安'], ['北京', '天津', '郑州', '太原', '济南'], ['北京', '济南', '石家庄', '郑州', '南京'], ['北京', '济南', '南昌', '上海'], ['北京', '南京', '合肥', '香港'], ['北京', '石家庄', '太原', '郑州', '南京'], ['北京', '长沙', '南宁'], ['北京', '太原', '呼和浩特', '天津'], ['北京', '武汉', '郑州', '广州'], ['北京', '太原', '石家庄', '南京'], ['北京', '济南', '南京', '合肥', '香港'], ['北京', '太原', '呼和浩特', '济南'], ['北京', '石家庄', '济南', '天津', '杭州'], ['北京', '天津', '武汉', '西安'], ['北京', '石家庄', '郑州', '武汉', '西安'], ['北京', '杭州', '天津'], ['北京', '呼和浩特', '重庆'], ['北京', '石家庄', '太原', '呼和浩特', '天津'], ['北京', '济南', '太原', '南昌'], ['北京', '武汉', '郑州', '西安'], ['北京', '石家庄', '郑州', '太原', '广州'], ['北京', '天津', '济南', '武汉', '福州'], ['北京', '石家庄', '太原', '呼和浩特', '济南'], ['北京', '石家庄', '武汉', '杭州'], ['北京', '合肥', '济南', '上海'], ['北京', '武汉', '长沙', '呼和浩特'], ['北京', '石家庄', '天津', '长沙'], ['北京', '济南', '石家庄', '太原', '南昌'], ['北京', '天津', '济南', '石家庄', '郑州', '澳门'], ['北京', '武汉', '南昌', '天津'], ['北京', '天津', '合肥', '南昌', '太原'], ['北京', '济南', '天津', '石家庄', '西安'], ['北京', '济南', '杭州', '天津'], ['北京', '南京', '杭州', '天津'], ['北京', '天津', '济南', '合肥', '南昌', '太原'], ['北京', '石家庄', '合肥', '香港'], ['北京', '天津', '南京', '合肥', '香港'], ['北京', '郑州', '长沙', '呼和浩特'], ['北京', '石家庄', '南昌', '天津'], ['北京', '武汉', '长沙', '南宁'], ['北京', '南京', '合肥', '太原'], ['北京', '天津', '济南', '石家庄', '郑州', '香港'], ['北京', '济南', '天津', '合肥', '香港'], ['北京', '济南', '南京', '杭州', '天津'], ['北京', '济南', '武汉', '杭州'], ['北京', '天津', '呼和浩特', '武汉'], ['北京', '济南', '南京', '合肥', '太原'], ['北京', '石家庄', '天津', '济南', '上海'], ['北京', '郑州', '石家庄', '广州'], ['北京', '合肥', '南京', '长沙'], ['北京', '郑州', '长沙', '南宁'], ['北京', '天津', '太原', '广州'], ['北京', '天津', '济南', '武汉', '西安'], ['北京', '呼和浩特', '太原', '南昌'], ['北京', '合肥', '济南', '长沙'], ['北京', '天津', '石家庄', '太原', '广州'], ['北京', '郑州', '武汉', '杭州'], ['北京', '济南', '合肥', '南京', '长沙'], ['北京', '南京', '合肥', '广州'], ['北京', '石家庄', '长沙', '呼和浩特'], ['北京', '长沙', '济南'], ['北京', '石家庄', '郑州', '长沙', '呼和浩特'], ['北京', '济南', '南京', '合肥', '广州'], ['北京', '武汉', '南昌', '太原'], ['北京', '天津', '石家庄', '济南', '上海'], ['北京', '天津', '呼和浩特', '长沙'], ['北京', '石家庄', '合肥', '太原'], ['北京', '天津', '南京', '合肥', '太原'], ['北京', '天津', '南昌', '上海'], ['北京', '石家庄', '长沙', '南宁'], ['北京', '石家庄', '南昌', '太原'], ['北京', '天津', '济南', '石家庄', '郑州', '南京'], ['北京', '石家庄', '天津', '济南', '长沙'], ['北京', '南京', '合肥', '澳门'], ['北京', '天津', '济南', '南昌', '上海'], ['北京', '济南', '天津', '合肥', '太原'], ['北京', '合肥', '济南', '福州'], ['北京', '郑州', '太原', '澳门'], ['北京', '石家庄', '郑州', '长沙', '南宁'], ['北京', '天津', '武汉', '杭州'], ['北京', '武汉', '郑州', '澳门'], ['北京', '合肥', '南昌', '上海'], ['北京', '济南', '太原', '合肥'], ['北京', '石家庄', '郑州', '武汉', '杭州'], ['北京', '济南', '南京', '合肥', '澳门'], ['北京', '石家庄', '呼和浩特', '重庆'], ['北京', '天津', '济南', '南京', '合肥', '香港'], ['北京', '济南', '天津', '南京', '石家庄'], ['北京', '济南', '合肥', '南昌', '上海'], ['北京', '天津', '郑州', '石家庄', '南京'], ['北京', '石家庄', '济南', '天津', '呼和浩特'], ['北京', '济南', '石家庄', '太原', '合肥'], ['北京', '郑州', '太原', '银川'], ['北京', '武汉', '郑州', '香港'], ['北京', '石家庄', '合肥', '广州'], ['北京', '天津', '南京', '合肥', '广州'], ['北京', '天津', '济南', '太原', '南昌'], ['北京', '济南', '天津', '合肥', '广州'], ['北京', '武汉', '长沙', '济南'], ['北京', '天津', '石家庄', '济南', '长沙'], ['北京', '天津', '郑州', '太原', '南昌'], ['北京', '石家庄', '天津', '济南', '福州'], ['北京', '合肥', '济南', '呼和浩特'], ['北京', '天津', '济南', '石家庄', '太原', '南昌'], ['北京', '天津', '合肥', '济南', '上海'], ['北京', '石家庄', '郑州', '太原', '澳门'], ['北京', '郑州', '长沙', '济南'], ['北京', '石家庄', '合肥', '澳门'], ['北京', '天津', '南京', '合肥', '澳门'], ['北京', '济南', '天津', '石家庄', '广州'], ['北京', '呼和浩特', '太原', '合肥'], ['北京', '济南', '天津', '合肥', '澳门'], ['北京', '天津', '济南', '武汉', '杭州'], ['北京', '石家庄', '郑州', '太原', '银川'], ['北京', '石家庄', '济南', '天津', '上海'], ['北京', '天津', '济南', '南京', '合肥', '太原'], ['北京', '济南', '郑州', '石家庄', '南京'], ['北京', '天津', '石家庄', '济南', '福州'], ['北京', '济南', '天津', '南京', '郑州'], ['北京', '石家庄', '天津', '济南', '呼和浩特'], ['北京', '太原', '石家庄', '西安'], ['北京', '武汉', '郑州', '南京'], ['北京', '天津', '合肥', '南京', '长沙'], ['北京', '天津', '济南', '合肥', '南京', '长沙'], ['北京', '天津', '合肥', '济南', '长沙'], ['北京', '石家庄', '长沙', '济南'], ['北京', '太原', '呼和浩特', '重庆'], ['北京', '天津', '太原', '澳门'], ['北京', '石家庄', '郑州', '长沙', '济南'], ['北京', '天津', '石家庄', '太原', '澳门'], ['北京', '天津', '济南', '南京', '合肥', '广州'], ['北京', '石家庄', '太原', '呼和浩特', '重庆'], ['北京', '杭州', '武汉'], ['北京', '天津', '太原', '银川'], ['北京', '天津', '石家庄', '济南', '呼和浩特'], ['北京', '天津', '石家庄', '太原', '银川'], ['北京', '济南', '太原', '广州'], ['北京', '天津', '合肥', '济南', '福州'], ['北京', '天津', '济南', '太原', '合肥'], ['北京', '天津', '济南', '南京', '合肥', '澳门'], ['北京', '天津', '呼和浩特', '银川'], ['北京', '天津', '合肥', '南昌', '上海'], ['北京', '济南', '石家庄', '太原', '广州'], ['北京', '天津', '郑州', '太原', '合肥'], ['北京', '济南', '杭州', '武汉'], ['北京', '南京', '杭州', '武汉'], ['北京', '天津', '济南', '合肥', '南昌', '上海'], ['北京', '天津', '济南', '石家庄', '太原', '合肥'], ['北京', '天津', '杭州', '武汉'], ['北京', '济南', '南京', '杭州', '武汉'], ['北京', '天津', '合肥', '济南', '呼和浩特'], ['北京', '呼和浩特', '太原', '广州'], ['北京', '长沙', '南京'], ['北京', '天津', '呼和浩特', '济南'], ['北京', '天津', '南京', '杭州', '武汉'], ['北京', '武汉', '南昌', '上海'], ['北京', '石家庄', '南昌', '上海'], ['北京', '太原', '石家庄', '广州'], ['北京', '天津', '郑州', '石家庄', '西安'], ['北京', '石家庄', '济南', '天津', '长沙'], ['北京', '武汉', '长沙', '南京'], ['北京', '天津', '济南', '太原', '广州'], ['北京', '长沙', '天津'], ['北京', '天津', '郑州', '太原', '广州'], ['北京', '郑州', '长沙', '南京'], ['北京', '天津', '济南', '石家庄', '太原', '广州'], ['北京', '天津', '济南', '杭州', '武汉'], ['北京', '济南', '太原', '澳门'], ['北京', '济南', '郑州', '石家庄', '西安'], ['北京', '天津', '济南', '南京', '杭州', '武汉'], ['北京', '济南', '石家庄', '太原', '澳门'], ['北京', '济南', '太原', '银川'], ['北京', '石家庄', '长沙', '南京'], ['北京', '济南', '石家庄', '太原', '银川'], ['北京', '石家庄', '郑州', '长沙', '南京'], ['北京', '武汉', '长沙', '天津'], ['北京', '济南', '天津', '南京', '长沙'], ['北京', '呼和浩特', '太原', '澳门'], ['北京', '郑州', '长沙', '天津'], ['北京', '呼和浩特', '太原', '银川'], ['北京', '天津', '郑州', '石家庄', '广州'], ['北京', '石家庄', '长沙', '天津'], ['北京', '石家庄', '郑州', '长沙', '天津'], ['北京', '天津', '济南', '太原', '澳门'], ['北京', '天津', '呼和浩特', '重庆'], ['北京', '天津', '郑州', '太原', '澳门'], ['北京', '济南', '郑州', '石家庄', '广州'], ['北京', '天津', '济南', '石家庄', '太原', '澳门'], ['北京', '天津', '济南', '太原', '银川'], ['北京', '天津', '郑州', '太原', '银川'], ['北京', '天津', '济南', '石家庄', '太原', '银川']]\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['北京', '天津', '上海']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfs_2(cities_connection,\"北京\",\"上海\",search_strategy=sort_by_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京', '石家庄']\n",
      "['北京', '武汉']\n",
      "['北京', '郑州']\n",
      "['北京', '济南']\n",
      "['北京', '南京']\n",
      "['北京', '合肥']\n",
      "['北京', '杭州']\n",
      "['北京', '南昌']\n",
      "['北京', '长沙']\n",
      "['北京', '太原']\n",
      "['北京', '天津']\n",
      "['北京', '呼和浩特']\n",
      "['北京', '石家庄', '武汉']\n",
      "['北京', '石家庄', '郑州']\n",
      "['北京', '石家庄', '济南']\n",
      "['北京', '石家庄', '南京']\n",
      "['北京', '石家庄', '合肥']\n",
      "['北京', '石家庄', '南昌']\n",
      "['北京', '石家庄', '广州']\n",
      "['北京', '石家庄', '长沙']\n",
      "['北京', '石家庄', '太原']\n",
      "['北京', '石家庄', '西安']\n",
      "['北京', '石家庄', '天津']\n",
      "['北京', '石家庄', '呼和浩特']\n",
      "['北京', '武汉', '石家庄']\n",
      "['北京', '武汉', '郑州']\n",
      "['北京', '武汉', '济南']\n",
      "['北京', '武汉', '南京']\n",
      "['北京', '武汉', '合肥']\n",
      "['北京', '武汉', '杭州']\n",
      "['北京', '武汉', '南昌']\n",
      "['北京', '武汉', '福州']\n",
      "['北京', '武汉', '广州']\n",
      "['北京', '武汉', '长沙']\n",
      "['北京', '武汉', '太原']\n",
      "['北京', '武汉', '西安']\n",
      "['北京', '武汉', '天津']\n",
      "['北京', '武汉', '呼和浩特']\n",
      "['北京', '武汉', '香港']\n",
      "['北京', '武汉', '澳门']\n",
      "['北京', '郑州', '石家庄']\n",
      "['北京', '郑州', '武汉']\n",
      "['北京', '郑州', '济南']\n",
      "['北京', '郑州', '南京']\n",
      "['北京', '郑州', '合肥']\n",
      "['北京', '郑州', '南昌']\n",
      "['北京', '郑州', '广州']\n",
      "['北京', '郑州', '长沙']\n",
      "['北京', '郑州', '太原']\n",
      "['北京', '郑州', '西安']\n",
      "['北京', '郑州', '天津']\n",
      "['北京', '郑州', '呼和浩特']\n",
      "['北京', '郑州', '香港']\n",
      "['北京', '郑州', '澳门']\n",
      "['北京', '济南', '石家庄']\n",
      "['北京', '济南', '武汉']\n",
      "['北京', '济南', '郑州']\n",
      "['北京', '济南', '南京']\n",
      "['北京', '济南', '合肥']\n",
      "['北京', '济南', '杭州']\n",
      "['北京', '济南', '南昌']\n",
      "['北京', '济南', '福州']\n",
      "['北京', '济南', '长沙']\n",
      "['北京', '济南', '太原']\n",
      "['北京', '济南', '上海']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['北京', '济南', '上海']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfs(cities_connection,\"北京\",\"上海\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752.66259009181"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distance_of_path([\"北京\",\"济南\",\"上海\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732.5085345714293"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distance_of_path([\"北京\",\"天津\",\"上海\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS是没有重排序的，优化就是重排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "1 5\n",
      "2 6\n",
      "3 7\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate([4,5,6,7]):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_3(graph,start,destination,search_strategy):\n",
    "    #这是个有问题的\n",
    "        pathes = [[start]]\n",
    "        visited = set()\n",
    "        while pathes:\n",
    "            print(pathes[0])\n",
    "            path = pathes.pop(0)\n",
    "            froniter = path[-1]\n",
    "            if froniter in visited:continue\n",
    "            successors = graph[froniter]\n",
    "            for city in successors:\n",
    "                if city in path: continue\n",
    "                new_path = path+[city]\n",
    "                pathes.append(new_path)\n",
    "\n",
    "            pathes = search_strategy(pathes)\n",
    "            # visit add\n",
    "            if pathes and pathes[0][-1] == destination:# 这条路径经过重排序之后是最短的，有可能重排序前的第一个最后一个是目标地址，但是visited就添加了它，导致后面所有数据跳过\n",
    "#                 print(pathes)\n",
    "#                 print(\"--------------------------------------\")\n",
    "                return pathes[0]\n",
    "            visited.add(froniter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['上海']\n",
      "['上海', '杭州']\n",
      "['上海', '南京']\n",
      "['上海', '杭州', '南京']\n",
      "['上海', '福州']\n",
      "['上海', '杭州', '福州']\n",
      "['上海', '合肥']\n",
      "['上海', '南京', '合肥']\n",
      "['上海', '南京', '杭州']\n",
      "['上海', '杭州', '合肥']\n",
      "['上海', '济南']\n",
      "['上海', '南京', '济南']\n",
      "['上海', '福州', '杭州']\n",
      "['上海', '南京', '福州']\n",
      "['上海', '南昌']\n",
      "['上海', '合肥', '南京']\n",
      "['上海', '杭州', '南昌']\n",
      "['上海', '天津']\n",
      "['上海', '杭州', '济南']\n",
      "['上海', '沈阳']\n",
      "['上海', '南京', '南昌']\n",
      "['上海', '合肥', '南昌']\n",
      "['上海', '福州', '南京']\n",
      "['上海', '济南', '天津']\n",
      "['上海', '南京', '天津']\n",
      "['上海', '合肥', '济南']\n",
      "['上海', '杭州', '天津']\n",
      "['上海', '天津', '北京']\n",
      "['上海', '济南', '北京']\n",
      "['上海', '福州', '合肥']\n",
      "['上海', '天津', '济南']\n",
      "['上海', '福州', '南昌']\n",
      "['上海', '南京', '北京']\n",
      "['上海', '合肥', '武汉']\n",
      "['上海', '合肥', '杭州']\n",
      "['上海', '南京', '武汉']\n",
      "['上海', '杭州', '武汉']\n",
      "['上海', '杭州', '北京']\n",
      "['上海', '济南', '合肥']\n",
      "['上海', '南昌', '武汉']\n",
      "['上海', '合肥', '天津']\n",
      "['上海', '合肥', '福州']\n",
      "['上海', '南昌', '合肥']\n",
      "['上海', '济南', '石家庄']\n",
      "['上海', '南京', '石家庄']\n",
      "['上海', '合肥', '北京']\n",
      "['上海', '济南', '南京']\n",
      "['上海', '南京', '郑州']\n",
      "['上海', '合肥', '郑州']\n",
      "['上海', '合肥', '石家庄']\n",
      "['上海', '天津', '北京', '济南']\n",
      "['上海', '沈阳', '长春']\n",
      "['上海', '天津', '石家庄']\n",
      "['上海', '南昌', '长沙']\n",
      "['上海', '济南', '郑州']\n",
      "['上海', '天津', '北京', '石家庄']\n",
      "['上海', '南京', '长沙']\n",
      "['上海', '合肥', '长沙']\n",
      "['上海', '福州', '武汉']\n",
      "['上海', '福州', '香港']\n",
      "['上海', '合肥', '武汉', '长沙']\n",
      "['上海', '福州', '济南']\n",
      "['上海', '济南', '南昌']\n",
      "['上海', '南昌', '香港']\n",
      "['上海', '济南', '武汉']\n",
      "['上海', '南昌', '南京']\n",
      "['上海', '合肥', '武汉', '南昌']\n",
      "['上海', '合肥', '武汉', '郑州']\n",
      "['上海', '天津', '合肥']\n",
      "['上海', '南昌', '郑州']\n",
      "['上海', '南昌', '广州']\n",
      "['上海', '南昌', '澳门']\n",
      "['上海', '南昌', '福州']\n",
      "['上海', '济南', '石家庄', '郑州']\n",
      "['上海', '合肥', '香港']\n",
      "['上海', '福州', '澳门']\n",
      "['上海', '福州', '香港', '澳门']\n",
      "['上海', '南昌', '济南']\n",
      "['上海', '天津', '南京']\n",
      "['上海', '南京', '郑州', '石家庄']\n",
      "['上海', '合肥', '太原']\n",
      "['上海', '福州', '广州']\n",
      "['上海', '济南', '杭州']\n",
      "['上海', '南京', '郑州', '太原']\n",
      "['上海', '合肥', '广州']\n",
      "['上海', '济南', '太原']\n",
      "['上海', '南昌', '广州', '澳门']\n",
      "['上海', '济南', '石家庄', '太原']\n",
      "['上海', '天津', '郑州']\n",
      "['上海', '合肥', '澳门']\n",
      "['上海', '福州', '香港', '广州']\n",
      "['上海', '南昌', '澳门', '广州']\n",
      "['上海', '南京', '郑州', '武汉']\n",
      "['上海', '济南', '石家庄', '北京']\n",
      "['上海', '沈阳', '哈尔滨']\n",
      "['上海', '南昌', '石家庄']\n",
      "['上海', '南昌', '澳门', '香港']\n",
      "['上海', '沈阳', '长春', '哈尔滨']\n",
      "['上海', '南昌', '杭州']\n",
      "['上海', '天津', '北京', '郑州']\n",
      "['上海', '南昌', '长沙', '武汉']\n",
      "['上海', '南昌', '广州', '香港']\n",
      "['上海', '天津', '北京', '合肥']\n",
      "['上海', '合肥', '武汉', '石家庄']\n",
      "['上海', '合肥', '武汉', '广州']\n",
      "['上海', '天津', '太原']\n",
      "['上海', '天津', '武汉']\n",
      "['上海', '济南', '长沙']\n",
      "['上海', '济南', '石家庄', '天津']\n",
      "['上海', '南昌', '天津']\n",
      "['上海', '天津', '北京', '太原']\n",
      "['上海', '天津', '南昌']\n",
      "['上海', '南昌', '长沙', '广州']\n",
      "['上海', '合肥', '武汉', '香港']\n",
      "['上海', '合肥', '武汉', '太原']\n",
      "['上海', '南京', '郑州', '长沙']\n",
      "['上海', '济南', '福州']\n",
      "['上海', '合肥', '武汉', '澳门']\n",
      "['上海', '南昌', '北京']\n",
      "['上海', '南昌', '太原']\n",
      "['上海', '济南', '呼和浩特']\n",
      "['上海', '济南', '石家庄', '呼和浩特']\n",
      "['上海', '济南', '石家庄', '武汉']\n",
      "['上海', '天津', '北京', '南京']\n",
      "['上海', '天津', '杭州']\n",
      "['上海', '合肥', '太原', '呼和浩特']\n",
      "['上海', '合肥', '武汉', '济南']\n",
      "['上海', '南昌', '长沙', '澳门']\n",
      "['上海', '南京', '郑州', '呼和浩特']\n",
      "['上海', '天津', '北京', '武汉']\n",
      "['上海', '南昌', '广州', '长沙']\n",
      "['上海', '合肥', '太原', '郑州']\n",
      "['上海', '南昌', '长沙', '香港']\n",
      "['上海', '南昌', '长沙', '郑州']\n",
      "['上海', '天津', '呼和浩特']\n",
      "['上海', '南京', '郑州', '南昌']\n",
      "['上海', '天津', '北京', '呼和浩特']\n",
      "['上海', '福州', '香港', '长沙']\n",
      "['上海', '南京', '郑州', '济南']\n",
      "['上海', '合肥', '太原', '石家庄']\n",
      "['上海', '南京', '郑州', '北京']\n",
      "['上海', '天津', '北京', '南昌']\n",
      "['上海', '沈阳', '哈尔滨', '长春']\n",
      "['上海', '济南', '石家庄', '合肥']\n",
      "['上海', '南昌', '澳门', '长沙']\n",
      "['上海', '合肥', '武汉', '南京']\n",
      "['上海', '合肥', '武汉', '北京']\n",
      "['上海', '南京', '郑州', '合肥']\n",
      "['上海', '合肥', '武汉', '天津']\n",
      "['上海', '福州', '香港', '南昌']\n",
      "['上海', '天津', '长沙']\n",
      "['上海', '济南', '石家庄', '长沙']\n",
      "['上海', '济南', '石家庄', '南昌']\n",
      "['上海', '南京', '郑州', '天津']\n",
      "['上海', '合肥', '武汉', '呼和浩特']\n",
      "['上海', '福州', '香港', '武汉']\n",
      "['上海', '济南', '呼和浩特', '太原']\n",
      "['上海', '南昌', '长沙', '太原']\n",
      "['上海', '南昌', '广州', '武汉']\n",
      "['上海', '天津', '北京', '杭州']\n",
      "['上海', '天津', '北京', '长沙']\n",
      "['上海', '合肥', '武汉', '福州']\n",
      "['上海', '南京', '郑州', '广州']\n",
      "['上海', '南京', '郑州', '西安']\n",
      "['上海', '南昌', '澳门', '武汉']\n",
      "['上海', '合肥', '武汉', '西安']\n",
      "['上海', '南昌', '长沙', '石家庄']\n",
      "['上海', '济南', '石家庄', '南京']\n",
      "['上海', '合肥', '太原', '武汉']\n",
      "['上海', '南京', '郑州', '澳门']\n",
      "['上海', '南京', '郑州', '香港']\n",
      "['上海', '合肥', '武汉', '杭州']\n",
      "['上海', '南昌', '长沙', '合肥']\n",
      "['上海', '南昌', '长沙', '西安']\n",
      "['上海', '合肥', '太原', '长沙']\n",
      "['上海', '合肥', '太原', '西安']\n",
      "['上海', '济南', '石家庄', '西安']\n",
      "['上海', '南昌', '长沙', '呼和浩特']\n",
      "['上海', '合肥', '太原', '北京']\n",
      "['上海', '南昌', '长沙', '南宁']\n",
      "['上海', '济南', '呼和浩特', '石家庄']\n",
      "['上海', '南昌', '广州', '郑州']\n",
      "['上海', '福州', '香港', '郑州']\n",
      "['上海', '济南', '呼和浩特', '郑州']\n",
      "['上海', '济南', '石家庄', '广州']\n",
      "['上海', '南昌', '长沙', '济南']\n",
      "['上海', '福州', '香港', '合肥']\n",
      "['上海', '合肥', '太原', '济南']\n",
      "['上海', '南昌', '广州', '南宁']\n",
      "['上海', '合肥', '太原', '天津']\n",
      "['上海', '南昌', '澳门', '郑州']\n",
      "['上海', '济南', '呼和浩特', '西安']\n",
      "['上海', '南昌', '澳门', '南宁']\n",
      "['上海', '南昌', '长沙', '北京']\n",
      "['上海', '合肥', '太原', '南昌']\n",
      "['上海', '南昌', '长沙', '南京']\n",
      "['上海', '福州', '香港', '南宁']\n",
      "['上海', '南昌', '广州', '合肥']\n",
      "['上海', '南昌', '长沙', '天津']\n",
      "['上海', '南昌', '澳门', '合肥']\n",
      "['上海', '南昌', '广州', '太原']\n",
      "['上海', '南昌', '广州', '西安']\n",
      "['上海', '南昌', '澳门', '福州']\n",
      "['上海', '合肥', '太原', '广州']\n",
      "['上海', '南昌', '广州', '石家庄']\n",
      "['上海', '南昌', '广州', '福州']\n",
      "['上海', '南京', '郑州', '西安', '重庆']\n",
      "['上海', '南昌', '澳门', '太原']\n",
      "['上海', '南昌', '长沙', '南宁', '贵阳']\n",
      "['上海', '济南', '呼和浩特', '武汉']\n",
      "['上海', '济南', '呼和浩特', '北京']\n",
      "['上海', '南京', '郑州', '西安', '银川']\n",
      "['上海', '济南', '呼和浩特', '长沙']\n",
      "['上海', '合肥', '太原', '澳门']\n",
      "['上海', '合肥', '太原', '银川']\n",
      "['上海', '南京', '郑州', '西安', '贵阳']\n",
      "['上海', '南京', '郑州', '西安', '呼和浩特']\n",
      "['上海', '济南', '呼和浩特', '银川']\n",
      "['上海', '南昌', '长沙', '南宁', '重庆']\n",
      "['上海', '南京', '郑州', '西安', '重庆', '贵阳']\n",
      "['上海', '南京', '郑州', '西安', '南宁']\n",
      "['上海', '济南', '呼和浩特', '天津']\n",
      "['上海', '南京', '郑州', '西安', '太原']\n",
      "['上海', '南昌', '长沙', '南宁', '贵阳', '重庆']\n",
      "['上海', '济南', '呼和浩特', '重庆']\n",
      "['上海', '南京', '郑州', '西安', '长沙']\n",
      "['上海', '南昌', '长沙', '南宁', '西安']\n",
      "['上海', '南京', '郑州', '西安', '成都']\n",
      "['上海', '南京', '郑州', '西安', '兰州']\n",
      "['上海', '南京', '郑州', '西安', '重庆', '成都']\n",
      "['上海', '南京', '郑州', '西安', '重庆', '银川']\n",
      "['上海', '南京', '郑州', '西安', '银川', '重庆']\n",
      "['上海', '南京', '郑州', '西安', '重庆', '南宁']\n",
      "['上海', '南京', '郑州', '西安', '武汉']\n",
      "['上海', '南京', '郑州', '西安', '银川', '兰州']\n",
      "['上海', '南京', '郑州', '西安', '石家庄']\n",
      "['上海', '南昌', '长沙', '南宁', '成都']\n",
      "['上海', '南昌', '长沙', '南宁', '贵阳', '成都']\n",
      "['上海', '南京', '郑州', '西安', '广州']\n",
      "['上海', '南昌', '长沙', '南宁', '广州']\n",
      "['上海', '南京', '郑州', '西安', '银川', '成都']\n",
      "['上海', '南昌', '长沙', '南宁', '银川']\n",
      "['上海', '南京', '郑州', '西安', '重庆', '兰州']\n",
      "['上海', '南昌', '长沙', '南宁', '澳门']\n",
      "['上海', '南昌', '长沙', '南宁', '贵阳', '西安']\n",
      "['上海', '南昌', '长沙', '南宁', '贵阳', '银川']\n",
      "['上海', '南京', '郑州', '西安', '成都', '兰州']\n",
      "['上海', '南京', '郑州', '西安', '银川', '贵阳']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '成都']\n",
      "['上海', '南昌', '长沙', '南宁', '拉萨']\n",
      "['上海', '南京', '郑州', '西安', '重庆', '拉萨']\n",
      "['上海', '南昌', '长沙', '南宁', '兰州']\n",
      "['上海', '南昌', '长沙', '南宁', '贵阳', '兰州']\n",
      "['上海', '南昌', '长沙', '南宁', '香港']\n",
      "['上海', '南京', '郑州', '西安', '成都', '拉萨']\n",
      "['上海', '南昌', '长沙', '南宁', '贵阳', '拉萨']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '西宁']\n",
      "['上海', '南京', '郑州', '西安', '成都', '重庆']\n",
      "['上海', '南京', '郑州', '西安', '银川', '西宁']\n",
      "['上海', '南京', '郑州', '西安', '成都', '西宁']\n",
      "['上海', '南京', '郑州', '西安', '银川', '拉萨']\n",
      "['上海', '南京', '郑州', '西安', '成都', '贵阳']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '银川']\n",
      "['上海', '南京', '郑州', '西安', '重庆', '西宁']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '拉萨']\n",
      "['上海', '南京', '郑州', '西安', '成都', '银川']\n",
      "['上海', '南京', '郑州', '西安', '银川', '南宁']\n",
      "['上海', '南京', '郑州', '西安', '银川', '呼和浩特']\n",
      "['上海', '南昌', '长沙', '南宁', '拉萨', '成都']\n",
      "['上海', '南昌', '长沙', '南宁', '贵阳', '西宁']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '重庆']\n",
      "['上海', '南京', '郑州', '西安', '重庆', '呼和浩特']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '贵阳']\n",
      "['上海', '南昌', '长沙', '南宁', '拉萨', '西宁']\n",
      "['上海', '南京', '郑州', '西安', '银川', '太原']\n",
      "['上海', '南昌', '长沙', '南宁', '拉萨', '兰州']\n",
      "['上海', '南京', '郑州', '西安', '成都', '南宁']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '西宁', '拉萨']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '西宁', '成都']\n",
      "['上海', '南昌', '长沙', '南宁', '拉萨', '重庆']\n",
      "['上海', '南昌', '长沙', '南宁', '拉萨', '贵阳']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '嘉峪关']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '西宁', '嘉峪关']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '南宁']\n",
      "['上海', '南京', '郑州', '西安', '成都', '嘉峪关']\n",
      "['上海', '南昌', '长沙', '南宁', '拉萨', '银川']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '西宁', '银川']\n",
      "['上海', '南昌', '长沙', '南宁', '拉萨', '嘉峪关']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '西宁', '重庆']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '西宁', '贵阳']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '嘉峪关', '西宁']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '嘉峪关', '拉萨']\n",
      "['上海', '南京', '郑州', '西安', '兰州', '嘉峪关', '成都']\n"
     ]
    }
   ],
   "source": [
    "bfs_3(cities_connection,\"上海\",\"香港\",search_strategy=sort_by_distance)#寻找不到路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dataset['data'],dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "       6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "       1.7800e+01, 3.9690e+02, 9.1400e+00])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rm = x[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bd7e7b8748>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the RM with respect to y\n",
    "plt.scatter(X_rm,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price(rm,k,b):\n",
    "    return k*rm+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y,y_hat):\n",
    "        return sum((y_i - y_hat_i)**2 for y_i, y_hat_i in zip(list(y),list(y_hat)))/len(list(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 补梯度公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define partial derivative \n",
    "def partial_derivative_k(x, y, y_hat):\n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for x_i, y_i, y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "        gradient += (y_i-y_hat_i) * x_i\n",
    "    return -2/n * gradient\n",
    "\n",
    "def partial_derivative_b(y, y_hat):\n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for y_i, y_hat_i in zip(list(y),list(y_hat)):\n",
    "        gradient += (y_i-y_hat_i)\n",
    "    return -2 / n * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, the loss is 285319.57217149396, parameters k is -66.73479606286645 and b is -89.51646899933365\n",
      "Iteration 1, the loss is 240479.6842937369, parameters k is -59.9800906306246 and b is -88.45356286034757\n",
      "Iteration 2, the loss is 202688.29692637632, parameters k is -53.77897736752455 and b is -87.47768424171126\n",
      "Iteration 3, the loss is 170837.43761569535, parameters k is -48.08608684737786 and b is -86.5817008396185\n",
      "Iteration 4, the loss is 143993.29903095338, parameters k is -42.859767877261056 and b is -85.75906487538262\n",
      "Iteration 5, the loss is 121368.8614876666, parameters k is -38.06178277118836 and b is -85.00376519091293\n",
      "Iteration 6, the loss is 102300.81900891942, parameters k is -33.65702759750925 and b is -84.31028327018744\n",
      "Iteration 7, the loss is 86230.1324401844, parameters k is -29.613275353319253 and b is -83.67355286496813\n",
      "Iteration 8, the loss is 72685.63947149886, parameters k is -25.900940186909683 and b is -83.0889229293748\n",
      "Iteration 9, the loss is 61270.24104364487, parameters k is -22.49286094327261 and b is -82.55212359214104\n",
      "Iteration 10, the loss is 51649.25914970634, parameters k is -19.364102449047877 and b is -82.05923491760052\n",
      "Iteration 11, the loss is 43540.62470462059, parameters k is -16.49177308308316 and b is -81.60665822685412\n",
      "Iteration 12, the loss is 36706.607809487316, parameters k is -13.854857297926133 and b is -81.1910897692995\n",
      "Iteration 13, the loss is 30946.847957522856, parameters k is -11.434061866951161 and b is -80.80949655189988\n",
      "Iteration 14, the loss is 26092.479840390948, parameters k is -9.211674732241459 and b is -80.45909414935556\n",
      "Iteration 15, the loss is 22001.18253458586, parameters k is -7.171435420536907 and b is -80.13732633283395\n",
      "Iteration 16, the loss is 18553.00691931386, parameters k is -5.298416079191295 and b is -79.84184636821891\n",
      "Iteration 17, the loss is 15646.858993602926, parameters k is -3.578912261780321 and b is -79.57049984705469\n",
      "Iteration 18, the loss is 13197.53599010574, parameters k is -2.0003426643316358 and b is -79.32130892457296\n",
      "Iteration 19, the loss is 11133.228390019518, parameters k is -0.5511570786322313 and b is -79.09245784948611\n",
      "Iteration 20, the loss is 9393.414602893195, parameters k is 0.7792481108141158 and b is -78.88227967968051\n",
      "Iteration 21, the loss is 7927.086587289008, parameters k is 2.0006075044161653 and b is -78.68924408661992\n",
      "Iteration 22, the loss is 6691.254390829115, parameters k is 3.121857907280826 and b is -78.51194615923416\n",
      "Iteration 23, the loss is 5649.685765551139, parameters k is 4.151203712209565 and b is -78.34909612538051\n",
      "Iteration 24, the loss is 4771.843906462451, parameters k is 5.096176924257381 and b is -78.19950991567885\n",
      "Iteration 25, the loss is 4031.9921697829195, parameters k is 5.96369226600294 and b is -78.0621005006837\n",
      "Iteration 26, the loss is 3408.4395228972166, parameters k is 6.7600977666882205 and b is -77.93586993801512\n",
      "Iteration 27, the loss is 2882.9046040263997, parameters k is 7.4912212053453695 and b is -77.81990207126364\n",
      "Iteration 28, the loss is 2439.9797470432163, parameters k is 8.162412747695566 and b is -77.71335582725364\n",
      "Iteration 29, the loss is 2066.6792576454905, parameters k is 8.778584088757823 and b is -77.61545906262675\n",
      "Iteration 30, the loss is 1752.0586971935884, parameters k is 9.344244387540861 and b is -77.52550291472622\n",
      "Iteration 31, the loss is 1486.8940123293085, parameters k is 9.863533256721606 and b is -77.44283661545207\n",
      "Iteration 32, the loss is 1263.4111030593454, parameters k is 10.340251048667723 and b is -77.3668627301449\n",
      "Iteration 33, the loss is 1075.057900747616, parameters k is 10.77788665938123 and b is -77.297032786665\n",
      "Iteration 34, the loss is 916.3122737713103, parameters k is 11.17964305378097 and b is -77.2328432626885\n",
      "Iteration 35, the loss is 782.5201289953603, parameters k is 11.548460699070727 and b is -77.17383190186312\n",
      "Iteration 36, the loss is 669.7589625047225, parameters k is 11.887039077634984 and b is -77.1195743318719\n",
      "Iteration 37, the loss is 574.7228591582415, parameters k is 12.197856436853868 and b is -77.06968095966214\n",
      "Iteration 38, the loss is 494.6255693670872, parameters k is 12.48318792032987 and b is -77.02379412112465\n",
      "Iteration 39, the loss is 427.11882149093776, parameters k is 12.745122213177108 and b is -76.98158546436994\n",
      "Iteration 40, the loss is 370.2234749248599, parameters k is 12.985576823152519 and b is -76.94275354745685\n",
      "Iteration 41, the loss is 322.2714954147091, parameters k is 13.206312109428035 and b is -76.90702163299848\n",
      "Iteration 42, the loss is 281.857051426299, parameters k is 13.408944161640322 and b is -76.87413566351029\n",
      "Iteration 43, the loss is 247.79529780576016, parameters k is 13.594956623443114 and b is -76.84386240268769\n",
      "Iteration 44, the loss is 219.0876383454326, parameters k is 13.765711547065026 and b is -76.81598772901458\n",
      "Iteration 45, the loss is 194.8924488189805, parameters k is 13.922459358286408 and b is -76.79031506921844\n",
      "Iteration 46, the loss is 174.5004021401172, parameters k is 14.066348004740481 and b is -76.76666396011096\n",
      "Iteration 47, the loss is 157.31367222495092, parameters k is 14.19843135446909 and b is -76.74486872829262\n",
      "Iteration 48, the loss is 142.8284068542558, parameters k is 14.319676906178175 and b is -76.72477727806131\n",
      "Iteration 49, the loss is 130.61995567292325, parameters k is 14.430972867602316 and b is -76.70624997865764\n",
      "Iteration 50, the loss is 120.3304202392797, parameters k is 14.533134653764728 and b is -76.68915864270545\n",
      "Iteration 51, the loss is 111.65816111511228, parameters k is 14.626910852674952 and b is -76.67338558837395\n",
      "Iteration 52, the loss is 104.34895436398739, parameters k is 14.712988702110158 and b is -76.65882277839988\n",
      "Iteration 53, the loss is 98.18853818301014, parameters k is 14.79199911754902 and b is -76.64537102967086\n",
      "Iteration 54, the loss is 92.99633114926753, parameters k is 14.864521308043273 and b is -76.63293928758695\n",
      "Iteration 55, the loss is 88.62013791174117, parameters k is 14.931087013797352 and b is -76.62144395989166\n",
      "Iteration 56, the loss is 84.93168710952368, parameters k is 14.992184396458878 and b is -76.61080830509856\n",
      "Iteration 57, the loss is 81.82287069648383, parameters k is 15.048261610581935 and b is -76.60096187103915\n",
      "Iteration 58, the loss is 79.20257441643996, parameters k is 15.0997300823925 and b is -76.59183997942431\n",
      "Iteration 59, the loss is 76.99400650433302, parameters k is 15.146967519843948 and b is -76.5833832526483\n",
      "Iteration 60, the loss is 75.13244629593332, parameters k is 15.190320675984669 and b is -76.57553717937341\n",
      "Iteration 61, the loss is 73.56334673954689, parameters k is 15.230107885854984 and b is -76.56825171571683\n",
      "Iteration 62, the loss is 72.24073517892988, parameters k is 15.266621395473681 and b is -76.56148091912222\n",
      "Iteration 63, the loss is 71.12586552136983, parameters k is 15.300129499953393 and b is -76.5551826122371\n",
      "Iteration 64, the loss is 70.18608227503441, parameters k is 15.33087850638758 and b is -76.5493180743371\n",
      "Iteration 65, the loss is 69.39386315129636, parameters k is 15.359094535869886 and b is -76.54385175803931\n",
      "Iteration 66, the loss is 68.72601216293329, parameters k is 15.384985177829723 and b is -76.53875102923244\n",
      "Iteration 67, the loss is 68.16297956135729, parameters k is 15.408741008787432 and b is -76.53398592832073\n",
      "Iteration 68, the loss is 67.68828867471156, parameters k is 15.43053698664048 and b is -76.52952895103512\n",
      "Iteration 69, the loss is 67.28805284280512, parameters k is 15.450533730681473 and b is -76.52535484720792\n",
      "Iteration 70, the loss is 66.95056828632177, parameters k is 15.46887869671282 and b is -76.52144043603884\n",
      "Iteration 71, the loss is 66.66597097399742, parameters k is 15.485707255855324 and b is -76.51776443650081\n",
      "Iteration 72, the loss is 66.42594742775373, parameters k is 15.50114368494346 and b is -76.51430731164481\n",
      "Iteration 73, the loss is 66.22349098713836, parameters k is 15.515302075753187 and b is -76.51105112566465\n",
      "Iteration 74, the loss is 66.05269638720257, parameters k is 15.528287169714377 and b is -76.50797941267595\n",
      "Iteration 75, the loss is 65.9085866272269, parameters k is 15.540195124214693 and b is -76.50507705624929\n",
      "Iteration 76, the loss is 65.78696705440937, parameters k is 15.55111421610136 and b is -76.50233017881617\n",
      "Iteration 77, the loss is 65.6843023845256, parameters k is 15.561125487527717 and b is -76.4997260401386\n",
      "Iteration 78, the loss is 65.5976130540365, parameters k is 15.570303338869678 and b is -76.49725294409973\n",
      "Iteration 79, the loss is 65.52438786488264, parameters k is 15.578716073049955 and b is -76.49490015313323\n",
      "Iteration 80, the loss is 65.46251036087467, parameters k is 15.586426395252406 and b is -76.4926578096657\n",
      "Iteration 81, the loss is 65.41019677717406, parameters k is 15.593491871682499 and b is -76.49051686399721\n",
      "Iteration 82, the loss is 65.36594374365853, parameters k is 15.599965350730235 and b is -76.48846900809234\n",
      "Iteration 83, the loss is 65.32848420893468, parameters k is 15.605895349616844 and b is -76.48650661479732\n",
      "Iteration 84, the loss is 65.29675029277152, parameters k is 15.611326409353993 and b is -76.48462268203873\n",
      "Iteration 85, the loss is 65.26984197785778, parameters k is 15.616299420612455 and b is -76.48281078159523\n",
      "Iteration 86, the loss is 65.24700072298572, parameters k is 15.620851922884354 and b is -76.48106501206775\n",
      "Iteration 87, the loss is 65.22758722404741, parameters k is 15.625018379127667 and b is -76.47937995570396\n",
      "Iteration 88, the loss is 65.21106267083975, parameters k is 15.628830427902363 and b is -76.47775063876126\n",
      "Iteration 89, the loss is 65.19697295016132, parameters k is 15.632317114842811 and b is -76.47617249511809\n",
      "Iteration 90, the loss is 65.18493533206677, parameters k is 15.635505105159972 and b is -76.47464133286749\n",
      "Iteration 91, the loss is 65.17462724894328, parameters k is 15.638418878728045 and b is -76.47315330364854\n",
      "Iteration 92, the loss is 65.16577683843491, parameters k is 15.641080909182877 and b is -76.47170487449115\n",
      "Iteration 93, the loss is 65.1581549729486, parameters k is 15.64351182834243 and b is -76.47029280196836\n",
      "Iteration 94, the loss is 65.15156854206381, parameters k is 15.645730577152223 and b is -76.46891410846689\n",
      "Iteration 95, the loss is 65.1458547908978, parameters k is 15.647754544260124 and b is -76.46756606040256\n",
      "Iteration 96, the loss is 65.14087654843837, parameters k is 15.649599693234272 and b is -76.46624614822093\n",
      "Iteration 97, the loss is 65.13651820594744, parameters k is 15.65128067935493 and b is -76.46495206803705\n",
      "Iteration 98, the loss is 65.1326823275302, parameters k is 15.65281095683469 and b is -76.46368170477989\n",
      "Iteration 99, the loss is 65.1292867934975, parameters k is 15.654202877251501 and b is -76.46243311671819\n",
      "Iteration 100, the loss is 65.12626239277132, parameters k is 15.655467779914648 and b is -76.46120452125444\n",
      "Iteration 101, the loss is 65.12355079374574, parameters k is 15.65661607482483 and b is -76.45999428188317\n",
      "Iteration 102, the loss is 65.12110283411417, parameters k is 15.657657318835277 and b is -76.458800896218\n",
      "Iteration 103, the loss is 65.11887707952249, parameters k is 15.658600285571106 and b is -76.45762298499999\n",
      "Iteration 104, the loss is 65.11683860879214, parameters k is 15.659453029618472 and b is -76.45645928200676\n",
      "Iteration 105, the loss is 65.1149579900967, parameters k is 15.660222945453123 and b is -76.45530862478864\n",
      "Iteration 106, the loss is 65.11321041807618, parameters k is 15.66091682153948 and b is -76.45416994616403\n",
      "Iteration 107, the loss is 65.11157498659028, parameters k is 15.66154088999606 and b is -76.45304226641169\n",
      "Iteration 108, the loss is 65.11003407578983, parameters k is 15.662100872190576 and b is -76.45192468610301\n",
      "Iteration 109, the loss is 65.10857283553607, parameters k is 15.662602020598325 and b is -76.45081637952167\n",
      "Iteration 110, the loss is 65.10717875002254, parameters k is 15.663049157230066 and b is -76.44971658862252\n",
      "Iteration 111, the loss is 65.10584127083504, parameters k is 15.663446708910588 and b is -76.44862461748568\n",
      "Iteration 112, the loss is 65.10455150769225, parameters k is 15.663798739666001 and b is -76.44753982722503\n",
      "Iteration 113, the loss is 65.10330196779931, parameters k is 15.66410898045677 and b is -76.44646163131408\n",
      "Iteration 114, the loss is 65.10208633617313, parameters k is 15.664380856473972 and b is -76.44538949129483\n",
      "Iteration 115, the loss is 65.10089929049936, parameters k is 15.664617512198502 and b is -76.44432291283836\n",
      "Iteration 116, the loss is 65.09973634509177, parameters k is 15.66482183440657 and b is -76.44326144212822\n",
      "Iteration 117, the loss is 65.0985937193807, parameters k is 15.664996473289785 and b is -76.44220466254023\n",
      "Iteration 118, the loss is 65.09746822707405, parameters k is 15.665143861844346 and b is -76.4411521915945\n",
      "Iteration 119, the loss is 65.0963571827406, parameters k is 15.665266233671211 and b is -76.440103678157\n",
      "Iteration 120, the loss is 65.0952583230792, parameters k is 15.665365639317454 and b is -76.43905879987076\n",
      "Iteration 121, the loss is 65.09416974056253, parameters k is 15.66544396127837 and b is -76.4380172607974\n",
      "Iteration 122, the loss is 65.09308982751209, parameters k is 15.665502927770099 and b is -76.43697878925194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 123, the loss is 65.09201722896421, parameters k is 15.6655441253735 and b is -76.43594313581526\n",
      "Iteration 124, the loss is 65.09095080294531, parameters k is 15.66556901064183 and b is -76.43491007150921\n",
      "Iteration 125, the loss is 65.08988958699118, parameters k is 15.665578920757088 and b is -76.43387938612139\n",
      "Iteration 126, the loss is 65.08883276992952, parameters k is 15.665575083313053 and b is -76.43285088666725\n",
      "Iteration 127, the loss is 65.08777966809804, parameters k is 15.665558625296535 and b is -76.43182439597815\n",
      "Iteration 128, the loss is 65.08672970530083, parameters k is 15.66553058133258 and b is -76.4307997514052\n",
      "Iteration 129, the loss is 65.0856823959151, parameters k is 15.665491901253946 and b is -76.42977680362928\n",
      "Iteration 130, the loss is 65.0846373306543, parameters k is 15.665443457050213 and b is -76.4287554155686\n",
      "Iteration 131, the loss is 65.08359416456821, parameters k is 15.665386049247397 and b is -76.42773546137583\n",
      "Iteration 132, the loss is 65.08255260692988, parameters k is 15.665320412764718 and b is -76.42671682551735\n",
      "Iteration 133, the loss is 65.0815124127121, parameters k is 15.665247222291372 and b is -76.42569940192799\n",
      "Iteration 134, the loss is 65.08047337540377, parameters k is 15.665167097222666 and b is -76.42468309323506\n",
      "Iteration 135, the loss is 65.07943532095561, parameters k is 15.665080606191603 and b is -76.423667810046\n",
      "Iteration 136, the loss is 65.0783981026769, parameters k is 15.664988271229086 and b is -76.4226534702943\n",
      "Iteration 137, the loss is 65.07736159693557, parameters k is 15.664890571583177 and b is -76.42163999863915\n",
      "Iteration 138, the loss is 65.076325699533, parameters k is 15.664787947225346 and b is -76.4206273259142\n",
      "Iteration 139, the loss is 65.07529032264961, parameters k is 15.664680802069368 and b is -76.41961538862157\n",
      "Iteration 140, the loss is 65.07425539226986, parameters k is 15.66456950692642 and b is -76.41860412846725\n",
      "Iteration 141, the loss is 65.07322084601275, parameters k is 15.664454402217984 and b is -76.41759349193468\n",
      "Iteration 142, the loss is 65.07218663130257, parameters k is 15.664335800466436 and b is -76.41658342989315\n",
      "Iteration 143, the loss is 65.07115270382786, parameters k is 15.664213988581489 and b is -76.41557389723842\n",
      "Iteration 144, the loss is 65.07011902624208, parameters k is 15.664089229959282 and b is -76.41456485256268\n",
      "Iteration 145, the loss is 65.0690855670691, parameters k is 15.66396176640942 and b is -76.41355625785162\n",
      "Iteration 146, the loss is 65.06805229978013, parameters k is 15.66383181992409 and b is -76.41254807820638\n",
      "Iteration 147, the loss is 65.06701920201601, parameters k is 15.66369959430219 and b is -76.41154028158813\n",
      "Iteration 148, the loss is 65.0659862549322, parameters k is 15.663565276640355 and b is -76.41053283858373\n",
      "Iteration 149, the loss is 65.06495344264579, parameters k is 15.663429038701778 and b is -76.40952572219055\n",
      "Iteration 150, the loss is 65.06392075177008, parameters k is 15.663291038172867 and b is -76.40851890761888\n",
      "Iteration 151, the loss is 65.0628881710226, parameters k is 15.663151419816888 and b is -76.40751237211063\n",
      "Iteration 152, the loss is 65.06185569089381, parameters k is 15.66301031653309 and b is -76.40650609477275\n",
      "Iteration 153, the loss is 65.06082330336866, parameters k is 15.662867850329004 and b is -76.40550005642444\n",
      "Iteration 154, the loss is 65.05979100169158, parameters k is 15.66272413321308 and b is -76.40449423945682\n",
      "Iteration 155, the loss is 65.05875878016872, parameters k is 15.66257926801415 and b is -76.40348862770408\n",
      "Iteration 156, the loss is 65.05772663400067, parameters k is 15.662433349133744 and b is -76.40248320632521\n",
      "Iteration 157, the loss is 65.0566945591422, parameters k is 15.662286463236741 and b is -76.40147796169549\n",
      "Iteration 158, the loss is 65.0556625521836, parameters k is 15.662138689885431 and b is -76.4004728813067\n",
      "Iteration 159, the loss is 65.05463061025075, parameters k is 15.6619901021216 and b is -76.39946795367571\n",
      "Iteration 160, the loss is 65.05359873092095, parameters k is 15.661840767000914 and b is -76.39846316826045\n",
      "Iteration 161, the loss is 65.05256691215183, parameters k is 15.661690746083513 and b is -76.39745851538275\n",
      "Iteration 162, the loss is 65.05153515222182, parameters k is 15.661540095884392 and b is -76.39645398615758\n",
      "Iteration 163, the loss is 65.05050344967964, parameters k is 15.661388868286876 and b is -76.395449572428\n",
      "Iteration 164, the loss is 65.04947180330164, parameters k is 15.661237110922201 and b is -76.39444526670557\n",
      "Iteration 165, the loss is 65.04844021205628, parameters k is 15.661084867518003 and b is -76.39344106211549\n",
      "Iteration 166, the loss is 65.0474086750736, parameters k is 15.660932178218223 and b is -76.39243695234632\n",
      "Iteration 167, the loss is 65.04637719162024, parameters k is 15.66077907987682 and b is -76.39143293160383\n",
      "Iteration 168, the loss is 65.04534576107744, parameters k is 15.660625606327388 and b is -76.39042899456862\n",
      "Iteration 169, the loss is 65.0443143829237, parameters k is 15.660471788630698 and b is -76.3894251363572\n",
      "Iteration 170, the loss is 65.04328305671898, parameters k is 15.660317655301942 and b is -76.38842135248623\n",
      "Iteration 171, the loss is 65.04225178209181, parameters k is 15.66016323251935 and b is -76.38741763883976\n",
      "Iteration 172, the loss is 65.04122055872905, parameters k is 15.660008544315719 and b is -76.38641399163913\n",
      "Iteration 173, the loss is 65.04018938636631, parameters k is 15.659853612754242 and b is -76.38541040741529\n",
      "Iteration 174, the loss is 65.03915826478031, parameters k is 15.659698458089922 and b is -76.38440688298346\n",
      "Iteration 175, the loss is 65.03812719378257, parameters k is 15.659543098917766 and b is -76.3834034154198\n",
      "Iteration 176, the loss is 65.03709617321377, parameters k is 15.659387552308825 and b is -76.3824000020401\n",
      "Iteration 177, the loss is 65.0360652029394, parameters k is 15.659231833935094 and b is -76.38139664038002\n",
      "Iteration 178, the loss is 65.03503428284564, parameters k is 15.659075958184165 and b is -76.38039332817716\n",
      "Iteration 179, the loss is 65.03400341283619, parameters k is 15.658919938264495 and b is -76.3793900633545\n",
      "Iteration 180, the loss is 65.03297259282947, parameters k is 15.658763786302039 and b is -76.37838684400519\n",
      "Iteration 181, the loss is 65.03194182275645, parameters k is 15.658607513428969 and b is -76.37738366837858\n",
      "Iteration 182, the loss is 65.03091110255845, parameters k is 15.658451129865114 and b is -76.3763805348675\n",
      "Iteration 183, the loss is 65.02988043218579, parameters k is 15.658294644992734 and b is -76.37537744199638\n",
      "Iteration 184, the loss is 65.02884981159613, parameters k is 15.658138067425165 and b is -76.37437438841057\n",
      "Iteration 185, the loss is 65.02781924075342, parameters k is 15.65798140506983 and b is -76.37337137286642\n",
      "Iteration 186, the loss is 65.02678871962685, parameters k is 15.657824665186094 and b is -76.3723683942221\n",
      "Iteration 187, the loss is 65.0257582481902, parameters k is 15.65766785443838 and b is -76.37136545142934\n",
      "Iteration 188, the loss is 65.02472782642091, parameters k is 15.657510978944918 and b is -76.37036254352573\n",
      "Iteration 189, the loss is 65.02369745429966, parameters k is 15.65735404432252 and b is -76.36935966962768\n",
      "Iteration 190, the loss is 65.02266713180967, parameters k is 15.657197055727663 and b is -76.368356828924\n",
      "Iteration 191, the loss is 65.02163685893656, parameters k is 15.657040017894218 and b is -76.36735402066986\n",
      "Iteration 192, the loss is 65.02060663566769, parameters k is 15.65688293516809 and b is -76.3663512441815\n",
      "Iteration 193, the loss is 65.01957646199229, parameters k is 15.656725811539006 and b is -76.36534849883111\n",
      "Iteration 194, the loss is 65.01854633790055, parameters k is 15.656568650669712 and b is -76.3643457840423\n",
      "Iteration 195, the loss is 65.01751626338411, parameters k is 15.656411455922767 and b is -76.36334309928586\n",
      "Iteration 196, the loss is 65.01648623843549, parameters k is 15.656254230385143 and b is -76.3623404440759\n",
      "Iteration 197, the loss is 65.01545626304791, parameters k is 15.656096976890813 and b is -76.36133781796633\n",
      "Iteration 198, the loss is 65.01442633721531, parameters k is 15.655939698041491 and b is -76.36033522054754\n",
      "Iteration 199, the loss is 65.01339646093236, parameters k is 15.655782396225655 and b is -76.35933265144345\n",
      "Iteration 200, the loss is 65.012366634194, parameters k is 15.655625073636033 and b is -76.35833011030877\n",
      "Iteration 201, the loss is 65.0113368569957, parameters k is 15.655467732285636 and b is -76.35732759682645\n",
      "Iteration 202, the loss is 65.0103071293332, parameters k is 15.655310374022498 and b is -76.35632511070537\n",
      "Iteration 203, the loss is 65.00927745120268, parameters k is 15.655153000543187 and b is -76.35532265167824\n",
      "Iteration 204, the loss is 65.00824782260034, parameters k is 15.654995613405223 and b is -76.3543202194996\n",
      "Iteration 205, the loss is 65.00721824352263, parameters k is 15.654838214038472 and b is -76.35331781394407\n",
      "Iteration 206, the loss is 65.00618871396642, parameters k is 15.65468080375561 and b is -76.35231543480471\n",
      "Iteration 207, the loss is 65.00515923392848, parameters k is 15.654523383761726 and b is -76.35131308189148\n",
      "Iteration 208, the loss is 65.00412980340575, parameters k is 15.654365955163135 and b is -76.35031075502985\n",
      "Iteration 209, the loss is 65.00310042239519, parameters k is 15.65420851897548 and b is -76.34930845405958\n",
      "Iteration 210, the loss is 65.00207109089419, parameters k is 15.65405107613116 and b is -76.3483061788335\n",
      "Iteration 211, the loss is 65.00104180889979, parameters k is 15.653893627486152 and b is -76.34730392921644\n",
      "Iteration 212, the loss is 65.00001257640932, parameters k is 15.653736173826273 and b is -76.34630170508427\n",
      "Iteration 213, the loss is 64.99898339342018, parameters k is 15.653578715872934 and b is -76.345299506323\n",
      "Iteration 214, the loss is 64.99795425992964, parameters k is 15.65342125428841 and b is -76.34429733282792\n",
      "Iteration 215, the loss is 64.99692517593525, parameters k is 15.6532637896807 and b is -76.34329518450285\n",
      "Iteration 216, the loss is 64.99589614143433, parameters k is 15.653106322607961 and b is -76.34229306125945\n",
      "Iteration 217, the loss is 64.99486715642452, parameters k is 15.6529488535826 and b is -76.34129096301659\n",
      "Iteration 218, the loss is 64.99383822090316, parameters k is 15.652791383075026 and b is -76.3402888896997\n",
      "Iteration 219, the loss is 64.99280933486783, parameters k is 15.652633911517084 and b is -76.33928684124032\n",
      "Iteration 220, the loss is 64.99178049831607, parameters k is 15.652476439305222 and b is -76.33828481757551\n",
      "Iteration 221, the loss is 64.99075171124547, parameters k is 15.652318966803389 and b is -76.33728281864748\n",
      "Iteration 222, the loss is 64.98972297365341, parameters k is 15.6521614943457 and b is -76.3362808444031\n",
      "Iteration 223, the loss is 64.98869428553778, parameters k is 15.65200402223888 and b is -76.33527889479357\n",
      "Iteration 224, the loss is 64.98766564689592, parameters k is 15.65184655076451 and b is -76.33427696977402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 225, the loss is 64.98663705772545, parameters k is 15.651689080181084 and b is -76.33327506930323\n",
      "Iteration 226, the loss is 64.98560851802392, parameters k is 15.651531610725906 and b is -76.33227319334328\n",
      "Iteration 227, the loss is 64.98458002778911, parameters k is 15.651374142616822 and b is -76.33127134185936\n",
      "Iteration 228, the loss is 64.98355158701834, parameters k is 15.65121667605382 and b is -76.33026951481942\n",
      "Iteration 229, the loss is 64.9825231957095, parameters k is 15.651059211220492 and b is -76.329267712194\n",
      "Iteration 230, the loss is 64.98149485386004, parameters k is 15.65090174828537 and b is -76.32826593395602\n",
      "Iteration 231, the loss is 64.98046656146758, parameters k is 15.650744287403173 and b is -76.32726418008056\n",
      "Iteration 232, the loss is 64.97943831852979, parameters k is 15.650586828715928 and b is -76.3262624505447\n",
      "Iteration 233, the loss is 64.97841012504415, parameters k is 15.650429372354019 and b is -76.32526074532736\n",
      "Iteration 234, the loss is 64.97738198100838, parameters k is 15.650271918437133 and b is -76.3242590644091\n",
      "Iteration 235, the loss is 64.97635388642007, parameters k is 15.650114467075142 and b is -76.3232574077721\n",
      "Iteration 236, the loss is 64.97532584127688, parameters k is 15.649957018368907 and b is -76.32225577539988\n",
      "Iteration 237, the loss is 64.97429784557634, parameters k is 15.649799572411014 and b is -76.3212541672773\n",
      "Iteration 238, the loss is 64.97326989931621, parameters k is 15.649642129286455 and b is -76.3202525833904\n",
      "Iteration 239, the loss is 64.97224200249399, parameters k is 15.64948468907325 and b is -76.31925102372632\n",
      "Iteration 240, the loss is 64.97121415510733, parameters k is 15.649327251843014 and b is -76.31824948827322\n",
      "Iteration 241, the loss is 64.97018635715375, parameters k is 15.649169817661488 and b is -76.31724797702016\n",
      "Iteration 242, the loss is 64.96915860863093, parameters k is 15.649012386589018 and b is -76.31624648995707\n",
      "Iteration 243, the loss is 64.96813090953673, parameters k is 15.648854958680994 and b is -76.31524502707464\n",
      "Iteration 244, the loss is 64.96710325986845, parameters k is 15.648697533988264 and b is -76.31424358836428\n",
      "Iteration 245, the loss is 64.96607565962383, parameters k is 15.648540112557496 and b is -76.31324217381807\n",
      "Iteration 246, the loss is 64.96504810880045, parameters k is 15.64838269443153 and b is -76.31224078342868\n",
      "Iteration 247, the loss is 64.96402060739608, parameters k is 15.648225279649687 and b is -76.31123941718933\n",
      "Iteration 248, the loss is 64.96299315540817, parameters k is 15.648067868248054 and b is -76.31023807509375\n",
      "Iteration 249, the loss is 64.96196575283446, parameters k is 15.647910460259757 and b is -76.30923675713615\n",
      "Iteration 250, the loss is 64.96093839967243, parameters k is 15.6477530557152 and b is -76.30823546331115\n",
      "Iteration 251, the loss is 64.95991109591988, parameters k is 15.647595654642284 and b is -76.30723419361378\n",
      "Iteration 252, the loss is 64.95888384157432, parameters k is 15.64743825706662 and b is -76.30623294803941\n",
      "Iteration 253, the loss is 64.95785663663344, parameters k is 15.64728086301171 and b is -76.30523172658376\n",
      "Iteration 254, the loss is 64.95682948109477, parameters k is 15.647123472499127 and b is -76.30423052924283\n",
      "Iteration 255, the loss is 64.95580237495598, parameters k is 15.64696608554866 and b is -76.30322935601293\n",
      "Iteration 256, the loss is 64.95477531821476, parameters k is 15.646808702178477 and b is -76.30222820689062\n",
      "Iteration 257, the loss is 64.95374831086865, parameters k is 15.646651322405246 and b is -76.30122708187267\n",
      "Iteration 258, the loss is 64.95272135291536, parameters k is 15.646493946244261 and b is -76.30022598095609\n",
      "Iteration 259, the loss is 64.95169444435233, parameters k is 15.646336573709556 and b is -76.29922490413807\n",
      "Iteration 260, the loss is 64.9506675851774, parameters k is 15.646179204814008 and b is -76.298223851416\n",
      "Iteration 261, the loss is 64.94964077538809, parameters k is 15.64602183956943 and b is -76.29722282278743\n",
      "Iteration 262, the loss is 64.94861401498207, parameters k is 15.645864477986661 and b is -76.29622181825006\n",
      "Iteration 263, the loss is 64.94758730395692, parameters k is 15.645707120075642 and b is -76.29522083780174\n",
      "Iteration 264, the loss is 64.94656064231025, parameters k is 15.645549765845493 and b is -76.29421988144044\n",
      "Iteration 265, the loss is 64.94553403003981, parameters k is 15.645392415304581 and b is -76.29321894916426\n",
      "Iteration 266, the loss is 64.94450746714305, parameters k is 15.645235068460577 and b is -76.29221804097138\n",
      "Iteration 267, the loss is 64.94348095361767, parameters k is 15.645077725320517 and b is -76.29121715686011\n",
      "Iteration 268, the loss is 64.94245448946131, parameters k is 15.644920385890853 and b is -76.29021629682886\n",
      "Iteration 269, the loss is 64.9414280746716, parameters k is 15.644763050177499 and b is -76.28921546087608\n",
      "Iteration 270, the loss is 64.94040170924617, parameters k is 15.64460571818588 and b is -76.28821464900034\n",
      "Iteration 271, the loss is 64.9393753931826, parameters k is 15.644448389920969 and b is -76.28721386120026\n",
      "Iteration 272, the loss is 64.93834912647851, parameters k is 15.64429106538732 and b is -76.28621309747453\n",
      "Iteration 273, the loss is 64.93732290913168, parameters k is 15.644133744589107 and b is -76.2852123578219\n",
      "Iteration 274, the loss is 64.9362967411396, parameters k is 15.64397642753016 and b is -76.28421164224119\n",
      "Iteration 275, the loss is 64.93527062249981, parameters k is 15.643819114213981 and b is -76.28321095073125\n",
      "Iteration 276, the loss is 64.93424455321015, parameters k is 15.643661804643783 and b is -76.28221028329096\n",
      "Iteration 277, the loss is 64.93321853326808, parameters k is 15.643504498822503 and b is -76.2812096399193\n",
      "Iteration 278, the loss is 64.93219256267128, parameters k is 15.643347196752835 and b is -76.28020902061522\n",
      "Iteration 279, the loss is 64.9311666414174, parameters k is 15.64318989843724 and b is -76.27920842537776\n",
      "Iteration 280, the loss is 64.93014076950402, parameters k is 15.643032603877975 and b is -76.27820785420597\n",
      "Iteration 281, the loss is 64.92911494692885, parameters k is 15.642875313077099 and b is -76.27720730709893\n",
      "Iteration 282, the loss is 64.92808917368941, parameters k is 15.642718026036498 and b is -76.27620678405576\n",
      "Iteration 283, the loss is 64.92706344978345, parameters k is 15.642560742757896 and b is -76.27520628507558\n",
      "Iteration 284, the loss is 64.92603777520844, parameters k is 15.642403463242866 and b is -76.27420581015757\n",
      "Iteration 285, the loss is 64.92501214996213, parameters k is 15.642246187492848 and b is -76.27320535930089\n",
      "Iteration 286, the loss is 64.92398657404209, parameters k is 15.642088915509154 and b is -76.27220493250475\n",
      "Iteration 287, the loss is 64.92296104744602, parameters k is 15.641931647292983 and b is -76.27120452976837\n",
      "Iteration 288, the loss is 64.92193557017148, parameters k is 15.641774382845426 and b is -76.27020415109098\n",
      "Iteration 289, the loss is 64.9209101422161, parameters k is 15.64161712216748 and b is -76.26920379647183\n",
      "Iteration 290, the loss is 64.91988476357754, parameters k is 15.64145986526005 and b is -76.26820346591019\n",
      "Iteration 291, the loss is 64.91885943425335, parameters k is 15.64130261212396 and b is -76.26720315940534\n",
      "Iteration 292, the loss is 64.91783415424128, parameters k is 15.64114536275996 and b is -76.26620287695657\n",
      "Iteration 293, the loss is 64.9168089235389, parameters k is 15.640988117168732 and b is -76.26520261856318\n",
      "Iteration 294, the loss is 64.91578374214383, parameters k is 15.64083087535089 and b is -76.26420238422448\n",
      "Iteration 295, the loss is 64.91475861005367, parameters k is 15.640673637306996 and b is -76.26320217393977\n",
      "Iteration 296, the loss is 64.91373352726616, parameters k is 15.640516403037555 and b is -76.26220198770841\n",
      "Iteration 297, the loss is 64.91270849377881, parameters k is 15.640359172543025 and b is -76.26120182552971\n",
      "Iteration 298, the loss is 64.91168350958925, parameters k is 15.640201945823819 and b is -76.26020168740303\n",
      "Iteration 299, the loss is 64.91065857469519, parameters k is 15.640044722880306 and b is -76.2592015733277\n",
      "Iteration 300, the loss is 64.90963368909422, parameters k is 15.63988750371282 and b is -76.2582014833031\n",
      "Iteration 301, the loss is 64.90860885278398, parameters k is 15.63973028832166 and b is -76.25720141732856\n",
      "Iteration 302, the loss is 64.90758406576205, parameters k is 15.63957307670709 and b is -76.25620137540346\n",
      "Iteration 303, the loss is 64.9065593280261, parameters k is 15.639415868869351 and b is -76.25520135752718\n",
      "Iteration 304, the loss is 64.90553463957383, parameters k is 15.63925866480865 and b is -76.2542013636991\n",
      "Iteration 305, the loss is 64.90451000040278, parameters k is 15.639101464525174 and b is -76.25320139391857\n",
      "Iteration 306, the loss is 64.90348541051054, parameters k is 15.638944268019086 and b is -76.25220144818499\n",
      "Iteration 307, the loss is 64.90246086989484, parameters k is 15.638787075290528 and b is -76.25120152649774\n",
      "Iteration 308, the loss is 64.90143637855321, parameters k is 15.638629886339624 and b is -76.2502016288562\n",
      "Iteration 309, the loss is 64.90041193648337, parameters k is 15.638472701166478 and b is -76.24920175525979\n",
      "Iteration 310, the loss is 64.89938754368293, parameters k is 15.63831551977118 and b is -76.24820190570787\n",
      "Iteration 311, the loss is 64.8983632001495, parameters k is 15.638158342153803 and b is -76.24720208019986\n",
      "Iteration 312, the loss is 64.89733890588077, parameters k is 15.63800116831441 and b is -76.24620227873514\n",
      "Iteration 313, the loss is 64.89631466087422, parameters k is 15.63784399825305 and b is -76.24520250131312\n",
      "Iteration 314, the loss is 64.89529046512769, parameters k is 15.63768683196976 and b is -76.2442027479332\n",
      "Iteration 315, the loss is 64.89426631863863, parameters k is 15.637529669464566 and b is -76.24320301859478\n",
      "Iteration 316, the loss is 64.89324222140473, parameters k is 15.637372510737485 and b is -76.24220331329727\n",
      "Iteration 317, the loss is 64.89221817342371, parameters k is 15.637215355788527 and b is -76.24120363204007\n",
      "Iteration 318, the loss is 64.89119417469306, parameters k is 15.63705820461769 and b is -76.24020397482259\n",
      "Iteration 319, the loss is 64.8901702252105, parameters k is 15.636901057224966 and b is -76.23920434164425\n",
      "Iteration 320, the loss is 64.88914632497364, parameters k is 15.636743913610344 and b is -76.23820473250446\n",
      "Iteration 321, the loss is 64.88812247398009, parameters k is 15.636586773773802 and b is -76.2372051474026\n",
      "Iteration 322, the loss is 64.88709867222755, parameters k is 15.636429637715313 and b is -76.23620558633812\n",
      "Iteration 323, the loss is 64.8860749197136, parameters k is 15.636272505434846 and b is -76.2352060493104\n",
      "Iteration 324, the loss is 64.88505121643578, parameters k is 15.636115376932365 and b is -76.23420653631888\n",
      "Iteration 325, the loss is 64.88402756239186, parameters k is 15.635958252207827 and b is -76.23320704736295\n",
      "Iteration 326, the loss is 64.88300395757948, parameters k is 15.63580113126119 and b is -76.23220758244204\n",
      "Iteration 327, the loss is 64.88198040199619, parameters k is 15.635644014092403 and b is -76.23120814155557\n",
      "Iteration 328, the loss is 64.88095689563963, parameters k is 15.635486900701416 and b is -76.23020872470295\n",
      "Iteration 329, the loss is 64.87993343850746, parameters k is 15.635329791088171 and b is -76.2292093318836\n",
      "Iteration 330, the loss is 64.87891003059735, parameters k is 15.635172685252613 and b is -76.22820996309693\n",
      "Iteration 331, the loss is 64.87788667190685, parameters k is 15.635015583194678 and b is -76.22721061834235\n",
      "Iteration 332, the loss is 64.8768633624337, parameters k is 15.634858484914304 and b is -76.2262112976193\n",
      "Iteration 333, the loss is 64.8758401021754, parameters k is 15.634701390411426 and b is -76.22521200092719\n",
      "Iteration 334, the loss is 64.87481689112967, parameters k is 15.634544299685976 and b is -76.22421272826543\n",
      "Iteration 335, the loss is 64.87379372929412, parameters k is 15.634387212737883 and b is -76.22321347963344\n",
      "Iteration 336, the loss is 64.8727706166664, parameters k is 15.634230129567078 and b is -76.22221425503065\n",
      "Iteration 337, the loss is 64.87174755324412, parameters k is 15.634073050173486 and b is -76.22121505445647\n",
      "Iteration 338, the loss is 64.87072453902493, parameters k is 15.633915974557034 and b is -76.2202158779103\n",
      "Iteration 339, the loss is 64.86970157400644, parameters k is 15.633758902717645 and b is -76.2192167253916\n",
      "Iteration 340, the loss is 64.86867865818637, parameters k is 15.633601834655243 and b is -76.21821759689978\n",
      "Iteration 341, the loss is 64.8676557915622, parameters k is 15.633444770369751 and b is -76.21721849243424\n",
      "Iteration 342, the loss is 64.86663297413173, parameters k is 15.633287709861088 and b is -76.21621941199442\n",
      "Iteration 343, the loss is 64.8656102058924, parameters k is 15.633130653129173 and b is -76.21522035557972\n",
      "Iteration 344, the loss is 64.8645874868421, parameters k is 15.632973600173928 and b is -76.21422132318958\n",
      "Iteration 345, the loss is 64.86356481697818, parameters k is 15.632816550995269 and b is -76.21322231482341\n",
      "Iteration 346, the loss is 64.86254219629846, parameters k is 15.632659505593114 and b is -76.21222333048064\n",
      "Iteration 347, the loss is 64.86151962480056, parameters k is 15.63250246396738 and b is -76.21122437016068\n",
      "Iteration 348, the loss is 64.86049710248204, parameters k is 15.632345426117984 and b is -76.21022543386296\n",
      "Iteration 349, the loss is 64.85947462934068, parameters k is 15.63218839204484 and b is -76.2092265215869\n",
      "Iteration 350, the loss is 64.85845220537395, parameters k is 15.632031361747865 and b is -76.20822763333192\n",
      "Iteration 351, the loss is 64.85742983057952, parameters k is 15.631874335226971 and b is -76.20722876909744\n",
      "Iteration 352, the loss is 64.85640750495511, parameters k is 15.631717312482074 and b is -76.20622992888288\n",
      "Iteration 353, the loss is 64.85538522849825, parameters k is 15.631560293513088 and b is -76.20523111268767\n",
      "Iteration 354, the loss is 64.85436300120666, parameters k is 15.631403278319926 and b is -76.20423232051122\n",
      "Iteration 355, the loss is 64.85334082307794, parameters k is 15.631246266902501 and b is -76.20323355235297\n",
      "Iteration 356, the loss is 64.85231869410973, parameters k is 15.631089259260724 and b is -76.20223480821232\n",
      "Iteration 357, the loss is 64.85129661429966, parameters k is 15.63093225539451 and b is -76.2012360880887\n",
      "Iteration 358, the loss is 64.85027458364527, parameters k is 15.63077525530377 and b is -76.20023739198155\n",
      "Iteration 359, the loss is 64.84925260214443, parameters k is 15.630618258988417 and b is -76.19923871989026\n",
      "Iteration 360, the loss is 64.8482306697945, parameters k is 15.63046126644836 and b is -76.19824007181427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 361, the loss is 64.84720878659346, parameters k is 15.630304277683514 and b is -76.197241447753\n",
      "Iteration 362, the loss is 64.84618695253857, parameters k is 15.630147292693788 and b is -76.19624284770588\n",
      "Iteration 363, the loss is 64.84516516762766, parameters k is 15.629990311479094 and b is -76.19524427167231\n",
      "Iteration 364, the loss is 64.84414343185838, parameters k is 15.629833334039343 and b is -76.19424571965173\n",
      "Iteration 365, the loss is 64.84312174522839, parameters k is 15.629676360374445 and b is -76.19324719164356\n",
      "Iteration 366, the loss is 64.84210010773519, parameters k is 15.629519390484312 and b is -76.19224868764724\n",
      "Iteration 367, the loss is 64.84107851937655, parameters k is 15.629362424368853 and b is -76.19125020766216\n",
      "Iteration 368, the loss is 64.84005698015002, parameters k is 15.629205462027981 and b is -76.19025175168777\n",
      "Iteration 369, the loss is 64.83903549005328, parameters k is 15.629048503461604 and b is -76.18925331972346\n",
      "Iteration 370, the loss is 64.83801404908395, parameters k is 15.628891548669634 and b is -76.18825491176868\n",
      "Iteration 371, the loss is 64.83699265723965, parameters k is 15.62873459765198 and b is -76.18725652782284\n",
      "Iteration 372, the loss is 64.83597131451805, parameters k is 15.628577650408552 and b is -76.18625816788537\n",
      "Iteration 373, the loss is 64.83495002091676, parameters k is 15.628420706939261 and b is -76.18525983195569\n",
      "Iteration 374, the loss is 64.8339287764335, parameters k is 15.628263767244016 and b is -76.18426152003322\n",
      "Iteration 375, the loss is 64.8329075810658, parameters k is 15.628106831322729 and b is -76.18326323211738\n",
      "Iteration 376, the loss is 64.83188643481135, parameters k is 15.627949899175308 and b is -76.1822649682076\n",
      "Iteration 377, the loss is 64.83086533766783, parameters k is 15.627792970801663 and b is -76.1812667283033\n",
      "Iteration 378, the loss is 64.82984428963275, parameters k is 15.627636046201705 and b is -76.1802685124039\n",
      "Iteration 379, the loss is 64.82882329070387, parameters k is 15.627479125375341 and b is -76.17927032050882\n",
      "Iteration 380, the loss is 64.82780234087879, parameters k is 15.627322208322484 and b is -76.1782721526175\n",
      "Iteration 381, the loss is 64.82678144015506, parameters k is 15.627165295043042 and b is -76.17727400872934\n",
      "Iteration 382, the loss is 64.82576058853053, parameters k is 15.627008385536925 and b is -76.17627588884378\n",
      "Iteration 383, the loss is 64.82473978600262, parameters k is 15.626851479804042 and b is -76.17527779296023\n",
      "Iteration 384, the loss is 64.82371903256913, parameters k is 15.626694577844303 and b is -76.17427972107812\n",
      "Iteration 385, the loss is 64.82269832822753, parameters k is 15.626537679657618 and b is -76.17328167319687\n",
      "Iteration 386, the loss is 64.82167767297555, parameters k is 15.626380785243896 and b is -76.1722836493159\n",
      "Iteration 387, the loss is 64.82065706681094, parameters k is 15.626223894603047 and b is -76.17128564943464\n",
      "Iteration 388, the loss is 64.8196365097312, parameters k is 15.62606700773498 and b is -76.17028767355251\n",
      "Iteration 389, the loss is 64.81861600173394, parameters k is 15.625910124639605 and b is -76.16928972166893\n",
      "Iteration 390, the loss is 64.81759554281693, parameters k is 15.625753245316831 and b is -76.16829179378333\n",
      "Iteration 391, the loss is 64.8165751329777, parameters k is 15.625596369766567 and b is -76.16729388989512\n",
      "Iteration 392, the loss is 64.815554772214, parameters k is 15.625439497988724 and b is -76.16629601000373\n",
      "Iteration 393, the loss is 64.81453446052338, parameters k is 15.62528262998321 and b is -76.1652981541086\n",
      "Iteration 394, the loss is 64.81351419790343, parameters k is 15.625125765749935 and b is -76.16430032220913\n",
      "Iteration 395, the loss is 64.81249398435197, parameters k is 15.624968905288808 and b is -76.16330251430475\n",
      "Iteration 396, the loss is 64.81147381986646, parameters k is 15.62481204859974 and b is -76.16230473039488\n",
      "Iteration 397, the loss is 64.81045370444461, parameters k is 15.624655195682637 and b is -76.16130697047895\n",
      "Iteration 398, the loss is 64.80943363808413, parameters k is 15.624498346537411 and b is -76.16030923455637\n",
      "Iteration 399, the loss is 64.8084136207825, parameters k is 15.624341501163972 and b is -76.15931152262657\n",
      "Iteration 400, the loss is 64.80739365253748, parameters k is 15.624184659562228 and b is -76.15831383468898\n",
      "Iteration 401, the loss is 64.80637373334677, parameters k is 15.624027821732088 and b is -76.15731617074302\n",
      "Iteration 402, the loss is 64.80535386320786, parameters k is 15.623870987673463 and b is -76.1563185307881\n",
      "Iteration 403, the loss is 64.80433404211843, parameters k is 15.62371415738626 and b is -76.15532091482366\n",
      "Iteration 404, the loss is 64.80331427007617, parameters k is 15.62355733087039 and b is -76.15432332284912\n",
      "Iteration 405, the loss is 64.80229454707872, parameters k is 15.623400508125764 and b is -76.1533257548639\n",
      "Iteration 406, the loss is 64.80127487312369, parameters k is 15.623243689152288 and b is -76.15232821086742\n",
      "Iteration 407, the loss is 64.8002552482087, parameters k is 15.623086873949873 and b is -76.15133069085911\n",
      "Iteration 408, the loss is 64.7992356723315, parameters k is 15.622930062518428 and b is -76.1503331948384\n",
      "Iteration 409, the loss is 64.79821614548958, parameters k is 15.622773254857863 and b is -76.1493357228047\n",
      "Iteration 410, the loss is 64.7971966676807, parameters k is 15.622616450968087 and b is -76.14833827475742\n",
      "Iteration 411, the loss is 64.79617723890244, parameters k is 15.62245965084901 and b is -76.14734085069601\n",
      "Iteration 412, the loss is 64.79515785915244, parameters k is 15.62230285450054 and b is -76.14634345061988\n",
      "Iteration 413, the loss is 64.79413852842836, parameters k is 15.622146061922585 and b is -76.14534607452846\n",
      "Iteration 414, the loss is 64.79311924672791, parameters k is 15.621989273115059 and b is -76.14434872242117\n",
      "Iteration 415, the loss is 64.7921000140486, parameters k is 15.621832488077867 and b is -76.14335139429743\n",
      "Iteration 416, the loss is 64.79108083038817, parameters k is 15.62167570681092 and b is -76.14235409015666\n",
      "Iteration 417, the loss is 64.7900616957442, parameters k is 15.62151892931413 and b is -76.14135680999829\n",
      "Iteration 418, the loss is 64.78904261011441, parameters k is 15.621362155587402 and b is -76.14035955382174\n",
      "Iteration 419, the loss is 64.78802357349635, parameters k is 15.621205385630647 and b is -76.13936232162644\n",
      "Iteration 420, the loss is 64.78700458588769, parameters k is 15.621048619443775 and b is -76.1383651134118\n",
      "Iteration 421, the loss is 64.78598564728617, parameters k is 15.620891857026693 and b is -76.13736792917724\n",
      "Iteration 422, the loss is 64.78496675768932, parameters k is 15.620735098379313 and b is -76.13637076892222\n",
      "Iteration 423, the loss is 64.78394791709482, parameters k is 15.620578343501544 and b is -76.13537363264612\n",
      "Iteration 424, the loss is 64.78292912550026, parameters k is 15.620421592393294 and b is -76.1343765203484\n",
      "Iteration 425, the loss is 64.78191038290333, parameters k is 15.620264845054475 and b is -76.13337943202845\n",
      "Iteration 426, the loss is 64.78089168930178, parameters k is 15.620108101484993 and b is -76.13238236768571\n",
      "Iteration 427, the loss is 64.7798730446931, parameters k is 15.619951361684759 and b is -76.1313853273196\n",
      "Iteration 428, the loss is 64.77885444907498, parameters k is 15.619794625653682 and b is -76.13038831092956\n",
      "Iteration 429, the loss is 64.77783590244508, parameters k is 15.619637893391673 and b is -76.12939131851499\n",
      "Iteration 430, the loss is 64.77681740480098, parameters k is 15.61948116489864 and b is -76.12839435007533\n",
      "Iteration 431, the loss is 64.77579895614045, parameters k is 15.619324440174491 and b is -76.12739740560998\n",
      "Iteration 432, the loss is 64.77478055646101, parameters k is 15.619167719219138 and b is -76.1264004851184\n",
      "Iteration 433, the loss is 64.77376220576049, parameters k is 15.61901100203249 and b is -76.12540358859998\n",
      "Iteration 434, the loss is 64.7727439040362, parameters k is 15.618854288614456 and b is -76.12440671605415\n",
      "Iteration 435, the loss is 64.77172565128618, parameters k is 15.618697578964944 and b is -76.12340986748035\n",
      "Iteration 436, the loss is 64.77070744750769, parameters k is 15.618540873083866 and b is -76.122413042878\n",
      "Iteration 437, the loss is 64.76968929269869, parameters k is 15.618384170971128 and b is -76.1214162422465\n",
      "Iteration 438, the loss is 64.76867118685668, parameters k is 15.618227472626641 and b is -76.1204194655853\n",
      "Iteration 439, the loss is 64.7676531299793, parameters k is 15.618070778050315 and b is -76.11942271289381\n",
      "Iteration 440, the loss is 64.7666351220642, parameters k is 15.61791408724206 and b is -76.11842598417145\n",
      "Iteration 441, the loss is 64.76561716310917, parameters k is 15.617757400201784 and b is -76.11742927941766\n",
      "Iteration 442, the loss is 64.76459925311154, parameters k is 15.617600716929395 and b is -76.11643259863186\n",
      "Iteration 443, the loss is 64.76358139206924, parameters k is 15.617444037424805 and b is -76.11543594181346\n",
      "Iteration 444, the loss is 64.76256357997984, parameters k is 15.617287361687923 and b is -76.11443930896189\n",
      "Iteration 445, the loss is 64.76154581684091, parameters k is 15.617130689718659 and b is -76.11344270007659\n",
      "Iteration 446, the loss is 64.76052810265021, parameters k is 15.616974021516919 and b is -76.11244611515696\n",
      "Iteration 447, the loss is 64.75951043740532, parameters k is 15.616817357082615 and b is -76.11144955420244\n",
      "Iteration 448, the loss is 64.75849282110387, parameters k is 15.616660696415657 and b is -76.11045301721244\n",
      "Iteration 449, the loss is 64.75747525374356, parameters k is 15.616504039515954 and b is -76.10945650418638\n",
      "Iteration 450, the loss is 64.756457735322, parameters k is 15.616347386383413 and b is -76.10846001512371\n",
      "Iteration 451, the loss is 64.75544026583682, parameters k is 15.616190737017947 and b is -76.10746355002384\n",
      "Iteration 452, the loss is 64.7544228452857, parameters k is 15.616034091419463 and b is -76.10646710888618\n",
      "Iteration 453, the loss is 64.75340547366626, parameters k is 15.615877449587872 and b is -76.10547069171017\n",
      "Iteration 454, the loss is 64.75238815097622, parameters k is 15.615720811523081 and b is -76.10447429849523\n",
      "Iteration 455, the loss is 64.7513708772131, parameters k is 15.615564177225002 and b is -76.10347792924078\n",
      "Iteration 456, the loss is 64.75035365237467, parameters k is 15.615407546693543 and b is -76.10248158394626\n",
      "Iteration 457, the loss is 64.74933647645848, parameters k is 15.615250919928615 and b is -76.10148526261106\n",
      "Iteration 458, the loss is 64.74831934946225, parameters k is 15.615094296930124 and b is -76.10048896523465\n",
      "Iteration 459, the loss is 64.7473022713836, parameters k is 15.614937677697982 and b is -76.09949269181641\n",
      "Iteration 460, the loss is 64.74628524222017, parameters k is 15.6147810622321 and b is -76.09849644235578\n",
      "Iteration 461, the loss is 64.74526826196966, parameters k is 15.614624450532384 and b is -76.0975002168522\n",
      "Iteration 462, the loss is 64.74425133062961, parameters k is 15.614467842598746 and b is -76.09650401530507\n",
      "Iteration 463, the loss is 64.74323444819768, parameters k is 15.614311238431094 and b is -76.09550783771382\n",
      "Iteration 464, the loss is 64.74221761467165, parameters k is 15.614154638029339 and b is -76.09451168407789\n",
      "Iteration 465, the loss is 64.74120083004904, parameters k is 15.613998041393387 and b is -76.09351555439669\n",
      "Iteration 466, the loss is 64.74018409432757, parameters k is 15.61384144852315 and b is -76.09251944866965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 467, the loss is 64.73916740750491, parameters k is 15.61368485941854 and b is -76.09152336689618\n",
      "Iteration 468, the loss is 64.73815076957857, parameters k is 15.61352827407946 and b is -76.09052730907572\n",
      "Iteration 469, the loss is 64.73713418054632, parameters k is 15.613371692505826 and b is -76.08953127520769\n",
      "Iteration 470, the loss is 64.73611764040577, parameters k is 15.613215114697544 and b is -76.08853526529151\n",
      "Iteration 471, the loss is 64.73510114915459, parameters k is 15.613058540654524 and b is -76.0875392793266\n",
      "Iteration 472, the loss is 64.73408470679038, parameters k is 15.612901970376676 and b is -76.0865433173124\n",
      "Iteration 473, the loss is 64.73306831331081, parameters k is 15.612745403863908 and b is -76.08554737924833\n",
      "Iteration 474, the loss is 64.73205196871355, parameters k is 15.61258884111613 and b is -76.08455146513379\n",
      "Iteration 475, the loss is 64.73103567299631, parameters k is 15.612432282133252 and b is -76.08355557496822\n",
      "Iteration 476, the loss is 64.73001942615659, parameters k is 15.612275726915183 and b is -76.08255970875105\n",
      "Iteration 477, the loss is 64.72900322819218, parameters k is 15.612119175461833 and b is -76.0815638664817\n",
      "Iteration 478, the loss is 64.7279870791006, parameters k is 15.611962627773112 and b is -76.0805680481596\n",
      "Iteration 479, the loss is 64.72697097887965, parameters k is 15.611806083848927 and b is -76.07957225378418\n",
      "Iteration 480, the loss is 64.72595492752681, parameters k is 15.611649543689191 and b is -76.07857648335484\n",
      "Iteration 481, the loss is 64.72493892503988, parameters k is 15.611493007293811 and b is -76.07758073687101\n",
      "Iteration 482, the loss is 64.72392297141643, parameters k is 15.611336474662696 and b is -76.07658501433212\n",
      "Iteration 483, the loss is 64.72290706665405, parameters k is 15.611179945795758 and b is -76.0755893157376\n",
      "Iteration 484, the loss is 64.72189121075053, parameters k is 15.611023420692904 and b is -76.07459364108688\n",
      "Iteration 485, the loss is 64.7208754037035, parameters k is 15.610866899354045 and b is -76.07359799037937\n",
      "Iteration 486, the loss is 64.71985964551058, parameters k is 15.610710381779091 and b is -76.0726023636145\n",
      "Iteration 487, the loss is 64.71884393616928, parameters k is 15.61055386796795 and b is -76.07160676079168\n",
      "Iteration 488, the loss is 64.71782827567745, parameters k is 15.610397357920531 and b is -76.07061118191035\n",
      "Iteration 489, the loss is 64.71681266403266, parameters k is 15.610240851636746 and b is -76.06961562696993\n",
      "Iteration 490, the loss is 64.71579710123257, parameters k is 15.610084349116503 and b is -76.06862009596985\n",
      "Iteration 491, the loss is 64.71478158727481, parameters k is 15.60992785035971 and b is -76.06762458890952\n",
      "Iteration 492, the loss is 64.71376612215715, parameters k is 15.609771355366279 and b is -76.06662910578838\n",
      "Iteration 493, the loss is 64.71275070587697, parameters k is 15.609614864136118 and b is -76.06563364660585\n",
      "Iteration 494, the loss is 64.7117353384322, parameters k is 15.609458376669137 and b is -76.06463821136134\n",
      "Iteration 495, the loss is 64.71072001982044, parameters k is 15.609301892965245 and b is -76.0636428000543\n",
      "Iteration 496, the loss is 64.70970475003918, parameters k is 15.609145413024352 and b is -76.06264741268413\n",
      "Iteration 497, the loss is 64.70868952908623, parameters k is 15.60898893684637 and b is -76.06165204925027\n",
      "Iteration 498, the loss is 64.70767435695915, parameters k is 15.608832464431204 and b is -76.06065670975214\n",
      "Iteration 499, the loss is 64.70665923365564, parameters k is 15.608675995778766 and b is -76.05966139418916\n",
      "Iteration 500, the loss is 64.70564415917342, parameters k is 15.608519530888966 and b is -76.05866610256076\n",
      "Iteration 501, the loss is 64.70462913351001, parameters k is 15.608363069761712 and b is -76.05767083486637\n",
      "Iteration 502, the loss is 64.7036141566631, parameters k is 15.608206612396913 and b is -76.0566755911054\n",
      "Iteration 503, the loss is 64.70259922863032, parameters k is 15.60805015879448 and b is -76.05568037127729\n",
      "Iteration 504, the loss is 64.70158434940944, parameters k is 15.607893708954323 and b is -76.05468517538145\n",
      "Iteration 505, the loss is 64.70056951899794, parameters k is 15.60773726287635 and b is -76.05369000341732\n",
      "Iteration 506, the loss is 64.69955473739367, parameters k is 15.607580820560472 and b is -76.0526948553843\n",
      "Iteration 507, the loss is 64.69854000459414, parameters k is 15.607424382006597 and b is -76.05169973128184\n",
      "Iteration 508, the loss is 64.697525320597, parameters k is 15.607267947214636 and b is -76.05070463110935\n",
      "Iteration 509, the loss is 64.69651068540004, parameters k is 15.607111516184498 and b is -76.04970955486627\n",
      "Iteration 510, the loss is 64.69549609900076, parameters k is 15.606955088916092 and b is -76.048714502552\n",
      "Iteration 511, the loss is 64.69448156139686, parameters k is 15.606798665409327 and b is -76.04771947416599\n",
      "Iteration 512, the loss is 64.69346707258605, parameters k is 15.606642245664114 and b is -76.04672446970766\n",
      "Iteration 513, the loss is 64.69245263256587, parameters k is 15.606485829680363 and b is -76.04572948917641\n",
      "Iteration 514, the loss is 64.6914382413341, parameters k is 15.606329417457982 and b is -76.0447345325717\n",
      "Iteration 515, the loss is 64.6904238988883, parameters k is 15.606173008996882 and b is -76.04373959989292\n",
      "Iteration 516, the loss is 64.68940960522617, parameters k is 15.60601660429697 and b is -76.04274469113952\n",
      "Iteration 517, the loss is 64.68839536034531, parameters k is 15.605860203358159 and b is -76.04174980631092\n",
      "Iteration 518, the loss is 64.6873811642435, parameters k is 15.605703806180356 and b is -76.04075494540653\n",
      "Iteration 519, the loss is 64.68636701691828, parameters k is 15.605547412763471 and b is -76.0397601084258\n",
      "Iteration 520, the loss is 64.68535291836734, parameters k is 15.605391023107414 and b is -76.03876529536812\n",
      "Iteration 521, the loss is 64.68433886858828, parameters k is 15.605234637212094 and b is -76.03777050623295\n",
      "Iteration 522, the loss is 64.68332486757892, parameters k is 15.605078255077421 and b is -76.0367757410197\n",
      "Iteration 523, the loss is 64.68231091533659, parameters k is 15.604921876703306 and b is -76.03578099972779\n",
      "Iteration 524, the loss is 64.6812970118593, parameters k is 15.604765502089657 and b is -76.03478628235665\n",
      "Iteration 525, the loss is 64.6802831571446, parameters k is 15.604609131236383 and b is -76.0337915889057\n",
      "Iteration 526, the loss is 64.67926935119002, parameters k is 15.604452764143396 and b is -76.03279691937438\n",
      "Iteration 527, the loss is 64.6782555939933, parameters k is 15.604296400810602 and b is -76.0318022737621\n",
      "Iteration 528, the loss is 64.6772418855521, parameters k is 15.604140041237914 and b is -76.03080765206828\n",
      "Iteration 529, the loss is 64.67622822586405, parameters k is 15.603983685425238 and b is -76.02981305429235\n",
      "Iteration 530, the loss is 64.67521461492683, parameters k is 15.603827333372486 and b is -76.02881848043374\n",
      "Iteration 531, the loss is 64.67420105273811, parameters k is 15.603670985079567 and b is -76.02782393049188\n",
      "Iteration 532, the loss is 64.6731875392955, parameters k is 15.603514640546392 and b is -76.02682940446618\n",
      "Iteration 533, the loss is 64.67217407459665, parameters k is 15.603358299772868 and b is -76.02583490235608\n",
      "Iteration 534, the loss is 64.67116065863928, parameters k is 15.603201962758908 and b is -76.024840424161\n",
      "Iteration 535, the loss is 64.67014729142112, parameters k is 15.603045629504418 and b is -76.02384596988036\n",
      "Iteration 536, the loss is 64.66913397293955, parameters k is 15.602889300009311 and b is -76.02285153951358\n",
      "Iteration 537, the loss is 64.66812070319241, parameters k is 15.602732974273493 and b is -76.0218571330601\n",
      "Iteration 538, the loss is 64.6671074821774, parameters k is 15.602576652296877 and b is -76.02086275051933\n",
      "Iteration 539, the loss is 64.66609430989209, parameters k is 15.602420334079369 and b is -76.0198683918907\n",
      "Iteration 540, the loss is 64.66508118633422, parameters k is 15.60226401962088 and b is -76.01887405717363\n",
      "Iteration 541, the loss is 64.66406811150125, parameters k is 15.602107708921322 and b is -76.01787974636757\n",
      "Iteration 542, the loss is 64.66305508539111, parameters k is 15.601951401980603 and b is -76.01688545947192\n",
      "Iteration 543, the loss is 64.66204210800122, parameters k is 15.601795098798632 and b is -76.01589119648611\n",
      "Iteration 544, the loss is 64.66102917932942, parameters k is 15.60163879937532 and b is -76.01489695740956\n",
      "Iteration 545, the loss is 64.6600162993732, parameters k is 15.601482503710573 and b is -76.01390274224171\n",
      "Iteration 546, the loss is 64.65900346813031, parameters k is 15.601326211804304 and b is -76.01290855098198\n",
      "Iteration 547, the loss is 64.65799068559846, parameters k is 15.601169923656423 and b is -76.01191438362979\n",
      "Iteration 548, the loss is 64.65697795177525, parameters k is 15.601013639266839 and b is -76.01092024018456\n",
      "Iteration 549, the loss is 64.6559652666582, parameters k is 15.600857358635459 and b is -76.00992612064573\n",
      "Iteration 550, the loss is 64.65495263024526, parameters k is 15.600701081762194 and b is -76.00893202501271\n",
      "Iteration 551, the loss is 64.65394004253388, parameters k is 15.600544808646957 and b is -76.00793795328494\n",
      "Iteration 552, the loss is 64.65292750352178, parameters k is 15.600388539289654 and b is -76.00694390546184\n",
      "Iteration 553, the loss is 64.65191501320656, parameters k is 15.600232273690194 and b is -76.00594988154283\n",
      "Iteration 554, the loss is 64.65090257158599, parameters k is 15.60007601184849 and b is -76.00495588152734\n",
      "Iteration 555, the loss is 64.64989017865757, parameters k is 15.59991975376445 and b is -76.00396190541478\n",
      "Iteration 556, the loss is 64.64887783441911, parameters k is 15.599763499437984 and b is -76.0029679532046\n",
      "Iteration 557, the loss is 64.64786553886823, parameters k is 15.599607248868999 and b is -76.00197402489621\n",
      "Iteration 558, the loss is 64.64685329200249, parameters k is 15.599451002057409 and b is -76.00098012048905\n",
      "Iteration 559, the loss is 64.64584109381963, parameters k is 15.59929475900312 and b is -75.99998623998252\n",
      "Iteration 560, the loss is 64.64482894431733, parameters k is 15.599138519706043 and b is -75.99899238337606\n",
      "Iteration 561, the loss is 64.6438168434932, parameters k is 15.59898228416609 and b is -75.99799855066911\n",
      "Iteration 562, the loss is 64.642804791345, parameters k is 15.598826052383165 and b is -75.99700474186108\n",
      "Iteration 563, the loss is 64.64179278787024, parameters k is 15.598669824357183 and b is -75.99601095695138\n",
      "Iteration 564, the loss is 64.6407808330666, parameters k is 15.59851360008805 and b is -75.99501719593945\n",
      "Iteration 565, the loss is 64.63976892693188, parameters k is 15.59835737957568 and b is -75.99402345882473\n",
      "Iteration 566, the loss is 64.63875706946361, parameters k is 15.598201162819977 and b is -75.99302974560662\n",
      "Iteration 567, the loss is 64.63774526065947, parameters k is 15.598044949820856 and b is -75.99203605628456\n",
      "Iteration 568, the loss is 64.63673350051715, parameters k is 15.597888740578224 and b is -75.99104239085797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 569, the loss is 64.63572178903435, parameters k is 15.59773253509199 and b is -75.99004874932628\n",
      "Iteration 570, the loss is 64.6347101262086, parameters k is 15.597576333362067 and b is -75.98905513168891\n",
      "Iteration 571, the loss is 64.63369851203765, parameters k is 15.59742013538836 and b is -75.9880615379453\n",
      "Iteration 572, the loss is 64.63268694651917, parameters k is 15.597263941170782 and b is -75.98706796809486\n",
      "Iteration 573, the loss is 64.63167542965074, parameters k is 15.597107750709242 and b is -75.98607442213702\n",
      "Iteration 574, the loss is 64.63066396143016, parameters k is 15.596951564003648 and b is -75.98508090007121\n",
      "Iteration 575, the loss is 64.62965254185501, parameters k is 15.596795381053912 and b is -75.98408740189684\n",
      "Iteration 576, the loss is 64.62864117092289, parameters k is 15.596639201859944 and b is -75.98309392761335\n",
      "Iteration 577, the loss is 64.62762984863147, parameters k is 15.596483026421652 and b is -75.98210047722016\n",
      "Iteration 578, the loss is 64.62661857497854, parameters k is 15.596326854738946 and b is -75.98110705071669\n",
      "Iteration 579, the loss is 64.62560734996165, parameters k is 15.596170686811735 and b is -75.98011364810237\n",
      "Iteration 580, the loss is 64.62459617357847, parameters k is 15.59601452263993 and b is -75.97912026937664\n",
      "Iteration 581, the loss is 64.62358504582669, parameters k is 15.59585836222344 and b is -75.9781269145389\n",
      "Iteration 582, the loss is 64.62257396670395, parameters k is 15.595702205562175 and b is -75.9771335835886\n",
      "Iteration 583, the loss is 64.62156293620795, parameters k is 15.595546052656044 and b is -75.97614027652514\n",
      "Iteration 584, the loss is 64.62055195433635, parameters k is 15.595389903504957 and b is -75.97514699334798\n",
      "Iteration 585, the loss is 64.61954102108677, parameters k is 15.595233758108824 and b is -75.97415373405651\n",
      "Iteration 586, the loss is 64.61853013645678, parameters k is 15.595077616467556 and b is -75.97316049865017\n",
      "Iteration 587, the loss is 64.61751930044433, parameters k is 15.59492147858106 and b is -75.9721672871284\n",
      "Iteration 588, the loss is 64.61650851304677, parameters k is 15.594765344449248 and b is -75.97117409949061\n",
      "Iteration 589, the loss is 64.61549777426194, parameters k is 15.59460921407203 and b is -75.97018093573622\n",
      "Iteration 590, the loss is 64.6144870840875, parameters k is 15.594453087449313 and b is -75.96918779586467\n",
      "Iteration 591, the loss is 64.61347644252098, parameters k is 15.594296964581009 and b is -75.96819467987538\n",
      "Iteration 592, the loss is 64.61246584956015, parameters k is 15.594140845467026 and b is -75.96720158776778\n",
      "Iteration 593, the loss is 64.61145530520263, parameters k is 15.593984730107275 and b is -75.96620851954128\n",
      "Iteration 594, the loss is 64.61044480944611, parameters k is 15.593828618501666 and b is -75.96521547519532\n",
      "Iteration 595, the loss is 64.60943436228833, parameters k is 15.593672510650109 and b is -75.96422245472932\n",
      "Iteration 596, the loss is 64.60842396372671, parameters k is 15.593516406552512 and b is -75.9632294581427\n",
      "Iteration 597, the loss is 64.60741361375925, parameters k is 15.593360306208785 and b is -75.96223648543491\n",
      "Iteration 598, the loss is 64.60640331238336, parameters k is 15.593204209618838 and b is -75.96124353660535\n",
      "Iteration 599, the loss is 64.60539305959678, parameters k is 15.593048116782581 and b is -75.96025061165346\n",
      "Iteration 600, the loss is 64.60438285539713, parameters k is 15.592892027699925 and b is -75.95925771057865\n",
      "Iteration 601, the loss is 64.60337269978217, parameters k is 15.592735942370778 and b is -75.95826483338037\n",
      "Iteration 602, the loss is 64.6023625927495, parameters k is 15.59257986079505 and b is -75.95727198005802\n",
      "Iteration 603, the loss is 64.60135253429675, parameters k is 15.59242378297265 and b is -75.95627915061105\n",
      "Iteration 604, the loss is 64.60034252442163, parameters k is 15.59226770890349 and b is -75.95528634503887\n",
      "Iteration 605, the loss is 64.59933256312183, parameters k is 15.592111638587479 and b is -75.95429356334091\n",
      "Iteration 606, the loss is 64.59832265039492, parameters k is 15.591955572024526 and b is -75.95330080551659\n",
      "Iteration 607, the loss is 64.5973127862387, parameters k is 15.59179950921454 and b is -75.95230807156535\n",
      "Iteration 608, the loss is 64.59630297065071, parameters k is 15.591643450157433 and b is -75.9513153614866\n",
      "Iteration 609, the loss is 64.59529320362874, parameters k is 15.591487394853111 and b is -75.95032267527979\n",
      "Iteration 610, the loss is 64.5942834851703, parameters k is 15.591331343301487 and b is -75.94933001294433\n",
      "Iteration 611, the loss is 64.59327381527314, parameters k is 15.59117529550247 and b is -75.94833737447964\n",
      "Iteration 612, the loss is 64.59226419393495, parameters k is 15.59101925145597 and b is -75.94734475988514\n",
      "Iteration 613, the loss is 64.59125462115338, parameters k is 15.590863211161897 and b is -75.94635216916028\n",
      "Iteration 614, the loss is 64.59024509692603, parameters k is 15.59070717462016 and b is -75.94535960230446\n",
      "Iteration 615, the loss is 64.58923562125061, parameters k is 15.59055114183067 and b is -75.94436705931713\n",
      "Iteration 616, the loss is 64.58822619412481, parameters k is 15.590395112793335 and b is -75.94337454019771\n",
      "Iteration 617, the loss is 64.5872168155463, parameters k is 15.590239087508065 and b is -75.94238204494562\n",
      "Iteration 618, the loss is 64.58620748551267, parameters k is 15.59008306597477 and b is -75.94138957356029\n",
      "Iteration 619, the loss is 64.58519820402165, parameters k is 15.589927048193362 and b is -75.94039712604113\n",
      "Iteration 620, the loss is 64.58418897107084, parameters k is 15.589771034163748 and b is -75.93940470238759\n",
      "Iteration 621, the loss is 64.58317978665801, parameters k is 15.58961502388584 and b is -75.93841230259909\n",
      "Iteration 622, the loss is 64.58217065078078, parameters k is 15.589459017359545 and b is -75.93741992667505\n",
      "Iteration 623, the loss is 64.58116156343677, parameters k is 15.589303014584774 and b is -75.9364275746149\n",
      "Iteration 624, the loss is 64.58015252462373, parameters k is 15.589147015561437 and b is -75.93543524641805\n",
      "Iteration 625, the loss is 64.57914353433914, parameters k is 15.588991020289445 and b is -75.93444294208395\n",
      "Iteration 626, the loss is 64.5781345925809, parameters k is 15.588835028768706 and b is -75.93345066161201\n",
      "Iteration 627, the loss is 64.57712569934655, parameters k is 15.58867904099913 and b is -75.93245840500168\n",
      "Iteration 628, the loss is 64.57611685463387, parameters k is 15.588523056980627 and b is -75.93146617225237\n",
      "Iteration 629, the loss is 64.57510805844038, parameters k is 15.588367076713107 and b is -75.9304739633635\n",
      "Iteration 630, the loss is 64.5740993107638, parameters k is 15.58821110019648 and b is -75.92948177833449\n",
      "Iteration 631, the loss is 64.57309061160186, parameters k is 15.588055127430655 and b is -75.92848961716479\n",
      "Iteration 632, the loss is 64.57208196095209, parameters k is 15.587899158415544 and b is -75.92749747985381\n",
      "Iteration 633, the loss is 64.57107335881223, parameters k is 15.587743193151054 and b is -75.92650536640099\n",
      "Iteration 634, the loss is 64.57006480517992, parameters k is 15.587587231637096 and b is -75.92551327680573\n",
      "Iteration 635, the loss is 64.56905630005302, parameters k is 15.58743127387358 and b is -75.92452121106749\n",
      "Iteration 636, the loss is 64.56804784342896, parameters k is 15.587275319860417 and b is -75.92352916918567\n",
      "Iteration 637, the loss is 64.56703943530545, parameters k is 15.587119369597515 and b is -75.9225371511597\n",
      "Iteration 638, the loss is 64.56603107568021, parameters k is 15.586963423084784 and b is -75.92154515698903\n",
      "Iteration 639, the loss is 64.56502276455092, parameters k is 15.586807480322134 and b is -75.92055318667305\n",
      "Iteration 640, the loss is 64.56401450191518, parameters k is 15.586651541309475 and b is -75.91956124021121\n",
      "Iteration 641, the loss is 64.56300628777076, parameters k is 15.586495606046716 and b is -75.91856931760293\n",
      "Iteration 642, the loss is 64.56199812211518, parameters k is 15.586339674533768 and b is -75.91757741884764\n",
      "Iteration 643, the loss is 64.56099000494623, parameters k is 15.58618374677054 and b is -75.91658554394476\n",
      "Iteration 644, the loss is 64.5599819362616, parameters k is 15.586027822756943 and b is -75.91559369289372\n",
      "Iteration 645, the loss is 64.55897391605878, parameters k is 15.585871902492885 and b is -75.91460186569395\n",
      "Iteration 646, the loss is 64.55796594433565, parameters k is 15.585715985978277 and b is -75.91361006234487\n",
      "Iteration 647, the loss is 64.55695802108974, parameters k is 15.58556007321303 and b is -75.91261828284591\n",
      "Iteration 648, the loss is 64.55595014631878, parameters k is 15.585404164197051 and b is -75.9116265271965\n",
      "Iteration 649, the loss is 64.55494232002049, parameters k is 15.585248258930253 and b is -75.91063479539606\n",
      "Iteration 650, the loss is 64.55393454219235, parameters k is 15.585092357412544 and b is -75.90964308744402\n",
      "Iteration 651, the loss is 64.55292681283221, parameters k is 15.584936459643833 and b is -75.90865140333982\n",
      "Iteration 652, the loss is 64.55191913193765, parameters k is 15.584780565624031 and b is -75.90765974308286\n",
      "Iteration 653, the loss is 64.55091149950643, parameters k is 15.584624675353048 and b is -75.90666810667258\n",
      "Iteration 654, the loss is 64.54990391553615, parameters k is 15.584468788830794 and b is -75.9056764941084\n",
      "Iteration 655, the loss is 64.54889638002443, parameters k is 15.584312906057178 and b is -75.90468490538976\n",
      "Iteration 656, the loss is 64.54788889296903, parameters k is 15.584157027032111 and b is -75.90369334051607\n",
      "Iteration 657, the loss is 64.54688145436756, parameters k is 15.584001151755501 and b is -75.90270179948676\n",
      "Iteration 658, the loss is 64.54587406421777, parameters k is 15.58384528022726 and b is -75.90171028230127\n",
      "Iteration 659, the loss is 64.5448667225172, parameters k is 15.583689412447297 and b is -75.90071878895901\n",
      "Iteration 660, the loss is 64.54385942926363, parameters k is 15.583533548415522 and b is -75.89972731945943\n",
      "Iteration 661, the loss is 64.54285218445473, parameters k is 15.583377688131844 and b is -75.89873587380194\n",
      "Iteration 662, the loss is 64.5418449880881, parameters k is 15.583221831596173 and b is -75.89774445198596\n",
      "Iteration 663, the loss is 64.54083784016144, parameters k is 15.58306597880842 and b is -75.89675305401093\n",
      "Iteration 664, the loss is 64.53983074067246, parameters k is 15.582910129768495 and b is -75.89576167987627\n",
      "Iteration 665, the loss is 64.53882368961875, parameters k is 15.582754284476307 and b is -75.8947703295814\n",
      "Iteration 666, the loss is 64.53781668699807, parameters k is 15.582598442931765 and b is -75.89377900312577\n",
      "Iteration 667, the loss is 64.53680973280805, parameters k is 15.582442605134782 and b is -75.89278770050879\n",
      "Iteration 668, the loss is 64.53580282704634, parameters k is 15.582286771085265 and b is -75.89179642172988\n",
      "Iteration 669, the loss is 64.5347959697106, parameters k is 15.582130940783124 and b is -75.89080516678848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 670, the loss is 64.53378916079862, parameters k is 15.58197511422827 and b is -75.88981393568402\n",
      "Iteration 671, the loss is 64.5327824003079, parameters k is 15.581819291420612 and b is -75.8888227284159\n",
      "Iteration 672, the loss is 64.53177568823621, parameters k is 15.58166347236006 and b is -75.88783154498357\n",
      "Iteration 673, the loss is 64.53076902458119, parameters k is 15.581507657046524 and b is -75.88684038538645\n",
      "Iteration 674, the loss is 64.52976240934052, parameters k is 15.581351845479915 and b is -75.88584924962397\n",
      "Iteration 675, the loss is 64.52875584251191, parameters k is 15.581196037660142 and b is -75.88485813769556\n",
      "Iteration 676, the loss is 64.52774932409304, parameters k is 15.581040233587114 and b is -75.88386704960064\n",
      "Iteration 677, the loss is 64.52674285408143, parameters k is 15.580884433260742 and b is -75.88287598533864\n",
      "Iteration 678, the loss is 64.5257364324749, parameters k is 15.580728636680936 and b is -75.88188494490899\n",
      "Iteration 679, the loss is 64.52473005927114, parameters k is 15.580572843847605 and b is -75.88089392831111\n",
      "Iteration 680, the loss is 64.52372373446771, parameters k is 15.58041705476066 and b is -75.87990293554444\n",
      "Iteration 681, the loss is 64.52271745806237, parameters k is 15.580261269420012 and b is -75.87891196660838\n",
      "Iteration 682, the loss is 64.52171123005269, parameters k is 15.580105487825568 and b is -75.87792102150239\n",
      "Iteration 683, the loss is 64.52070505043652, parameters k is 15.579949709977239 and b is -75.87693010022588\n",
      "Iteration 684, the loss is 64.51969891921144, parameters k is 15.579793935874935 and b is -75.87593920277827\n",
      "Iteration 685, the loss is 64.518692836375, parameters k is 15.579638165518567 and b is -75.874948329159\n",
      "Iteration 686, the loss is 64.51768680192505, parameters k is 15.579482398908043 and b is -75.87395747936749\n",
      "Iteration 687, the loss is 64.51668081585916, parameters k is 15.579326636043275 and b is -75.87296665340317\n",
      "Iteration 688, the loss is 64.51567487817499, parameters k is 15.579170876924172 and b is -75.87197585126546\n",
      "Iteration 689, the loss is 64.5146689888704, parameters k is 15.579015121550643 and b is -75.8709850729538\n",
      "Iteration 690, the loss is 64.51366314794282, parameters k is 15.578859369922599 and b is -75.86999431846762\n",
      "Iteration 691, the loss is 64.51265735539, parameters k is 15.57870362203995 and b is -75.86900358780633\n",
      "Iteration 692, the loss is 64.51165161120974, parameters k is 15.578547877902604 and b is -75.86801288096936\n",
      "Iteration 693, the loss is 64.51064591539958, parameters k is 15.578392137510473 and b is -75.86702219795615\n",
      "Iteration 694, the loss is 64.50964026795721, parameters k is 15.578236400863467 and b is -75.86603153876611\n",
      "Iteration 695, the loss is 64.50863466888033, parameters k is 15.578080667961496 and b is -75.86504090339868\n",
      "Iteration 696, the loss is 64.50762911816662, parameters k is 15.577924938804468 and b is -75.86405029185329\n",
      "Iteration 697, the loss is 64.50662361581375, parameters k is 15.577769213392296 and b is -75.86305970412936\n",
      "Iteration 698, the loss is 64.50561816181934, parameters k is 15.577613491724888 and b is -75.86206914022631\n",
      "Iteration 699, the loss is 64.50461275618112, parameters k is 15.577457773802154 and b is -75.86107860014357\n",
      "Iteration 700, the loss is 64.50360739889678, parameters k is 15.577302059624003 and b is -75.86008808388058\n",
      "Iteration 701, the loss is 64.50260208996393, parameters k is 15.577146349190347 and b is -75.85909759143676\n",
      "Iteration 702, the loss is 64.50159682938033, parameters k is 15.576990642501094 and b is -75.85810712281153\n",
      "Iteration 703, the loss is 64.50059161714356, parameters k is 15.576834939556157 and b is -75.85711667800433\n",
      "Iteration 704, the loss is 64.49958645325131, parameters k is 15.576679240355443 and b is -75.85612625701458\n",
      "Iteration 705, the loss is 64.49858133770138, parameters k is 15.576523544898862 and b is -75.8551358598417\n",
      "Iteration 706, the loss is 64.49757627049131, parameters k is 15.576367853186326 and b is -75.85414548648512\n",
      "Iteration 707, the loss is 64.4965712516188, parameters k is 15.576212165217743 and b is -75.85315513694428\n",
      "Iteration 708, the loss is 64.49556628108154, parameters k is 15.576056480993024 and b is -75.8521648112186\n",
      "Iteration 709, the loss is 64.49456135887725, parameters k is 15.57590080051208 and b is -75.85117450930751\n",
      "Iteration 710, the loss is 64.49355648500352, parameters k is 15.57574512377482 and b is -75.85018423121043\n",
      "Iteration 711, the loss is 64.49255165945807, parameters k is 15.575589450781152 and b is -75.8491939769268\n",
      "Iteration 712, the loss is 64.4915468822386, parameters k is 15.575433781530988 and b is -75.84820374645604\n",
      "Iteration 713, the loss is 64.49054215334274, parameters k is 15.575278116024238 and b is -75.84721353979756\n",
      "Iteration 714, the loss is 64.48953747276815, parameters k is 15.575122454260812 and b is -75.84622335695082\n",
      "Iteration 715, the loss is 64.48853284051259, parameters k is 15.57496679624062 and b is -75.84523319791522\n",
      "Iteration 716, the loss is 64.48752825657368, parameters k is 15.574811141963572 and b is -75.8442430626902\n",
      "Iteration 717, the loss is 64.48652372094912, parameters k is 15.574655491429576 and b is -75.84325295127518\n",
      "Iteration 718, the loss is 64.48551923363652, parameters k is 15.574499844638545 and b is -75.84226286366959\n",
      "Iteration 719, the loss is 64.48451479463365, parameters k is 15.574344201590387 and b is -75.84127279987287\n",
      "Iteration 720, the loss is 64.48351040393815, parameters k is 15.574188562285013 and b is -75.84028275988443\n",
      "Iteration 721, the loss is 64.48250606154765, parameters k is 15.574032926722332 and b is -75.83929274370371\n",
      "Iteration 722, the loss is 64.4815017674599, parameters k is 15.573877294902255 and b is -75.83830275133013\n",
      "Iteration 723, the loss is 64.4804975216725, parameters k is 15.57372166682469 and b is -75.83731278276314\n",
      "Iteration 724, the loss is 64.4794933241832, parameters k is 15.573566042489551 and b is -75.83632283800213\n",
      "Iteration 725, the loss is 64.47848917498966, parameters k is 15.573410421896744 and b is -75.83533291704656\n",
      "Iteration 726, the loss is 64.47748507408953, parameters k is 15.573254805046181 and b is -75.83434301989583\n",
      "Iteration 727, the loss is 64.4764810214805, parameters k is 15.573099191937771 and b is -75.83335314654938\n",
      "Iteration 728, the loss is 64.47547701716026, parameters k is 15.572943582571426 and b is -75.83236329700665\n",
      "Iteration 729, the loss is 64.47447306112646, parameters k is 15.572787976947055 and b is -75.83137347126706\n",
      "Iteration 730, the loss is 64.47346915337683, parameters k is 15.572632375064567 and b is -75.83038366933002\n",
      "Iteration 731, the loss is 64.47246529390894, parameters k is 15.572476776923873 and b is -75.82939389119497\n",
      "Iteration 732, the loss is 64.4714614827206, parameters k is 15.572321182524881 and b is -75.82840413686134\n",
      "Iteration 733, the loss is 64.47045771980939, parameters k is 15.572165591867504 and b is -75.82741440632856\n",
      "Iteration 734, the loss is 64.46945400517313, parameters k is 15.57201000495165 and b is -75.82642469959605\n",
      "Iteration 735, the loss is 64.46845033880932, parameters k is 15.57185442177723 and b is -75.82543501666325\n",
      "Iteration 736, the loss is 64.46744672071566, parameters k is 15.571698842344155 and b is -75.82444535752957\n",
      "Iteration 737, the loss is 64.46644315089002, parameters k is 15.571543266652332 and b is -75.82345572219445\n",
      "Iteration 738, the loss is 64.46543962932982, parameters k is 15.571387694701674 and b is -75.82246611065732\n",
      "Iteration 739, the loss is 64.46443615603292, parameters k is 15.57123212649209 and b is -75.82147652291759\n",
      "Iteration 740, the loss is 64.46343273099687, parameters k is 15.571076562023489 and b is -75.82048695897471\n",
      "Iteration 741, the loss is 64.4624293542195, parameters k is 15.570921001295783 and b is -75.8194974188281\n",
      "Iteration 742, the loss is 64.46142602569836, parameters k is 15.570765444308881 and b is -75.8185079024772\n",
      "Iteration 743, the loss is 64.46042274543123, parameters k is 15.570609891062693 and b is -75.8175184099214\n",
      "Iteration 744, the loss is 64.45941951341571, parameters k is 15.570454341557129 and b is -75.81652894116017\n",
      "Iteration 745, the loss is 64.45841632964951, parameters k is 15.5702987957921 and b is -75.81553949619291\n",
      "Iteration 746, the loss is 64.45741319413028, parameters k is 15.570143253767514 and b is -75.81455007501906\n",
      "Iteration 747, the loss is 64.45641010685569, parameters k is 15.569987715483283 and b is -75.81356067763804\n",
      "Iteration 748, the loss is 64.45540706782349, parameters k is 15.569832180939315 and b is -75.81257130404929\n",
      "Iteration 749, the loss is 64.45440407703133, parameters k is 15.569676650135522 and b is -75.81158195425222\n",
      "Iteration 750, the loss is 64.45340113447689, parameters k is 15.569521123071814 and b is -75.81059262824627\n",
      "Iteration 751, the loss is 64.45239824015783, parameters k is 15.5693655997481 and b is -75.80960332603087\n",
      "Iteration 752, the loss is 64.45139539407187, parameters k is 15.569210080164291 and b is -75.80861404760545\n",
      "Iteration 753, the loss is 64.45039259621663, parameters k is 15.569054564320297 and b is -75.80762479296942\n",
      "Iteration 754, the loss is 64.44938984658985, parameters k is 15.568899052216027 and b is -75.80663556212222\n",
      "Iteration 755, the loss is 64.44838714518919, parameters k is 15.568743543851392 and b is -75.80564635506329\n",
      "Iteration 756, the loss is 64.44738449201229, parameters k is 15.568588039226302 and b is -75.80465717179204\n",
      "Iteration 757, the loss is 64.4463818870569, parameters k is 15.568432538340668 and b is -75.80366801230791\n",
      "Iteration 758, the loss is 64.44537933032062, parameters k is 15.568277041194397 and b is -75.80267887661032\n",
      "Iteration 759, the loss is 64.4443768218012, parameters k is 15.568121547787403 and b is -75.8016897646987\n",
      "Iteration 760, the loss is 64.44337436149632, parameters k is 15.567966058119593 and b is -75.80070067657248\n",
      "Iteration 761, the loss is 64.44237194940364, parameters k is 15.567810572190877 and b is -75.79971161223108\n",
      "Iteration 762, the loss is 64.44136958552076, parameters k is 15.567655090001168 and b is -75.79872257167393\n",
      "Iteration 763, the loss is 64.4403672698456, parameters k is 15.567499611550375 and b is -75.79773355490047\n",
      "Iteration 764, the loss is 64.43936500237555, parameters k is 15.567344136838406 and b is -75.79674456191012\n",
      "Iteration 765, the loss is 64.4383627831085, parameters k is 15.567188665865173 and b is -75.7957555927023\n",
      "Iteration 766, the loss is 64.437360612042, parameters k is 15.567033198630586 and b is -75.79476664727646\n",
      "Iteration 767, the loss is 64.43635848917384, parameters k is 15.566877735134554 and b is -75.79377772563201\n",
      "Iteration 768, the loss is 64.43535641450164, parameters k is 15.56672227537699 and b is -75.79278882776838\n",
      "Iteration 769, the loss is 64.43435438802305, parameters k is 15.5665668193578 and b is -75.791799953685\n",
      "Iteration 770, the loss is 64.43335240973587, parameters k is 15.566411367076896 and b is -75.7908111033813\n",
      "Iteration 771, the loss is 64.4323504796376, parameters k is 15.566255918534189 and b is -75.78982227685671\n",
      "Iteration 772, the loss is 64.43134859772614, parameters k is 15.566100473729588 and b is -75.78883347411065\n",
      "Iteration 773, the loss is 64.43034676399904, parameters k is 15.565945032663004 and b is -75.78784469514255\n",
      "Iteration 774, the loss is 64.42934497845397, parameters k is 15.565789595334346 and b is -75.78685593995185\n",
      "Iteration 775, the loss is 64.42834324108863, parameters k is 15.565634161743525 and b is -75.78586720853797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 776, the loss is 64.42734155190075, parameters k is 15.56547873189045 and b is -75.78487850090033\n",
      "Iteration 777, the loss is 64.42633991088799, parameters k is 15.565323305775031 and b is -75.78388981703837\n",
      "Iteration 778, the loss is 64.42533831804798, parameters k is 15.56516788339718 and b is -75.78290115695151\n",
      "Iteration 779, the loss is 64.42433677337849, parameters k is 15.565012464756807 and b is -75.78191252063918\n",
      "Iteration 780, the loss is 64.42333527687718, parameters k is 15.56485704985382 and b is -75.78092390810082\n",
      "Iteration 781, the loss is 64.42233382854172, parameters k is 15.564701638688131 and b is -75.77993531933585\n",
      "Iteration 782, the loss is 64.42133242836978, parameters k is 15.56454623125965 and b is -75.77894675434369\n",
      "Iteration 783, the loss is 64.42033107635908, parameters k is 15.564390827568285 and b is -75.77795821312378\n",
      "Iteration 784, the loss is 64.41932977250723, parameters k is 15.56423542761395 and b is -75.77696969567555\n",
      "Iteration 785, the loss is 64.41832851681195, parameters k is 15.564080031396552 and b is -75.77598120199842\n",
      "Iteration 786, the loss is 64.41732730927096, parameters k is 15.563924638916001 and b is -75.77499273209182\n",
      "Iteration 787, the loss is 64.4163261498819, parameters k is 15.563769250172209 and b is -75.77400428595517\n",
      "Iteration 788, the loss is 64.41532503864255, parameters k is 15.563613865165085 and b is -75.77301586358791\n",
      "Iteration 789, the loss is 64.41432397555046, parameters k is 15.56345848389454 and b is -75.77202746498948\n",
      "Iteration 790, the loss is 64.41332296060337, parameters k is 15.563303106360483 and b is -75.77103909015929\n",
      "Iteration 791, the loss is 64.41232199379895, parameters k is 15.563147732562824 and b is -75.77005073909677\n",
      "Iteration 792, the loss is 64.41132107513496, parameters k is 15.562992362501474 and b is -75.76906241180136\n",
      "Iteration 793, the loss is 64.41032020460896, parameters k is 15.562836996176342 and b is -75.76807410827247\n",
      "Iteration 794, the loss is 64.40931938221878, parameters k is 15.56268163358734 and b is -75.76708582850955\n",
      "Iteration 795, the loss is 64.40831860796195, parameters k is 15.562526274734378 and b is -75.76609757251201\n",
      "Iteration 796, the loss is 64.40731788183626, parameters k is 15.562370919617365 and b is -75.76510934027928\n",
      "Iteration 797, the loss is 64.4063172038393, parameters k is 15.562215568236212 and b is -75.7641211318108\n",
      "Iteration 798, the loss is 64.40531657396896, parameters k is 15.562060220590828 and b is -75.76313294710599\n",
      "Iteration 799, the loss is 64.40431599222273, parameters k is 15.561904876681124 and b is -75.76214478616428\n",
      "Iteration 800, the loss is 64.40331545859831, parameters k is 15.561749536507012 and b is -75.76115664898511\n",
      "Iteration 801, the loss is 64.40231497309345, parameters k is 15.561594200068399 and b is -75.76016853556789\n",
      "Iteration 802, the loss is 64.40131453570588, parameters k is 15.561438867365197 and b is -75.75918044591205\n",
      "Iteration 803, the loss is 64.40031414643315, parameters k is 15.561283538397316 and b is -75.75819238001704\n",
      "Iteration 804, the loss is 64.399313805273, parameters k is 15.561128213164665 and b is -75.75720433788227\n",
      "Iteration 805, the loss is 64.39831351222317, parameters k is 15.560972891667156 and b is -75.75621631950717\n",
      "Iteration 806, the loss is 64.39731326728136, parameters k is 15.560817573904698 and b is -75.75522832489118\n",
      "Iteration 807, the loss is 64.39631307044505, parameters k is 15.560662259877201 and b is -75.75424035403371\n",
      "Iteration 808, the loss is 64.39531292171216, parameters k is 15.560506949584576 and b is -75.75325240693421\n",
      "Iteration 809, the loss is 64.39431282108039, parameters k is 15.560351643026733 and b is -75.75226448359209\n",
      "Iteration 810, the loss is 64.39331276854725, parameters k is 15.560196340203582 and b is -75.75127658400679\n",
      "Iteration 811, the loss is 64.3923127641105, parameters k is 15.560041041115033 and b is -75.75028870817773\n",
      "Iteration 812, the loss is 64.39131280776787, parameters k is 15.559885745760996 and b is -75.74930085610436\n",
      "Iteration 813, the loss is 64.39031289951701, parameters k is 15.55973045414138 and b is -75.74831302778607\n",
      "Iteration 814, the loss is 64.38931303935559, parameters k is 15.5595751662561 and b is -75.74732522322232\n",
      "Iteration 815, the loss is 64.38831322728136, parameters k is 15.559419882105061 and b is -75.74633744241252\n",
      "Iteration 816, the loss is 64.38731346329195, parameters k is 15.559264601688175 and b is -75.74534968535612\n",
      "Iteration 817, the loss is 64.38631374738502, parameters k is 15.559109325005354 and b is -75.74436195205253\n",
      "Iteration 818, the loss is 64.38531407955831, parameters k is 15.558954052056505 and b is -75.74337424250119\n",
      "Iteration 819, the loss is 64.38431445980959, parameters k is 15.558798782841539 and b is -75.74238655670153\n",
      "Iteration 820, the loss is 64.38331488813634, parameters k is 15.558643517360368 and b is -75.74139889465297\n",
      "Iteration 821, the loss is 64.38231536453645, parameters k is 15.5584882556129 and b is -75.74041125635495\n",
      "Iteration 822, the loss is 64.38131588900748, parameters k is 15.558332997599047 and b is -75.73942364180688\n",
      "Iteration 823, the loss is 64.3803164615472, parameters k is 15.55817774331872 and b is -75.73843605100821\n",
      "Iteration 824, the loss is 64.37931708215322, parameters k is 15.558022492771826 and b is -75.73744848395836\n",
      "Iteration 825, the loss is 64.3783177508232, parameters k is 15.557867245958278 and b is -75.73646094065676\n",
      "Iteration 826, the loss is 64.377318467555, parameters k is 15.557712002877985 and b is -75.73547342110282\n",
      "Iteration 827, the loss is 64.37631923234618, parameters k is 15.557556763530858 and b is -75.734485925296\n",
      "Iteration 828, the loss is 64.37532004519448, parameters k is 15.557401527916806 and b is -75.73349845323571\n",
      "Iteration 829, the loss is 64.37432090609751, parameters k is 15.557246296035741 and b is -75.73251100492139\n",
      "Iteration 830, the loss is 64.373321815053, parameters k is 15.557091067887571 and b is -75.73152358035246\n",
      "Iteration 831, the loss is 64.37232277205872, parameters k is 15.556935843472207 and b is -75.73053617952836\n",
      "Iteration 832, the loss is 64.3713237771123, parameters k is 15.55678062278956 and b is -75.7295488024485\n",
      "Iteration 833, the loss is 64.37032483021132, parameters k is 15.55662540583954 and b is -75.72856144911233\n",
      "Iteration 834, the loss is 64.36932593135361, parameters k is 15.556470192622058 and b is -75.72757411951926\n",
      "Iteration 835, the loss is 64.3683270805368, parameters k is 15.556314983137023 and b is -75.72658681366873\n",
      "Iteration 836, the loss is 64.3673282777586, parameters k is 15.556159777384346 and b is -75.72559953156016\n",
      "Iteration 837, the loss is 64.3663295230167, parameters k is 15.556004575363938 and b is -75.724612273193\n",
      "Iteration 838, the loss is 64.36533081630883, parameters k is 15.555849377075706 and b is -75.72362503856667\n",
      "Iteration 839, the loss is 64.36433215763259, parameters k is 15.555694182519563 and b is -75.72263782768059\n",
      "Iteration 840, the loss is 64.36333354698571, parameters k is 15.55553899169542 and b is -75.72165064053418\n",
      "Iteration 841, the loss is 64.36233498436593, parameters k is 15.555383804603183 and b is -75.72066347712689\n",
      "Iteration 842, the loss is 64.36133646977088, parameters k is 15.555228621242767 and b is -75.71967633745814\n",
      "Iteration 843, the loss is 64.36033800319824, parameters k is 15.55507344161408 and b is -75.71868922152737\n",
      "Iteration 844, the loss is 64.35933958464568, parameters k is 15.554918265717033 and b is -75.717702129334\n",
      "Iteration 845, the loss is 64.35834121411105, parameters k is 15.554763093551536 and b is -75.71671506087745\n",
      "Iteration 846, the loss is 64.35734289159181, parameters k is 15.554607925117498 and b is -75.71572801615716\n",
      "Iteration 847, the loss is 64.35634461708585, parameters k is 15.554452760414831 and b is -75.71474099517256\n",
      "Iteration 848, the loss is 64.35534639059075, parameters k is 15.554297599443446 and b is -75.71375399792308\n",
      "Iteration 849, the loss is 64.35434821210424, parameters k is 15.55414244220325 and b is -75.71276702440814\n",
      "Iteration 850, the loss is 64.35335008162401, parameters k is 15.553987288694158 and b is -75.71178007462717\n",
      "Iteration 851, the loss is 64.3523519991477, parameters k is 15.553832138916075 and b is -75.71079314857961\n",
      "Iteration 852, the loss is 64.35135396467311, parameters k is 15.553676992868915 and b is -75.70980624626489\n",
      "Iteration 853, the loss is 64.35035597819775, parameters k is 15.553521850552587 and b is -75.70881936768244\n",
      "Iteration 854, the loss is 64.34935803971956, parameters k is 15.553366711967001 and b is -75.70783251283167\n",
      "Iteration 855, the loss is 64.348360149236, parameters k is 15.553211577112068 and b is -75.70684568171202\n",
      "Iteration 856, the loss is 64.34736230674494, parameters k is 15.553056445987698 and b is -75.70585887432293\n",
      "Iteration 857, the loss is 64.34636451224395, parameters k is 15.5529013185938 and b is -75.70487209066381\n",
      "Iteration 858, the loss is 64.34536676573073, parameters k is 15.552746194930288 and b is -75.70388533073411\n",
      "Iteration 859, the loss is 64.34436906720313, parameters k is 15.552591074997068 and b is -75.70289859453325\n",
      "Iteration 860, the loss is 64.34337141665856, parameters k is 15.552435958794053 and b is -75.70191188206066\n",
      "Iteration 861, the loss is 64.34237381409496, parameters k is 15.552280846321151 and b is -75.70092519331575\n",
      "Iteration 862, the loss is 64.3413762595099, parameters k is 15.552125737578276 and b is -75.69993852829799\n",
      "Iteration 863, the loss is 64.34037875290112, parameters k is 15.551970632565334 and b is -75.69895188700679\n",
      "Iteration 864, the loss is 64.33938129426629, parameters k is 15.551815531282239 and b is -75.69796526944157\n",
      "Iteration 865, the loss is 64.33838388360314, parameters k is 15.551660433728898 and b is -75.69697867560176\n",
      "Iteration 866, the loss is 64.33738652090928, parameters k is 15.551505339905225 and b is -75.6959921054868\n",
      "Iteration 867, the loss is 64.3363892061825, parameters k is 15.551350249811128 and b is -75.6950055590961\n",
      "Iteration 868, the loss is 64.3353919394204, parameters k is 15.551195163446517 and b is -75.69401903642913\n",
      "Iteration 869, the loss is 64.33439472062078, parameters k is 15.551040080811303 and b is -75.69303253748528\n",
      "Iteration 870, the loss is 64.33339754978128, parameters k is 15.550885001905396 and b is -75.692046062264\n",
      "Iteration 871, the loss is 64.33240042689948, parameters k is 15.550729926728707 and b is -75.69105961076471\n",
      "Iteration 872, the loss is 64.3314033519733, parameters k is 15.550574855281145 and b is -75.69007318298684\n",
      "Iteration 873, the loss is 64.3304063250003, parameters k is 15.550419787562621 and b is -75.68908677892982\n",
      "Iteration 874, the loss is 64.32940934597816, parameters k is 15.550264723573047 and b is -75.68810039859308\n",
      "Iteration 875, the loss is 64.32841241490463, parameters k is 15.55010966331233 and b is -75.68711404197606\n",
      "Iteration 876, the loss is 64.32741553177742, parameters k is 15.549954606780384 and b is -75.68612770907818\n",
      "Iteration 877, the loss is 64.32641869659406, parameters k is 15.549799553977117 and b is -75.68514139989887\n",
      "Iteration 878, the loss is 64.32542190935244, parameters k is 15.549644504902439 and b is -75.68415511443756\n",
      "Iteration 879, the loss is 64.32442517005019, parameters k is 15.549489459556261 and b is -75.68316885269367\n",
      "Iteration 880, the loss is 64.32342847868499, parameters k is 15.549334417938494 and b is -75.68218261466664\n",
      "Iteration 881, the loss is 64.32243183525448, parameters k is 15.549179380049049 and b is -75.6811964003559\n",
      "Iteration 882, the loss is 64.32143523975647, parameters k is 15.549024345887835 and b is -75.68021020976089\n",
      "Iteration 883, the loss is 64.32043869218856, parameters k is 15.548869315454763 and b is -75.67922404288102\n",
      "Iteration 884, the loss is 64.31944219254855, parameters k is 15.548714288749741 and b is -75.67823789971573\n",
      "Iteration 885, the loss is 64.31844574083404, parameters k is 15.548559265772683 and b is -75.67725178026444\n",
      "Iteration 886, the loss is 64.31744933704272, parameters k is 15.548404246523496 and b is -75.6762656845266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 887, the loss is 64.31645298117232, parameters k is 15.548249231002094 and b is -75.67527961250163\n",
      "Iteration 888, the loss is 64.31545667322057, parameters k is 15.548094219208384 and b is -75.67429356418894\n",
      "Iteration 889, the loss is 64.31446041318515, parameters k is 15.547939211142278 and b is -75.673307539588\n",
      "Iteration 890, the loss is 64.31346420106368, parameters k is 15.547784206803685 and b is -75.6723215386982\n",
      "Iteration 891, the loss is 64.31246803685394, parameters k is 15.547629206192518 and b is -75.67133556151899\n",
      "Iteration 892, the loss is 64.3114719205536, parameters k is 15.547474209308685 and b is -75.67034960804979\n",
      "Iteration 893, the loss is 64.31047585216034, parameters k is 15.547319216152097 and b is -75.66936367829004\n",
      "Iteration 894, the loss is 64.30947983167184, parameters k is 15.547164226722664 and b is -75.66837777223917\n",
      "Iteration 895, the loss is 64.30848385908584, parameters k is 15.547009241020298 and b is -75.6673918898966\n",
      "Iteration 896, the loss is 64.30748793440003, parameters k is 15.546854259044908 and b is -75.66640603126177\n",
      "Iteration 897, the loss is 64.30649205761215, parameters k is 15.546699280796405 and b is -75.66542019633411\n",
      "Iteration 898, the loss is 64.30549622871972, parameters k is 15.546544306274699 and b is -75.66443438511304\n",
      "Iteration 899, the loss is 64.30450044772067, parameters k is 15.5463893354797 and b is -75.66344859759799\n",
      "Iteration 900, the loss is 64.30350471461252, parameters k is 15.54623436841132 and b is -75.66246283378841\n",
      "Iteration 901, the loss is 64.3025090293931, parameters k is 15.546079405069467 and b is -75.66147709368371\n",
      "Iteration 902, the loss is 64.30151339206, parameters k is 15.545924445454052 and b is -75.66049137728332\n",
      "Iteration 903, the loss is 64.30051780261095, parameters k is 15.545769489564986 and b is -75.65950568458668\n",
      "Iteration 904, the loss is 64.29952226104366, parameters k is 15.54561453740218 and b is -75.65852001559321\n",
      "Iteration 905, the loss is 64.29852676735582, parameters k is 15.545459588965544 and b is -75.65753437030234\n",
      "Iteration 906, the loss is 64.29753132154514, parameters k is 15.545304644254987 and b is -75.65654874871352\n",
      "Iteration 907, the loss is 64.29653592360926, parameters k is 15.54514970327042 and b is -75.65556315082615\n",
      "Iteration 908, the loss is 64.29554057354598, parameters k is 15.544994766011754 and b is -75.6545775766397\n",
      "Iteration 909, the loss is 64.2945452713529, parameters k is 15.544839832478901 and b is -75.65359202615356\n",
      "Iteration 910, the loss is 64.29355001702781, parameters k is 15.54468490267177 and b is -75.65260649936718\n",
      "Iteration 911, the loss is 64.29255481056832, parameters k is 15.54452997659027 and b is -75.65162099627999\n",
      "Iteration 912, the loss is 64.29155965197215, parameters k is 15.544375054234314 and b is -75.65063551689141\n",
      "Iteration 913, the loss is 64.2905645412371, parameters k is 15.54422013560381 and b is -75.64965006120087\n",
      "Iteration 914, the loss is 64.28956947836068, parameters k is 15.54406522069867 and b is -75.64866462920781\n",
      "Iteration 915, the loss is 64.28857446334071, parameters k is 15.543910309518802 and b is -75.64767922091166\n",
      "Iteration 916, the loss is 64.28757949617489, parameters k is 15.54375540206412 and b is -75.64669383631184\n",
      "Iteration 917, the loss is 64.28658457686088, parameters k is 15.54360049833453 and b is -75.64570847540779\n",
      "Iteration 918, the loss is 64.28558970539638, parameters k is 15.543445598329948 and b is -75.64472313819893\n",
      "Iteration 919, the loss is 64.28459488177914, parameters k is 15.54329070205028 and b is -75.6437378246847\n",
      "Iteration 920, the loss is 64.28360010600676, parameters k is 15.543135809495437 and b is -75.64275253486454\n",
      "Iteration 921, the loss is 64.28260537807714, parameters k is 15.542980920665332 and b is -75.64176726873787\n",
      "Iteration 922, the loss is 64.28161069798776, parameters k is 15.542826035559873 and b is -75.6407820263041\n",
      "Iteration 923, the loss is 64.28061606573634, parameters k is 15.542671154178972 and b is -75.63979680756267\n",
      "Iteration 924, the loss is 64.27962148132069, parameters k is 15.542516276522537 and b is -75.63881161251304\n",
      "Iteration 925, the loss is 64.27862694473848, parameters k is 15.542361402590481 and b is -75.6378264411546\n",
      "Iteration 926, the loss is 64.27763245598729, parameters k is 15.542206532382714 and b is -75.63684129348681\n",
      "Iteration 927, the loss is 64.276638015065, parameters k is 15.542051665899146 and b is -75.63585616950908\n",
      "Iteration 928, the loss is 64.27564362196922, parameters k is 15.541896803139688 and b is -75.63487106922086\n",
      "Iteration 929, the loss is 64.27464927669769, parameters k is 15.541741944104249 and b is -75.63388599262157\n",
      "Iteration 930, the loss is 64.27365497924808, parameters k is 15.54158708879274 and b is -75.63290093971064\n",
      "Iteration 931, the loss is 64.27266072961798, parameters k is 15.541432237205072 and b is -75.63191591048749\n",
      "Iteration 932, the loss is 64.2716665278053, parameters k is 15.541277389341154 and b is -75.63093090495157\n",
      "Iteration 933, the loss is 64.27067237380759, parameters k is 15.5411225452009 and b is -75.6299459231023\n",
      "Iteration 934, the loss is 64.26967826762258, parameters k is 15.540967704784215 and b is -75.62896096493911\n",
      "Iteration 935, the loss is 64.26868420924801, parameters k is 15.540812868091015 and b is -75.62797603046143\n",
      "Iteration 936, the loss is 64.2676901986816, parameters k is 15.540658035121208 and b is -75.62699111966869\n",
      "Iteration 937, the loss is 64.26669623592096, parameters k is 15.540503205874703 and b is -75.62600623256033\n",
      "Iteration 938, the loss is 64.26570232096383, parameters k is 15.540348380351412 and b is -75.62502136913577\n",
      "Iteration 939, the loss is 64.26470845380796, parameters k is 15.540193558551247 and b is -75.62403652939444\n",
      "Iteration 940, the loss is 64.26371463445105, parameters k is 15.540038740474115 and b is -75.62305171333578\n",
      "Iteration 941, the loss is 64.26272086289066, parameters k is 15.539883926119929 and b is -75.62206692095921\n",
      "Iteration 942, the loss is 64.26172713912469, parameters k is 15.5397291154886 and b is -75.62108215226417\n",
      "Iteration 943, the loss is 64.2607334631506, parameters k is 15.539574308580036 and b is -75.62009740725007\n",
      "Iteration 944, the loss is 64.25973983496641, parameters k is 15.539419505394148 and b is -75.61911268591638\n",
      "Iteration 945, the loss is 64.25874625456953, parameters k is 15.539264705930849 and b is -75.61812798826249\n",
      "Iteration 946, the loss is 64.25775272195791, parameters k is 15.539109910190048 and b is -75.61714331428784\n",
      "Iteration 947, the loss is 64.25675923712892, parameters k is 15.538955118171653 and b is -75.61615866399188\n",
      "Iteration 948, the loss is 64.25576580008062, parameters k is 15.538800329875578 and b is -75.61517403737403\n",
      "Iteration 949, the loss is 64.25477241081059, parameters k is 15.538645545301732 and b is -75.61418943443373\n",
      "Iteration 950, the loss is 64.25377906931638, parameters k is 15.538490764450025 and b is -75.61320485517038\n",
      "Iteration 951, the loss is 64.25278577559587, parameters k is 15.538335987320368 and b is -75.61222029958344\n",
      "Iteration 952, the loss is 64.25179252964668, parameters k is 15.538181213912672 and b is -75.61123576767233\n",
      "Iteration 953, the loss is 64.25079933146651, parameters k is 15.538026444226848 and b is -75.61025125943648\n",
      "Iteration 954, the loss is 64.2498061810532, parameters k is 15.537871678262805 and b is -75.60926677487532\n",
      "Iteration 955, the loss is 64.24881307840423, parameters k is 15.537716916020456 and b is -75.60828231398828\n",
      "Iteration 956, the loss is 64.24782002351749, parameters k is 15.537562157499709 and b is -75.60729787677481\n",
      "Iteration 957, the loss is 64.24682701639057, parameters k is 15.537407402700474 and b is -75.60631346323432\n",
      "Iteration 958, the loss is 64.24583405702117, parameters k is 15.537252651622664 and b is -75.60532907336624\n",
      "Iteration 959, the loss is 64.24484114540711, parameters k is 15.537097904266187 and b is -75.60434470717\n",
      "Iteration 960, the loss is 64.243848281546, parameters k is 15.536943160630955 and b is -75.60336036464504\n",
      "Iteration 961, the loss is 64.24285546543548, parameters k is 15.536788420716878 and b is -75.60237604579079\n",
      "Iteration 962, the loss is 64.24186269707344, parameters k is 15.536633684523867 and b is -75.60139175060668\n",
      "Iteration 963, the loss is 64.24086997645742, parameters k is 15.536478952051832 and b is -75.60040747909214\n",
      "Iteration 964, the loss is 64.23987730358517, parameters k is 15.536324223300683 and b is -75.5994232312466\n",
      "Iteration 965, the loss is 64.23888467845444, parameters k is 15.536169498270333 and b is -75.59843900706949\n",
      "Iteration 966, the loss is 64.23789210106293, parameters k is 15.53601477696069 and b is -75.59745480656024\n",
      "Iteration 967, the loss is 64.23689957140826, parameters k is 15.535860059371664 and b is -75.59647062971828\n",
      "Iteration 968, the loss is 64.23590708948814, parameters k is 15.53570534550317 and b is -75.59548647654304\n",
      "Iteration 969, the loss is 64.23491465530044, parameters k is 15.535550635355113 and b is -75.59450234703397\n",
      "Iteration 970, the loss is 64.23392226884262, parameters k is 15.535395928927407 and b is -75.59351824119047\n",
      "Iteration 971, the loss is 64.23292993011256, parameters k is 15.535241226219961 and b is -75.59253415901199\n",
      "Iteration 972, the loss is 64.23193763910793, parameters k is 15.535086527232686 and b is -75.59155010049795\n",
      "Iteration 973, the loss is 64.23094539582642, parameters k is 15.534931831965492 and b is -75.5905660656478\n",
      "Iteration 974, the loss is 64.2299532002657, parameters k is 15.534777140418292 and b is -75.58958205446096\n",
      "Iteration 975, the loss is 64.22896105242359, parameters k is 15.534622452590995 and b is -75.58859806693685\n",
      "Iteration 976, the loss is 64.22796895229763, parameters k is 15.534467768483509 and b is -75.58761410307491\n",
      "Iteration 977, the loss is 64.22697689988573, parameters k is 15.534313088095749 and b is -75.58663016287458\n",
      "Iteration 978, the loss is 64.2259848951853, parameters k is 15.534158411427622 and b is -75.58564624633529\n",
      "Iteration 979, the loss is 64.22499293819435, parameters k is 15.53400373847904 and b is -75.58466235345645\n",
      "Iteration 980, the loss is 64.2240010289104, parameters k is 15.533849069249912 and b is -75.58367848423751\n",
      "Iteration 981, the loss is 64.22300916733124, parameters k is 15.533694403740151 and b is -75.58269463867789\n",
      "Iteration 982, the loss is 64.22201735345445, parameters k is 15.533539741949667 and b is -75.58171081677703\n",
      "Iteration 983, the loss is 64.22102558727795, parameters k is 15.53338508387837 and b is -75.58072701853436\n",
      "Iteration 984, the loss is 64.22003386879928, parameters k is 15.53323042952617 and b is -75.57974324394931\n",
      "Iteration 985, the loss is 64.21904219801618, parameters k is 15.533075778892979 and b is -75.57875949302131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 986, the loss is 64.21805057492638, parameters k is 15.532921131978707 and b is -75.57777576574979\n",
      "Iteration 987, the loss is 64.21705899952762, parameters k is 15.532766488783263 and b is -75.57679206213419\n",
      "Iteration 988, the loss is 64.2160674718175, parameters k is 15.53261184930656 and b is -75.57580838217392\n",
      "Iteration 989, the loss is 64.21507599179382, parameters k is 15.532457213548508 and b is -75.57482472586842\n",
      "Iteration 990, the loss is 64.21408455945426, parameters k is 15.532302581509017 and b is -75.57384109321714\n",
      "Iteration 991, the loss is 64.21309317479654, parameters k is 15.532147953187996 and b is -75.5728574842195\n",
      "Iteration 992, the loss is 64.21210183781828, parameters k is 15.531993328585358 and b is -75.57187389887491\n",
      "Iteration 993, the loss is 64.21111054851733, parameters k is 15.531838707701013 and b is -75.57089033718283\n",
      "Iteration 994, the loss is 64.21011930689127, parameters k is 15.53168409053487 and b is -75.56990679914269\n",
      "Iteration 995, the loss is 64.20912811293789, parameters k is 15.531529477086844 and b is -75.5689232847539\n",
      "Iteration 996, the loss is 64.20813696665486, parameters k is 15.53137486735684 and b is -75.5679397940159\n",
      "Iteration 997, the loss is 64.20714586803993, parameters k is 15.531220261344773 and b is -75.56695632692814\n",
      "Iteration 998, the loss is 64.20615481709073, parameters k is 15.531065659050551 and b is -75.56597288349002\n",
      "Iteration 999, the loss is 64.205163813805, parameters k is 15.530911060474086 and b is -75.564989463701\n",
      "Iteration 1000, the loss is 64.20417285818046, parameters k is 15.530756465615287 and b is -75.56400606756048\n",
      "Iteration 1001, the loss is 64.20318195021484, parameters k is 15.530601874474065 and b is -75.56302269506793\n",
      "Iteration 1002, the loss is 64.20219108990581, parameters k is 15.530447287050333 and b is -75.56203934622275\n",
      "Iteration 1003, the loss is 64.20120027725108, parameters k is 15.530292703343997 and b is -75.56105602102438\n",
      "Iteration 1004, the loss is 64.20020951224846, parameters k is 15.530138123354973 and b is -75.56007271947226\n",
      "Iteration 1005, the loss is 64.19921879489546, parameters k is 15.529983547083168 and b is -75.55908944156582\n",
      "Iteration 1006, the loss is 64.19822812518991, parameters k is 15.529828974528494 and b is -75.55810618730447\n",
      "Iteration 1007, the loss is 64.19723750312951, parameters k is 15.52967440569086 and b is -75.55712295668768\n",
      "Iteration 1008, the loss is 64.196246928712, parameters k is 15.52951984057018 and b is -75.55613974971484\n",
      "Iteration 1009, the loss is 64.19525640193507, parameters k is 15.529365279166361 and b is -75.5551565663854\n",
      "Iteration 1010, the loss is 64.19426592279636, parameters k is 15.529210721479316 and b is -75.55417340669881\n",
      "Iteration 1011, the loss is 64.19327549129362, parameters k is 15.529056167508955 and b is -75.55319027065447\n",
      "Iteration 1012, the loss is 64.19228510742457, parameters k is 15.528901617255187 and b is -75.55220715825183\n",
      "Iteration 1013, the loss is 64.19129477118699, parameters k is 15.528747070717923 and b is -75.55122406949032\n",
      "Iteration 1014, the loss is 64.19030448257837, parameters k is 15.528592527897077 and b is -75.55024100436935\n",
      "Iteration 1015, the loss is 64.18931424159669, parameters k is 15.528437988792556 and b is -75.54925796288839\n",
      "Iteration 1016, the loss is 64.18832404823951, parameters k is 15.52828345340427 and b is -75.54827494504684\n",
      "Iteration 1017, the loss is 64.1873339025046, parameters k is 15.528128921732135 and b is -75.54729195084414\n",
      "Iteration 1018, the loss is 64.18634380438955, parameters k is 15.527974393776056 and b is -75.54630898027973\n",
      "Iteration 1019, the loss is 64.18535375389219, parameters k is 15.527819869535946 and b is -75.54532603335304\n",
      "Iteration 1020, the loss is 64.18436375101021, parameters k is 15.527665349011716 and b is -75.5443431100635\n",
      "Iteration 1021, the loss is 64.18337379574129, parameters k is 15.527510832203276 and b is -75.54336021041053\n",
      "Iteration 1022, the loss is 64.18238388808318, parameters k is 15.527356319110536 and b is -75.54237733439356\n",
      "Iteration 1023, the loss is 64.18139402803354, parameters k is 15.527201809733407 and b is -75.54139448201205\n",
      "Iteration 1024, the loss is 64.18040421559012, parameters k is 15.5270473040718 and b is -75.54041165326541\n",
      "Iteration 1025, the loss is 64.17941445075053, parameters k is 15.526892802125627 and b is -75.53942884815307\n",
      "Iteration 1026, the loss is 64.17842473351273, parameters k is 15.526738303894795 and b is -75.53844606667447\n",
      "Iteration 1027, the loss is 64.17743506387414, parameters k is 15.526583809379218 and b is -75.53746330882903\n",
      "Iteration 1028, the loss is 64.17644544183264, parameters k is 15.526429318578806 and b is -75.5364805746162\n",
      "Iteration 1029, the loss is 64.17545586738588, parameters k is 15.526274831493469 and b is -75.5354978640354\n",
      "Iteration 1030, the loss is 64.17446634053161, parameters k is 15.526120348123118 and b is -75.53451517708606\n",
      "Iteration 1031, the loss is 64.17347686126749, parameters k is 15.525965868467663 and b is -75.53353251376763\n",
      "Iteration 1032, the loss is 64.17248742959133, parameters k is 15.525811392527016 and b is -75.5325498740795\n",
      "Iteration 1033, the loss is 64.17149804550068, parameters k is 15.525656920301087 and b is -75.53156725802116\n",
      "Iteration 1034, the loss is 64.17050870899342, parameters k is 15.525502451789785 and b is -75.53058466559199\n",
      "Iteration 1035, the loss is 64.16951942006712, parameters k is 15.525347986993024 and b is -75.52960209679145\n",
      "Iteration 1036, the loss is 64.1685301787196, parameters k is 15.525193525910712 and b is -75.52861955161896\n",
      "Iteration 1037, the loss is 64.16754098494856, parameters k is 15.525039068542762 and b is -75.52763703007396\n",
      "Iteration 1038, the loss is 64.16655183875159, parameters k is 15.524884614889082 and b is -75.52665453215587\n",
      "Iteration 1039, the loss is 64.1655627401266, parameters k is 15.524730164949585 and b is -75.52567205786414\n",
      "Iteration 1040, the loss is 64.16457368907108, parameters k is 15.52457571872418 and b is -75.5246896071982\n",
      "Iteration 1041, the loss is 64.163584685583, parameters k is 15.524421276212777 and b is -75.52370718015746\n",
      "Iteration 1042, the loss is 64.1625957296598, parameters k is 15.52426683741529 and b is -75.52272477674137\n",
      "Iteration 1043, the loss is 64.16160682129937, parameters k is 15.524112402331626 and b is -75.52174239694935\n",
      "Iteration 1044, the loss is 64.16061796049941, parameters k is 15.5239579709617 and b is -75.52076004078084\n",
      "Iteration 1045, the loss is 64.15962914725752, parameters k is 15.523803543305418 and b is -75.51977770823528\n",
      "Iteration 1046, the loss is 64.15864038157156, parameters k is 15.523649119362693 and b is -75.5187953993121\n",
      "Iteration 1047, the loss is 64.1576516634391, parameters k is 15.523494699133437 and b is -75.5178131140107\n",
      "Iteration 1048, the loss is 64.15666299285799, parameters k is 15.523340282617559 and b is -75.51683085233056\n",
      "Iteration 1049, the loss is 64.15567436982587, parameters k is 15.523185869814968 and b is -75.51584861427108\n",
      "Iteration 1050, the loss is 64.15468579434045, parameters k is 15.523031460725578 and b is -75.5148663998317\n",
      "Iteration 1051, the loss is 64.15369726639946, parameters k is 15.522877055349298 and b is -75.51388420901186\n",
      "Iteration 1052, the loss is 64.15270878600064, parameters k is 15.522722653686039 and b is -75.51290204181099\n",
      "Iteration 1053, the loss is 64.15172035314157, parameters k is 15.522568255735711 and b is -75.5119198982285\n",
      "Iteration 1054, the loss is 64.15073196782015, parameters k is 15.522413861498228 and b is -75.51093777826384\n",
      "Iteration 1055, the loss is 64.14974363003404, parameters k is 15.522259470973497 and b is -75.50995568191644\n",
      "Iteration 1056, the loss is 64.14875533978083, parameters k is 15.52210508416143 and b is -75.50897360918573\n",
      "Iteration 1057, the loss is 64.1477670970584, parameters k is 15.521950701061936 and b is -75.50799156007116\n",
      "Iteration 1058, the loss is 64.14677890186441, parameters k is 15.521796321674929 and b is -75.50700953457215\n",
      "Iteration 1059, the loss is 64.14579075419644, parameters k is 15.521641946000317 and b is -75.50602753268812\n",
      "Iteration 1060, the loss is 64.1448026540524, parameters k is 15.521487574038012 and b is -75.50504555441852\n",
      "Iteration 1061, the loss is 64.14381460142991, parameters k is 15.521333205787926 and b is -75.50406359976276\n",
      "Iteration 1062, the loss is 64.14282659632674, parameters k is 15.521178841249966 and b is -75.5030816687203\n",
      "Iteration 1063, the loss is 64.1418386387405, parameters k is 15.521024480424046 and b is -75.50209976129055\n",
      "Iteration 1064, the loss is 64.14085072866897, parameters k is 15.520870123310075 and b is -75.50111787747295\n",
      "Iteration 1065, the loss is 64.13986286610994, parameters k is 15.520715769907966 and b is -75.50013601726694\n",
      "Iteration 1066, the loss is 64.13887505106098, parameters k is 15.520561420217627 and b is -75.49915418067194\n",
      "Iteration 1067, the loss is 64.13788728351993, parameters k is 15.52040707423897 and b is -75.49817236768739\n",
      "Iteration 1068, the loss is 64.13689956348435, parameters k is 15.520252731971905 and b is -75.49719057831271\n",
      "Iteration 1069, the loss is 64.13591189095216, parameters k is 15.520098393416344 and b is -75.49620881254735\n",
      "Iteration 1070, the loss is 64.13492426592094, parameters k is 15.519944058572198 and b is -75.49522707039073\n",
      "Iteration 1071, the loss is 64.13393668838837, parameters k is 15.519789727439377 and b is -75.49424535184228\n",
      "Iteration 1072, the loss is 64.13294915835222, parameters k is 15.519635400017792 and b is -75.49326365690145\n",
      "Iteration 1073, the loss is 64.13196167581027, parameters k is 15.519481076307352 and b is -75.49228198556766\n",
      "Iteration 1074, the loss is 64.13097424076021, parameters k is 15.51932675630797 and b is -75.49130033784033\n",
      "Iteration 1075, the loss is 64.12998685319972, parameters k is 15.519172440019556 and b is -75.4903187137189\n",
      "Iteration 1076, the loss is 64.12899951312649, parameters k is 15.51901812744202 and b is -75.48933711320282\n",
      "Iteration 1077, the loss is 64.12801222053827, parameters k is 15.518863818575275 and b is -75.48835553629151\n",
      "Iteration 1078, the loss is 64.12702497543279, parameters k is 15.518709513419228 and b is -75.4873739829844\n",
      "Iteration 1079, the loss is 64.12603777780778, parameters k is 15.518555211973794 and b is -75.48639245328091\n",
      "Iteration 1080, the loss is 64.1250506276609, parameters k is 15.518400914238882 and b is -75.48541094718051\n",
      "Iteration 1081, the loss is 64.1240635249899, parameters k is 15.518246620214402 and b is -75.4844294646826\n",
      "Iteration 1082, the loss is 64.12307646979242, parameters k is 15.518092329900265 and b is -75.48344800578663\n",
      "Iteration 1083, the loss is 64.12208946206638, parameters k is 15.51793804329638 and b is -75.48246657049201\n",
      "Iteration 1084, the loss is 64.12110250180926, parameters k is 15.517783760402663 and b is -75.4814851587982\n",
      "Iteration 1085, the loss is 64.1201155890189, parameters k is 15.517629481219021 and b is -75.4805037707046\n",
      "Iteration 1086, the loss is 64.11912872369302, parameters k is 15.517475205745365 and b is -75.47952240621068\n",
      "Iteration 1087, the loss is 64.11814190582933, parameters k is 15.517320933981607 and b is -75.47854106531585\n",
      "Iteration 1088, the loss is 64.11715513542555, parameters k is 15.517166665927656 and b is -75.47755974801954\n",
      "Iteration 1089, the loss is 64.11616841247934, parameters k is 15.517012401583424 and b is -75.4765784543212\n",
      "Iteration 1090, the loss is 64.11518173698848, parameters k is 15.516858140948822 and b is -75.47559718422025\n",
      "Iteration 1091, the loss is 64.11419510895068, parameters k is 15.516703884023759 and b is -75.47461593771612\n",
      "Iteration 1092, the loss is 64.11320852836359, parameters k is 15.516549630808148 and b is -75.47363471480826\n",
      "Iteration 1093, the loss is 64.11222199522501, parameters k is 15.5163953813019 and b is -75.47265351549608\n",
      "Iteration 1094, the loss is 64.1112355095327, parameters k is 15.516241135504924 and b is -75.47167233977902\n",
      "Iteration 1095, the loss is 64.11024907128424, parameters k is 15.516086893417132 and b is -75.47069118765651\n",
      "Iteration 1096, the loss is 64.10926268047739, parameters k is 15.515932655038434 and b is -75.46971005912799\n",
      "Iteration 1097, the loss is 64.10827633711001, parameters k is 15.515778420368742 and b is -75.4687289541929\n",
      "Iteration 1098, the loss is 64.1072900411796, parameters k is 15.515624189407966 and b is -75.46774787285065\n",
      "Iteration 1099, the loss is 64.10630379268397, parameters k is 15.515469962156017 and b is -75.46676681510068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1100, the loss is 64.10531759162086, parameters k is 15.515315738612804 and b is -75.46578578094244\n",
      "Iteration 1101, the loss is 64.10433143798805, parameters k is 15.51516151877824 and b is -75.46480477037535\n",
      "Iteration 1102, the loss is 64.10334533178312, parameters k is 15.515007302652236 and b is -75.46382378339884\n",
      "Iteration 1103, the loss is 64.10235927300388, parameters k is 15.514853090234702 and b is -75.46284282001234\n",
      "Iteration 1104, the loss is 64.10137326164809, parameters k is 15.514698881525549 and b is -75.4618618802153\n",
      "Iteration 1105, the loss is 64.10038729771333, parameters k is 15.514544676524686 and b is -75.46088096400713\n",
      "Iteration 1106, the loss is 64.09940138119747, parameters k is 15.514390475232027 and b is -75.45990007138728\n",
      "Iteration 1107, the loss is 64.09841551209801, parameters k is 15.51423627764748 and b is -75.45891920235518\n",
      "Iteration 1108, the loss is 64.09742969041294, parameters k is 15.514082083770958 and b is -75.45793835691025\n",
      "Iteration 1109, the loss is 64.09644391613985, parameters k is 15.513927893602371 and b is -75.45695753505194\n",
      "Iteration 1110, the loss is 64.09545818927643, parameters k is 15.513773707141631 and b is -75.45597673677968\n",
      "Iteration 1111, the loss is 64.09447250982039, parameters k is 15.513619524388647 and b is -75.45499596209288\n",
      "Iteration 1112, the loss is 64.09348687776955, parameters k is 15.51346534534333 and b is -75.454015210991\n",
      "Iteration 1113, the loss is 64.09250129312159, parameters k is 15.513311170005593 and b is -75.45303448347347\n",
      "Iteration 1114, the loss is 64.09151575587421, parameters k is 15.513156998375345 and b is -75.45205377953971\n",
      "Iteration 1115, the loss is 64.09053026602507, parameters k is 15.513002830452496 and b is -75.45107309918916\n",
      "Iteration 1116, the loss is 64.08954482357203, parameters k is 15.512848666236959 and b is -75.45009244242125\n",
      "Iteration 1117, the loss is 64.08855942851268, parameters k is 15.512694505728643 and b is -75.44911180923542\n",
      "Iteration 1118, the loss is 64.08757408084479, parameters k is 15.512540348927459 and b is -75.44813119963109\n",
      "Iteration 1119, the loss is 64.08658878056616, parameters k is 15.512386195833319 and b is -75.44715061360772\n",
      "Iteration 1120, the loss is 64.0856035276744, parameters k is 15.512232046446133 and b is -75.44617005116471\n",
      "Iteration 1121, the loss is 64.08461832216729, parameters k is 15.512077900765812 and b is -75.44518951230151\n",
      "Iteration 1122, the loss is 64.08363316404247, parameters k is 15.511923758792268 and b is -75.44420899701755\n",
      "Iteration 1123, the loss is 64.08264805329772, parameters k is 15.51176962052541 and b is -75.44322850531226\n",
      "Iteration 1124, the loss is 64.08166298993082, parameters k is 15.51161548596515 and b is -75.44224803718508\n",
      "Iteration 1125, the loss is 64.08067797393944, parameters k is 15.511461355111399 and b is -75.44126759263544\n",
      "Iteration 1126, the loss is 64.07969300532125, parameters k is 15.511307227964068 and b is -75.44028717166277\n",
      "Iteration 1127, the loss is 64.07870808407405, parameters k is 15.511153104523066 and b is -75.43930677426651\n",
      "Iteration 1128, the loss is 64.07772321019549, parameters k is 15.510998984788307 and b is -75.43832640044609\n",
      "Iteration 1129, the loss is 64.07673838368335, parameters k is 15.5108448687597 and b is -75.43734605020093\n",
      "Iteration 1130, the loss is 64.07575360453541, parameters k is 15.510690756437155 and b is -75.43636572353047\n",
      "Iteration 1131, the loss is 64.07476887274919, parameters k is 15.510536647820585 and b is -75.43538542043416\n",
      "Iteration 1132, the loss is 64.07378418832262, parameters k is 15.510382542909898 and b is -75.43440514091141\n",
      "Iteration 1133, the loss is 64.07279955125325, parameters k is 15.510228441705008 and b is -75.43342488496167\n",
      "Iteration 1134, the loss is 64.07181496153899, parameters k is 15.510074344205824 and b is -75.43244465258437\n",
      "Iteration 1135, the loss is 64.07083041917734, parameters k is 15.509920250412257 and b is -75.43146444377894\n",
      "Iteration 1136, the loss is 64.06984592416633, parameters k is 15.509766160324219 and b is -75.43048425854481\n",
      "Iteration 1137, the loss is 64.06886147650339, parameters k is 15.50961207394162 and b is -75.42950409688142\n",
      "Iteration 1138, the loss is 64.06787707618638, parameters k is 15.509457991264371 and b is -75.42852395878819\n",
      "Iteration 1139, the loss is 64.06689272321294, parameters k is 15.509303912292385 and b is -75.42754384426456\n",
      "Iteration 1140, the loss is 64.06590841758091, parameters k is 15.50914983702557 and b is -75.42656375330998\n",
      "Iteration 1141, the loss is 64.06492415928793, parameters k is 15.508995765463837 and b is -75.42558368592385\n",
      "Iteration 1142, the loss is 64.06393994833172, parameters k is 15.508841697607098 and b is -75.42460364210564\n",
      "Iteration 1143, the loss is 64.06295578471006, parameters k is 15.508687633455263 and b is -75.42362362185476\n",
      "Iteration 1144, the loss is 64.06197166842063, parameters k is 15.508533573008245 and b is -75.42264362517065\n",
      "Iteration 1145, the loss is 64.0609875994612, parameters k is 15.508379516265952 and b is -75.42166365205274\n",
      "Iteration 1146, the loss is 64.06000357782945, parameters k is 15.508225463228298 and b is -75.42068370250047\n",
      "Iteration 1147, the loss is 64.059019603523, parameters k is 15.508071413895191 and b is -75.41970377651326\n",
      "Iteration 1148, the loss is 64.05803567653986, parameters k is 15.507917368266543 and b is -75.41872387409056\n",
      "Iteration 1149, the loss is 64.05705179687743, parameters k is 15.507763326342266 and b is -75.41774399523179\n",
      "Iteration 1150, the loss is 64.0560679645337, parameters k is 15.50760928812227 and b is -75.41676413993639\n",
      "Iteration 1151, the loss is 64.05508417950621, parameters k is 15.507455253606466 and b is -75.4157843082038\n",
      "Iteration 1152, the loss is 64.05410044179278, parameters k is 15.507301222794764 and b is -75.41480450003344\n",
      "Iteration 1153, the loss is 64.05311675139107, parameters k is 15.507147195687075 and b is -75.41382471542475\n",
      "Iteration 1154, the loss is 64.05213310829888, parameters k is 15.506993172283313 and b is -75.41284495437716\n",
      "Iteration 1155, the loss is 64.05114951251389, parameters k is 15.506839152583385 and b is -75.4118652168901\n",
      "Iteration 1156, the loss is 64.05016596403381, parameters k is 15.506685136587205 and b is -75.41088550296303\n",
      "Iteration 1157, the loss is 64.04918246285648, parameters k is 15.506531124294682 and b is -75.40990581259534\n",
      "Iteration 1158, the loss is 64.04819900897951, parameters k is 15.506377115705726 and b is -75.4089261457865\n",
      "Iteration 1159, the loss is 64.04721560240057, parameters k is 15.506223110820251 and b is -75.40794650253592\n",
      "Iteration 1160, the loss is 64.04623224311749, parameters k is 15.506069109638165 and b is -75.40696688284305\n",
      "Iteration 1161, the loss is 64.04524893112793, parameters k is 15.505915112159382 and b is -75.40598728670732\n",
      "Iteration 1162, the loss is 64.04426566642972, parameters k is 15.50576111838381 and b is -75.40500771412815\n",
      "Iteration 1163, the loss is 64.0432824490205, parameters k is 15.505607128311363 and b is -75.40402816510499\n",
      "Iteration 1164, the loss is 64.04229927889797, parameters k is 15.505453141941949 and b is -75.40304863963726\n",
      "Iteration 1165, the loss is 64.04131615605995, parameters k is 15.505299159275479 and b is -75.40206913772441\n",
      "Iteration 1166, the loss is 64.04033308050414, parameters k is 15.505145180311866 and b is -75.40108965936587\n",
      "Iteration 1167, the loss is 64.03935005222824, parameters k is 15.50499120505102 and b is -75.40011020456105\n",
      "Iteration 1168, the loss is 64.03836707122989, parameters k is 15.504837233492852 and b is -75.39913077330941\n",
      "Iteration 1169, the loss is 64.037384137507, parameters k is 15.504683265637272 and b is -75.39815136561037\n",
      "Iteration 1170, the loss is 64.03640125105717, parameters k is 15.504529301484192 and b is -75.39717198146337\n",
      "Iteration 1171, the loss is 64.03541841187806, parameters k is 15.504375341033525 and b is -75.39619262086785\n",
      "Iteration 1172, the loss is 64.03443561996768, parameters k is 15.504221384285177 and b is -75.39521328382322\n",
      "Iteration 1173, the loss is 64.03345287532343, parameters k is 15.504067431239063 and b is -75.39423397032894\n",
      "Iteration 1174, the loss is 64.03247017794327, parameters k is 15.503913481895093 and b is -75.39325468038443\n",
      "Iteration 1175, the loss is 64.03148752782475, parameters k is 15.503759536253177 and b is -75.39227541398913\n",
      "Iteration 1176, the loss is 64.03050492496577, parameters k is 15.503605594313228 and b is -75.39129617114247\n",
      "Iteration 1177, the loss is 64.02952236936386, parameters k is 15.503451656075155 and b is -75.39031695184389\n",
      "Iteration 1178, the loss is 64.028539861017, parameters k is 15.50329772153887 and b is -75.38933775609281\n",
      "Iteration 1179, the loss is 64.02755739992261, parameters k is 15.503143790704282 and b is -75.38835858388867\n",
      "Iteration 1180, the loss is 64.02657498607861, parameters k is 15.502989863571305 and b is -75.38737943523091\n",
      "Iteration 1181, the loss is 64.02559261948277, parameters k is 15.502835940139848 and b is -75.38640031011896\n",
      "Iteration 1182, the loss is 64.02461030013275, parameters k is 15.502682020409823 and b is -75.38542120855224\n",
      "Iteration 1183, the loss is 64.02362802802624, parameters k is 15.50252810438114 and b is -75.38444213053022\n",
      "Iteration 1184, the loss is 64.02264580316098, parameters k is 15.502374192053711 and b is -75.3834630760523\n",
      "Iteration 1185, the loss is 64.02166362553473, parameters k is 15.502220283427446 and b is -75.38248404511792\n",
      "Iteration 1186, the loss is 64.02068149514521, parameters k is 15.502066378502258 and b is -75.38150503772653\n",
      "Iteration 1187, the loss is 64.0196994119902, parameters k is 15.501912477278056 and b is -75.38052605387755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1188, the loss is 64.01871737606729, parameters k is 15.501758579754751 and b is -75.37954709357041\n",
      "Iteration 1189, the loss is 64.01773538737439, parameters k is 15.501604685932255 and b is -75.37856815680455\n",
      "Iteration 1190, the loss is 64.01675344590907, parameters k is 15.501450795810479 and b is -75.37758924357941\n",
      "Iteration 1191, the loss is 64.01577155166909, parameters k is 15.501296909389334 and b is -75.3766103538944\n",
      "Iteration 1192, the loss is 64.01478970465226, parameters k is 15.50114302666873 and b is -75.37563148774899\n",
      "Iteration 1193, the loss is 64.01380790485624, parameters k is 15.500989147648578 and b is -75.37465264514259\n",
      "Iteration 1194, the loss is 64.01282615227878, parameters k is 15.500835272328791 and b is -75.37367382607464\n",
      "Iteration 1195, the loss is 64.01184444691764, parameters k is 15.500681400709277 and b is -75.37269503054458\n",
      "Iteration 1196, the loss is 64.01086278877045, parameters k is 15.500527532789949 and b is -75.37171625855183\n",
      "Iteration 1197, the loss is 64.00988117783503, parameters k is 15.500373668570719 and b is -75.37073751009584\n",
      "Iteration 1198, the loss is 64.00889961410905, parameters k is 15.500219808051495 and b is -75.36975878517603\n",
      "Iteration 1199, the loss is 64.00791809759032, parameters k is 15.500065951232191 and b is -75.36878008379185\n",
      "Iteration 1200, the loss is 64.00693662827652, parameters k is 15.499912098112716 and b is -75.36780140594271\n",
      "Iteration 1201, the loss is 64.00595520616537, parameters k is 15.499758248692983 and b is -75.36682275162806\n",
      "Iteration 1202, the loss is 64.00497383125459, parameters k is 15.499604402972901 and b is -75.36584412084734\n",
      "Iteration 1203, the loss is 64.003992503542, parameters k is 15.499450560952381 and b is -75.36486551359997\n",
      "Iteration 1204, the loss is 64.00301122302518, parameters k is 15.499296722631335 and b is -75.36388692988538\n",
      "Iteration 1205, the loss is 64.00202998970197, parameters k is 15.499142888009676 and b is -75.36290836970302\n",
      "Iteration 1206, the loss is 64.00104880357011, parameters k is 15.49898905708731 and b is -75.36192983305233\n",
      "Iteration 1207, the loss is 64.00006766462728, parameters k is 15.498835229864154 and b is -75.36095131993272\n",
      "Iteration 1208, the loss is 63.99908657287115, parameters k is 15.498681406340115 and b is -75.35997283034365\n",
      "Iteration 1209, the loss is 63.99810552829954, parameters k is 15.498527586515104 and b is -75.35899436428453\n",
      "Iteration 1210, the loss is 63.99712453091026, parameters k is 15.498373770389033 and b is -75.3580159217548\n",
      "Iteration 1211, the loss is 63.99614358070087, parameters k is 15.498219957961814 and b is -75.3570375027539\n",
      "Iteration 1212, the loss is 63.99516267766915, parameters k is 15.498066149233356 and b is -75.35605910728127\n",
      "Iteration 1213, the loss is 63.99418182181293, parameters k is 15.497912344203572 and b is -75.35508073533633\n",
      "Iteration 1214, the loss is 63.99320101312987, parameters k is 15.497758542872372 and b is -75.35410238691853\n",
      "Iteration 1215, the loss is 63.992220251617674, parameters k is 15.497604745239668 and b is -75.35312406202729\n",
      "Iteration 1216, the loss is 63.99123953727404, parameters k is 15.497450951305371 and b is -75.35214576066205\n",
      "Iteration 1217, the loss is 63.99025887009688, parameters k is 15.497297161069392 and b is -75.35116748282225\n",
      "Iteration 1218, the loss is 63.98927825008372, parameters k is 15.49714337453164 and b is -75.35018922850732\n",
      "Iteration 1219, the loss is 63.988297677232445, parameters k is 15.49698959169203 and b is -75.34921099771668\n",
      "Iteration 1220, the loss is 63.987317151540594, parameters k is 15.496835812550469 and b is -75.34823279044979\n",
      "Iteration 1221, the loss is 63.98633667300609, parameters k is 15.49668203710687 and b is -75.34725460670606\n",
      "Iteration 1222, the loss is 63.985356241626626, parameters k is 15.496528265361144 and b is -75.34627644648494\n",
      "Iteration 1223, the loss is 63.984375857399876, parameters k is 15.496374497313202 and b is -75.34529830978586\n",
      "Iteration 1224, the loss is 63.983395520323604, parameters k is 15.496220732962955 and b is -75.34432019660827\n",
      "Iteration 1225, the loss is 63.982415230395475, parameters k is 15.496066972310315 and b is -75.34334210695157\n",
      "Iteration 1226, the loss is 63.98143498761336, parameters k is 15.495913215355191 and b is -75.34236404081521\n",
      "Iteration 1227, the loss is 63.980454791974985, parameters k is 15.495759462097496 and b is -75.34138599819865\n",
      "Iteration 1228, the loss is 63.979474643477914, parameters k is 15.49560571253714 and b is -75.34040797910129\n",
      "Iteration 1229, the loss is 63.97849454212005, parameters k is 15.495451966674034 and b is -75.33942998352258\n",
      "Iteration 1230, the loss is 63.97751448789899, parameters k is 15.49529822450809 and b is -75.33845201146195\n",
      "Iteration 1231, the loss is 63.97653448081253, parameters k is 15.49514448603922 and b is -75.33747406291884\n",
      "Iteration 1232, the loss is 63.975554520858495, parameters k is 15.494990751267332 and b is -75.33649613789268\n",
      "Iteration 1233, the loss is 63.97457460803444, parameters k is 15.49483702019234 and b is -75.3355182363829\n",
      "Iteration 1234, the loss is 63.973594742338236, parameters k is 15.494683292814154 and b is -75.33454035838894\n",
      "Iteration 1235, the loss is 63.97261492376756, parameters k is 15.494529569132684 and b is -75.33356250391023\n",
      "Iteration 1236, the loss is 63.971635152320175, parameters k is 15.494375849147843 and b is -75.33258467294621\n",
      "Iteration 1237, the loss is 63.970655427993826, parameters k is 15.494222132859543 and b is -75.33160686549631\n",
      "Iteration 1238, the loss is 63.96967575078609, parameters k is 15.494068420267691 and b is -75.33062908155998\n",
      "Iteration 1239, the loss is 63.968696120694936, parameters k is 15.493914711372202 and b is -75.32965132113662\n",
      "Iteration 1240, the loss is 63.96771653771793, parameters k is 15.493761006172985 and b is -75.3286735842257\n",
      "Iteration 1241, the loss is 63.96673700185289, parameters k is 15.49360730466995 and b is -75.32769587082663\n",
      "Iteration 1242, the loss is 63.96575751309752, parameters k is 15.493453606863012 and b is -75.32671818093887\n",
      "Iteration 1243, the loss is 63.96477807144958, parameters k is 15.493299912752079 and b is -75.32574051456183\n",
      "Iteration 1244, the loss is 63.963798676906805, parameters k is 15.493146222337064 and b is -75.32476287169496\n",
      "Iteration 1245, the loss is 63.962819329466775, parameters k is 15.492992535617876 and b is -75.32378525233769\n",
      "Iteration 1246, the loss is 63.96184002912753, parameters k is 15.492838852594428 and b is -75.32280765648945\n",
      "Iteration 1247, the loss is 63.96086077588655, parameters k is 15.49268517326663 and b is -75.32183008414967\n",
      "Iteration 1248, the loss is 63.95988156974169, parameters k is 15.492531497634394 and b is -75.3208525353178\n",
      "Iteration 1249, the loss is 63.958902410690534, parameters k is 15.49237782569763 and b is -75.31987500999327\n",
      "Iteration 1250, the loss is 63.957923298731004, parameters k is 15.492224157456251 and b is -75.31889750817551\n",
      "Iteration 1251, the loss is 63.95694423386085, parameters k is 15.492070492910166 and b is -75.31792002986396\n",
      "Iteration 1252, the loss is 63.95596521607762, parameters k is 15.491916832059287 and b is -75.31694257505805\n",
      "Iteration 1253, the loss is 63.954986245379146, parameters k is 15.491763174903525 and b is -75.31596514375723\n",
      "Iteration 1254, the loss is 63.95400732176319, parameters k is 15.491609521442792 and b is -75.31498773596091\n",
      "Iteration 1255, the loss is 63.95302844522745, parameters k is 15.491455871676997 and b is -75.31401035166854\n",
      "Iteration 1256, the loss is 63.95204961576974, parameters k is 15.491302225606056 and b is -75.31303299087955\n",
      "Iteration 1257, the loss is 63.95107083338768, parameters k is 15.491148583229874 and b is -75.31205565359338\n",
      "Iteration 1258, the loss is 63.95009209807899, parameters k is 15.490994944548365 and b is -75.31107833980946\n",
      "Iteration 1259, the loss is 63.94911340984164, parameters k is 15.490841309561443 and b is -75.31010104952722\n",
      "Iteration 1260, the loss is 63.94813476867305, parameters k is 15.490687678269014 and b is -75.3091237827461\n",
      "Iteration 1261, the loss is 63.94715617457114, parameters k is 15.490534050670991 and b is -75.30814653946554\n",
      "Iteration 1262, the loss is 63.94617762753364, parameters k is 15.490380426767286 and b is -75.30716931968497\n",
      "Iteration 1263, the loss is 63.9451991275582, parameters k is 15.49022680655781 and b is -75.30619212340383\n",
      "Iteration 1264, the loss is 63.94422067464266, parameters k is 15.490073190042475 and b is -75.30521495062155\n",
      "Iteration 1265, the loss is 63.9432422687847, parameters k is 15.48991957722119 and b is -75.30423780133755\n",
      "Iteration 1266, the loss is 63.942263909982074, parameters k is 15.489765968093868 and b is -75.30326067555129\n",
      "Iteration 1267, the loss is 63.94128559823252, parameters k is 15.48961236266042 and b is -75.30228357326219\n",
      "Iteration 1268, the loss is 63.940307333533795, parameters k is 15.489458760920757 and b is -75.30130649446969\n",
      "Iteration 1269, the loss is 63.93932911588355, parameters k is 15.489305162874789 and b is -75.30032943917323\n",
      "Iteration 1270, the loss is 63.938350945279645, parameters k is 15.489151568522427 and b is -75.29935240737224\n",
      "Iteration 1271, the loss is 63.937372821719705, parameters k is 15.488997977863583 and b is -75.29837539906616\n",
      "Iteration 1272, the loss is 63.93639474520151, parameters k is 15.48884439089817 and b is -75.29739841425442\n",
      "Iteration 1273, the loss is 63.93541671572287, parameters k is 15.488690807626096 and b is -75.29642145293644\n",
      "Iteration 1274, the loss is 63.93443873328139, parameters k is 15.488537228047274 and b is -75.29544451511168\n",
      "Iteration 1275, the loss is 63.93346079787494, parameters k is 15.488383652161616 and b is -75.29446760077957\n",
      "Iteration 1276, the loss is 63.932482909501125, parameters k is 15.488230079969032 and b is -75.29349070993953\n",
      "Iteration 1277, the loss is 63.93150506815777, parameters k is 15.488076511469433 and b is -75.292513842591\n",
      "Iteration 1278, the loss is 63.93052727384258, parameters k is 15.48792294666273 and b is -75.29153699873343\n",
      "Iteration 1279, the loss is 63.9295495265533, parameters k is 15.487769385548834 and b is -75.29056017836625\n",
      "Iteration 1280, the loss is 63.928571826287765, parameters k is 15.487615828127657 and b is -75.28958338148888\n",
      "Iteration 1281, the loss is 63.92759417304349, parameters k is 15.48746227439911 and b is -75.28860660810078\n",
      "Iteration 1282, the loss is 63.92661656681845, parameters k is 15.487308724363105 and b is -75.28762985820136\n",
      "Iteration 1283, the loss is 63.9256390076103, parameters k is 15.487155178019552 and b is -75.28665313179006\n",
      "Iteration 1284, the loss is 63.92466149541666, parameters k is 15.487001635368363 and b is -75.28567642886632\n",
      "Iteration 1285, the loss is 63.92368403023545, parameters k is 15.48684809640945 and b is -75.28469974942959\n",
      "Iteration 1286, the loss is 63.92270661206427, parameters k is 15.486694561142722 and b is -75.28372309347928\n",
      "Iteration 1287, the loss is 63.921729240900945, parameters k is 15.486541029568091 and b is -75.28274646101484\n",
      "Iteration 1288, the loss is 63.9207519167432, parameters k is 15.486387501685469 and b is -75.28176985203571\n",
      "Iteration 1289, the loss is 63.91977463958874, parameters k is 15.486233977494766 and b is -75.28079326654131\n",
      "Iteration 1290, the loss is 63.91879740943534, parameters k is 15.486080456995895 and b is -75.27981670453109\n",
      "Iteration 1291, the loss is 63.91782022628068, parameters k is 15.485926940188765 and b is -75.27884016600447\n",
      "Iteration 1292, the loss is 63.916843090122576, parameters k is 15.48577342707329 and b is -75.2778636509609\n",
      "Iteration 1293, the loss is 63.91586600095874, parameters k is 15.48561991764938 and b is -75.2768871593998\n",
      "Iteration 1294, the loss is 63.91488895878695, parameters k is 15.485466411916946 and b is -75.27591069132062\n",
      "Iteration 1295, the loss is 63.91391196360481, parameters k is 15.485312909875898 and b is -75.27493424672278\n",
      "Iteration 1296, the loss is 63.912935015410255, parameters k is 15.485159411526148 and b is -75.27395782560573\n",
      "Iteration 1297, the loss is 63.911958114200786, parameters k is 15.485005916867607 and b is -75.2729814279689\n",
      "Iteration 1298, the loss is 63.910981259974434, parameters k is 15.484852425900188 and b is -75.27200505381172\n",
      "Iteration 1299, the loss is 63.91000445272868, parameters k is 15.4846989386238 and b is -75.27102870313364\n",
      "Iteration 1300, the loss is 63.90902769246145, parameters k is 15.484545455038356 and b is -75.27005237593409\n",
      "Iteration 1301, the loss is 63.90805097917027, parameters k is 15.484391975143767 and b is -75.26907607221248\n",
      "Iteration 1302, the loss is 63.90707431285321, parameters k is 15.484238498939943 and b is -75.26809979196828\n",
      "Iteration 1303, the loss is 63.906097693507704, parameters k is 15.484085026426797 and b is -75.26712353520091\n",
      "Iteration 1304, the loss is 63.90512112113163, parameters k is 15.483931557604238 and b is -75.26614730190981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1305, the loss is 63.904144595722634, parameters k is 15.48377809247218 and b is -75.2651710920944\n",
      "Iteration 1306, the loss is 63.90316811727858, parameters k is 15.483624631030532 and b is -75.26419490575414\n",
      "Iteration 1307, the loss is 63.90219168579723, parameters k is 15.483471173279206 and b is -75.26321874288845\n",
      "Iteration 1308, the loss is 63.90121530127619, parameters k is 15.483317719218112 and b is -75.26224260349677\n",
      "Iteration 1309, the loss is 63.90023896371323, parameters k is 15.483164268847164 and b is -75.26126648757854\n",
      "Iteration 1310, the loss is 63.899262673106165, parameters k is 15.483010822166271 and b is -75.26029039513318\n",
      "Iteration 1311, the loss is 63.89828642945268, parameters k is 15.482857379175345 and b is -75.25931432616015\n",
      "Iteration 1312, the loss is 63.897310232750556, parameters k is 15.482703939874296 and b is -75.25833828065886\n",
      "Iteration 1313, the loss is 63.896334082997534, parameters k is 15.482550504263038 and b is -75.25736225862876\n",
      "Iteration 1314, the loss is 63.89535798019128, parameters k is 15.482397072341481 and b is -75.25638626006929\n",
      "Iteration 1315, the loss is 63.894381924329664, parameters k is 15.482243644109536 and b is -75.25541028497987\n",
      "Iteration 1316, the loss is 63.893405915410256, parameters k is 15.482090219567114 and b is -75.25443433335995\n",
      "Iteration 1317, the loss is 63.892429953430984, parameters k is 15.481936798714127 and b is -75.25345840520896\n",
      "Iteration 1318, the loss is 63.89145403838939, parameters k is 15.481783381550487 and b is -75.25248250052633\n",
      "Iteration 1319, the loss is 63.89047817028348, parameters k is 15.481629968076104 and b is -75.2515066193115\n",
      "Iteration 1320, the loss is 63.88950234911077, parameters k is 15.48147655829089 and b is -75.25053076156391\n",
      "Iteration 1321, the loss is 63.88852657486909, parameters k is 15.481323152194754 and b is -75.24955492728299\n",
      "Iteration 1322, the loss is 63.88755084755623, parameters k is 15.481169749787611 and b is -75.24857911646818\n",
      "Iteration 1323, the loss is 63.88657516716981, parameters k is 15.48101635106937 and b is -75.24760332911892\n",
      "Iteration 1324, the loss is 63.885599533707584, parameters k is 15.480862956039942 and b is -75.24662756523463\n",
      "Iteration 1325, the loss is 63.88462394716751, parameters k is 15.48070956469924 and b is -75.24565182481476\n",
      "Iteration 1326, the loss is 63.88364840754707, parameters k is 15.480556177047173 and b is -75.24467610785874\n",
      "Iteration 1327, the loss is 63.88267291484414, parameters k is 15.480402793083654 and b is -75.243700414366\n",
      "Iteration 1328, the loss is 63.88169746905639, parameters k is 15.480249412808593 and b is -75.24272474433599\n",
      "Iteration 1329, the loss is 63.88072207018168, parameters k is 15.480096036221903 and b is -75.24174909776814\n",
      "Iteration 1330, the loss is 63.87974671821761, parameters k is 15.479942663323495 and b is -75.24077347466188\n",
      "Iteration 1331, the loss is 63.878771413162006, parameters k is 15.47978929411328 and b is -75.23979787501665\n",
      "Iteration 1332, the loss is 63.877796155012675, parameters k is 15.479635928591168 and b is -75.23882229883188\n",
      "Iteration 1333, the loss is 63.8768209437672, parameters k is 15.479482566757072 and b is -75.23784674610701\n",
      "Iteration 1334, the loss is 63.875845779423415, parameters k is 15.479329208610903 and b is -75.23687121684148\n",
      "Iteration 1335, the loss is 63.874870661979074, parameters k is 15.479175854152572 and b is -75.23589571103473\n",
      "Iteration 1336, the loss is 63.873895591431925, parameters k is 15.47902250338199 and b is -75.23492022868618\n",
      "Iteration 1337, the loss is 63.8729205677797, parameters k is 15.47886915629907 and b is -75.23394476979527\n",
      "Iteration 1338, the loss is 63.87194559102014, parameters k is 15.47871581290372 and b is -75.23296933436146\n",
      "Iteration 1339, the loss is 63.87097066115099, parameters k is 15.478562473195854 and b is -75.23199392238415\n",
      "Iteration 1340, the loss is 63.86999577817, parameters k is 15.478409137175383 and b is -75.2310185338628\n",
      "Iteration 1341, the loss is 63.86902094207487, parameters k is 15.478255804842219 and b is -75.23004316879683\n",
      "Iteration 1342, the loss is 63.86804615286342, parameters k is 15.478102476196272 and b is -75.22906782718569\n",
      "Iteration 1343, the loss is 63.86707141053338, parameters k is 15.477949151237452 and b is -75.22809250902881\n",
      "Iteration 1344, the loss is 63.86609671508245, parameters k is 15.477795829965672 and b is -75.22711721432563\n",
      "Iteration 1345, the loss is 63.865122066508384, parameters k is 15.477642512380845 and b is -75.22614194307559\n",
      "Iteration 1346, the loss is 63.864147464808994, parameters k is 15.47748919848288 and b is -75.2251666952781\n",
      "Iteration 1347, the loss is 63.86317290998196, parameters k is 15.47733588827169 and b is -75.22419147093262\n",
      "Iteration 1348, the loss is 63.86219840202497, parameters k is 15.477182581747183 and b is -75.22321627003859\n",
      "Iteration 1349, the loss is 63.861223940935886, parameters k is 15.477029278909274 and b is -75.22224109259544\n",
      "Iteration 1350, the loss is 63.86024952671244, parameters k is 15.476875979757873 and b is -75.2212659386026\n",
      "Iteration 1351, the loss is 63.85927515935235, parameters k is 15.476722684292891 and b is -75.2202908080595\n",
      "Iteration 1352, the loss is 63.85830083885336, parameters k is 15.476569392514241 and b is -75.2193157009656\n",
      "Iteration 1353, the loss is 63.85732656521325, parameters k is 15.476416104421832 and b is -75.21834061732031\n",
      "Iteration 1354, the loss is 63.85635233842969, parameters k is 15.476262820015576 and b is -75.21736555712307\n",
      "Iteration 1355, the loss is 63.85537815850043, parameters k is 15.476109539295386 and b is -75.21639052037334\n",
      "Iteration 1356, the loss is 63.854404025423285, parameters k is 15.475956262261173 and b is -75.21541550707053\n",
      "Iteration 1357, the loss is 63.853429939196026, parameters k is 15.475802988912847 and b is -75.21444051721409\n",
      "Iteration 1358, the loss is 63.85245589981628, parameters k is 15.475649719250319 and b is -75.21346555080345\n",
      "Iteration 1359, the loss is 63.85148190728189, parameters k is 15.475496453273502 and b is -75.21249060783805\n",
      "Iteration 1360, the loss is 63.85050796159057, parameters k is 15.475343190982306 and b is -75.21151568831732\n",
      "Iteration 1361, the loss is 63.84953406274008, parameters k is 15.475189932376644 and b is -75.21054079224069\n",
      "Iteration 1362, the loss is 63.848560210728145, parameters k is 15.475036677456425 and b is -75.20956591960761\n",
      "Iteration 1363, the loss is 63.847586405552526, parameters k is 15.474883426221561 and b is -75.20859107041753\n",
      "Iteration 1364, the loss is 63.846612647210975, parameters k is 15.474730178671965 and b is -75.20761624466985\n",
      "Iteration 1365, the loss is 63.84563893570121, parameters k is 15.474576934807548 and b is -75.20664144236403\n",
      "Iteration 1366, the loss is 63.844665271021086, parameters k is 15.474423694628221 and b is -75.2056666634995\n",
      "Iteration 1367, the loss is 63.84369165316819, parameters k is 15.474270458133896 and b is -75.2046919080757\n",
      "Iteration 1368, the loss is 63.84271808214035, parameters k is 15.474117225324482 and b is -75.20371717609207\n",
      "Iteration 1369, the loss is 63.84174455793535, parameters k is 15.473963996199894 and b is -75.20274246754803\n",
      "Iteration 1370, the loss is 63.840771080550915, parameters k is 15.47381077076004 and b is -75.20176778244304\n",
      "Iteration 1371, the loss is 63.83979764998473, parameters k is 15.473657549004832 and b is -75.20079312077652\n",
      "Iteration 1372, the loss is 63.83882426623461, parameters k is 15.473504330934183 and b is -75.19981848254791\n",
      "Iteration 1373, the loss is 63.837850929298334, parameters k is 15.473351116548004 and b is -75.19884386775665\n",
      "Iteration 1374, the loss is 63.836877639173565, parameters k is 15.473197905846206 and b is -75.19786927640217\n",
      "Iteration 1375, the loss is 63.83590439585807, parameters k is 15.4730446988287 and b is -75.19689470848391\n",
      "Iteration 1376, the loss is 63.83493119934963, parameters k is 15.472891495495398 and b is -75.19592016400131\n",
      "Iteration 1377, the loss is 63.833958049645965, parameters k is 15.472738295846211 and b is -75.19494564295378\n",
      "Iteration 1378, the loss is 63.83298494674488, parameters k is 15.472585099881051 and b is -75.1939711453408\n",
      "Iteration 1379, the loss is 63.83201189064399, parameters k is 15.47243190759983 and b is -75.19299667116177\n",
      "Iteration 1380, the loss is 63.83103888134128, parameters k is 15.472278719002459 and b is -75.19202222041613\n",
      "Iteration 1381, the loss is 63.83006591883424, parameters k is 15.472125534088848 and b is -75.19104779310335\n",
      "Iteration 1382, the loss is 63.82909300312081, parameters k is 15.47197235285891 and b is -75.19007338922285\n",
      "Iteration 1383, the loss is 63.828120134198606, parameters k is 15.471819175312554 and b is -75.18909900877405\n",
      "Iteration 1384, the loss is 63.827147312065506, parameters k is 15.471666001449693 and b is -75.1881246517564\n",
      "Iteration 1385, the loss is 63.826174536719165, parameters k is 15.471512831270239 and b is -75.18715031816933\n",
      "Iteration 1386, the loss is 63.825201808157345, parameters k is 15.471359664774104 and b is -75.18617600801228\n",
      "Iteration 1387, the loss is 63.8242291263778, parameters k is 15.471206501961197 and b is -75.18520172128468\n",
      "Iteration 1388, the loss is 63.823256491378274, parameters k is 15.47105334283143 and b is -75.18422745798598\n",
      "Iteration 1389, the loss is 63.822283903156574, parameters k is 15.470900187384718 and b is -75.18325321811561\n",
      "Iteration 1390, the loss is 63.82131136171036, parameters k is 15.470747035620969 and b is -75.18227900167301\n",
      "Iteration 1391, the loss is 63.820338867037464, parameters k is 15.470593887540094 and b is -75.18130480865761\n",
      "Iteration 1392, the loss is 63.819366419135676, parameters k is 15.470440743142007 and b is -75.18033063906886\n",
      "Iteration 1393, the loss is 63.81839401800263, parameters k is 15.470287602426616 and b is -75.17935649290618\n",
      "Iteration 1394, the loss is 63.81742166363609, parameters k is 15.470134465393835 and b is -75.178382370169\n",
      "Iteration 1395, the loss is 63.81644935603388, parameters k is 15.469981332043576 and b is -75.17740827085679\n",
      "Iteration 1396, the loss is 63.81547709519367, parameters k is 15.469828202375748 and b is -75.17643419496895\n",
      "Iteration 1397, the loss is 63.81450488111318, parameters k is 15.469675076390264 and b is -75.17546014250495\n",
      "Iteration 1398, the loss is 63.813532713790366, parameters k is 15.469521954087035 and b is -75.1744861134642\n",
      "Iteration 1399, the loss is 63.81256059322278, parameters k is 15.469368835465975 and b is -75.17351210784615\n",
      "Iteration 1400, the loss is 63.81158851940828, parameters k is 15.469215720526991 and b is -75.17253812565023\n",
      "Iteration 1401, the loss is 63.810616492344565, parameters k is 15.469062609269997 and b is -75.17156416687588\n",
      "Iteration 1402, the loss is 63.80964451202941, parameters k is 15.468909501694904 and b is -75.17059023152254\n",
      "Iteration 1403, the loss is 63.808672578460474, parameters k is 15.468756397801624 and b is -75.16961631958964\n",
      "Iteration 1404, the loss is 63.80770069163567, parameters k is 15.468603297590068 and b is -75.16864243107662\n",
      "Iteration 1405, the loss is 63.80672885155263, parameters k is 15.468450201060147 and b is -75.16766856598292\n",
      "Iteration 1406, the loss is 63.80575705820917, parameters k is 15.468297108211774 and b is -75.16669472430797\n",
      "Iteration 1407, the loss is 63.804785311603, parameters k is 15.468144019044859 and b is -75.16572090605122\n",
      "Iteration 1408, the loss is 63.803813611731925, parameters k is 15.467990933559312 and b is -75.1647471112121\n",
      "Iteration 1409, the loss is 63.80284195859355, parameters k is 15.467837851755048 and b is -75.16377333979003\n",
      "Iteration 1410, the loss is 63.801870352185844, parameters k is 15.467684773631976 and b is -75.16279959178446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1411, the loss is 63.800898792506395, parameters k is 15.467531699190008 and b is -75.16182586719485\n",
      "Iteration 1412, the loss is 63.79992727955306, parameters k is 15.467378628429056 and b is -75.1608521660206\n",
      "Iteration 1413, the loss is 63.798955813323595, parameters k is 15.467225561349032 and b is -75.15987848826117\n",
      "Iteration 1414, the loss is 63.797984393815554, parameters k is 15.467072497949847 and b is -75.15890483391598\n",
      "Iteration 1415, the loss is 63.79701302102693, parameters k is 15.466919438231411 and b is -75.15793120298449\n",
      "Iteration 1416, the loss is 63.79604169495543, parameters k is 15.466766382193637 and b is -75.15695759546611\n",
      "Iteration 1417, the loss is 63.795070415598765, parameters k is 15.466613329836436 and b is -75.1559840113603\n",
      "Iteration 1418, the loss is 63.794099182954625, parameters k is 15.466460281159721 and b is -75.1550104506665\n",
      "Iteration 1419, the loss is 63.79312799702083, parameters k is 15.4663072361634 and b is -75.15403691338412\n",
      "Iteration 1420, the loss is 63.79215685779518, parameters k is 15.46615419484739 and b is -75.1530633995126\n",
      "Iteration 1421, the loss is 63.79118576527531, parameters k is 15.466001157211597 and b is -75.1520899090514\n",
      "Iteration 1422, the loss is 63.790214719459115, parameters k is 15.465848123255935 and b is -75.15111644199995\n",
      "Iteration 1423, the loss is 63.789243720344196, parameters k is 15.465695092980315 and b is -75.15014299835768\n",
      "Iteration 1424, the loss is 63.78827276792847, parameters k is 15.465542066384648 and b is -75.14916957812403\n",
      "Iteration 1425, the loss is 63.78730186220953, parameters k is 15.465389043468846 and b is -75.14819618129843\n",
      "Iteration 1426, the loss is 63.78633100318523, parameters k is 15.465236024232821 and b is -75.14722280788033\n",
      "Iteration 1427, the loss is 63.78536019085341, parameters k is 15.465083008676485 and b is -75.14624945786916\n",
      "Iteration 1428, the loss is 63.78438942521155, parameters k is 15.464929996799748 and b is -75.14527613126435\n",
      "Iteration 1429, the loss is 63.78341870625762, parameters k is 15.464776988602523 and b is -75.14430282806535\n",
      "Iteration 1430, the loss is 63.78244803398935, parameters k is 15.46462398408472 and b is -75.1433295482716\n",
      "Iteration 1431, the loss is 63.78147740840442, parameters k is 15.464470983246253 and b is -75.14235629188252\n",
      "Iteration 1432, the loss is 63.78050682950073, parameters k is 15.46431798608703 and b is -75.14138305889756\n",
      "Iteration 1433, the loss is 63.77953629727585, parameters k is 15.464164992606966 and b is -75.14040984931616\n",
      "Iteration 1434, the loss is 63.778565811727695, parameters k is 15.464012002805969 and b is -75.13943666313774\n",
      "Iteration 1435, the loss is 63.77759537285395, parameters k is 15.463859016683953 and b is -75.13846350036175\n",
      "Iteration 1436, the loss is 63.7766249806523, parameters k is 15.463706034240829 and b is -75.13749036098763\n",
      "Iteration 1437, the loss is 63.77565463512063, parameters k is 15.463553055476508 and b is -75.13651724501482\n",
      "Iteration 1438, the loss is 63.774684336256584, parameters k is 15.463400080390903 and b is -75.13554415244273\n",
      "Iteration 1439, the loss is 63.773714084058035, parameters k is 15.463247108983923 and b is -75.13457108327083\n",
      "Iteration 1440, the loss is 63.77274387852266, parameters k is 15.463094141255482 and b is -75.13359803749854\n",
      "Iteration 1441, the loss is 63.77177371964822, parameters k is 15.46294117720549 and b is -75.13262501512531\n",
      "Iteration 1442, the loss is 63.770803607432434, parameters k is 15.462788216833859 and b is -75.13165201615057\n",
      "Iteration 1443, the loss is 63.76983354187314, parameters k is 15.462635260140502 and b is -75.13067904057375\n",
      "Iteration 1444, the loss is 63.76886352296809, parameters k is 15.46248230712533 and b is -75.1297060883943\n",
      "Iteration 1445, the loss is 63.767893550714966, parameters k is 15.462329357788251 and b is -75.12873315961164\n",
      "Iteration 1446, the loss is 63.76692362511151, parameters k is 15.46217641212918 and b is -75.12776025422522\n",
      "Iteration 1447, the loss is 63.76595374615565, parameters k is 15.46202347014803 and b is -75.12678737223449\n",
      "Iteration 1448, the loss is 63.764983913844944, parameters k is 15.461870531844708 and b is -75.12581451363886\n",
      "Iteration 1449, the loss is 63.764014128177315, parameters k is 15.46171759721913 and b is -75.12484167843779\n",
      "Iteration 1450, the loss is 63.76304438915037, parameters k is 15.461564666271205 and b is -75.1238688666307\n",
      "Iteration 1451, the loss is 63.76207469676194, parameters k is 15.461411739000845 and b is -75.12289607821704\n",
      "Iteration 1452, the loss is 63.761105051009785, parameters k is 15.46125881540796 and b is -75.12192331319625\n",
      "Iteration 1453, the loss is 63.76013545189167, parameters k is 15.461105895492466 and b is -75.12095057156775\n",
      "Iteration 1454, the loss is 63.75916589940526, parameters k is 15.46095297925427 and b is -75.119977853331\n",
      "Iteration 1455, the loss is 63.758196393548445, parameters k is 15.460800066693285 and b is -75.11900515848541\n",
      "Iteration 1456, the loss is 63.75722693431889, parameters k is 15.460647157809424 and b is -75.11803248703043\n",
      "Iteration 1457, the loss is 63.75625752171446, parameters k is 15.460494252602597 and b is -75.11705983896552\n",
      "Iteration 1458, the loss is 63.75528815573273, parameters k is 15.460341351072717 and b is -75.11608721429009\n",
      "Iteration 1459, the loss is 63.75431883637166, parameters k is 15.460188453219695 and b is -75.11511461300358\n",
      "Iteration 1460, the loss is 63.75334956362888, parameters k is 15.460035559043442 and b is -75.11414203510544\n",
      "Iteration 1461, the loss is 63.75238033750215, parameters k is 15.45988266854387 and b is -75.1131694805951\n",
      "Iteration 1462, the loss is 63.751411157989345, parameters k is 15.45972978172089 and b is -75.11219694947201\n",
      "Iteration 1463, the loss is 63.75044202508802, parameters k is 15.459576898574413 and b is -75.11122444173559\n",
      "Iteration 1464, the loss is 63.74947293879613, parameters k is 15.459424019104352 and b is -75.11025195738527\n",
      "Iteration 1465, the loss is 63.74850389911128, parameters k is 15.45927114331062 and b is -75.10927949642051\n",
      "Iteration 1466, the loss is 63.747534906031426, parameters k is 15.459118271193125 and b is -75.10830705884074\n",
      "Iteration 1467, the loss is 63.746565959554125, parameters k is 15.458965402751781 and b is -75.10733464464539\n",
      "Iteration 1468, the loss is 63.7455970596772, parameters k is 15.4588125379865 and b is -75.10636225383391\n",
      "Iteration 1469, the loss is 63.74462820639849, parameters k is 15.458659676897192 and b is -75.10538988640573\n",
      "Iteration 1470, the loss is 63.74365939971565, parameters k is 15.458506819483768 and b is -75.1044175423603\n",
      "Iteration 1471, the loss is 63.742690639626424, parameters k is 15.458353965746142 and b is -75.10344522169703\n",
      "Iteration 1472, the loss is 63.74172192612869, parameters k is 15.458201115684224 and b is -75.10247292441538\n",
      "Iteration 1473, the loss is 63.74075325922005, parameters k is 15.458048269297926 and b is -75.10150065051478\n",
      "Iteration 1474, the loss is 63.739784638898456, parameters k is 15.457895426587159 and b is -75.10052839999467\n",
      "Iteration 1475, the loss is 63.73881606516158, parameters k is 15.457742587551836 and b is -75.09955617285449\n",
      "Iteration 1476, the loss is 63.7378475380071, parameters k is 15.457589752191868 and b is -75.09858396909368\n",
      "Iteration 1477, the loss is 63.7368790574329, parameters k is 15.457436920507167 and b is -75.09761178871167\n",
      "Iteration 1478, the loss is 63.73591062343663, parameters k is 15.457284092497643 and b is -75.09663963170792\n",
      "Iteration 1479, the loss is 63.73494223601613, parameters k is 15.45713126816321 and b is -75.09566749808184\n",
      "Iteration 1480, the loss is 63.733973895169164, parameters k is 15.456978447503777 and b is -75.09469538783287\n",
      "Iteration 1481, the loss is 63.733005600893456, parameters k is 15.456825630519258 and b is -75.09372330096046\n",
      "Iteration 1482, the loss is 63.73203735318667, parameters k is 15.456672817209563 and b is -75.09275123746404\n",
      "Iteration 1483, the loss is 63.73106915204674, parameters k is 15.456520007574605 and b is -75.09177919734306\n",
      "Iteration 1484, the loss is 63.730100997471396, parameters k is 15.456367201614293 and b is -75.09080718059694\n",
      "Iteration 1485, the loss is 63.72913288945834, parameters k is 15.456214399328543 and b is -75.08983518722513\n",
      "Iteration 1486, the loss is 63.72816482800532, parameters k is 15.456061600717263 and b is -75.08886321722707\n",
      "Iteration 1487, the loss is 63.727196813110076, parameters k is 15.455908805780366 and b is -75.08789127060219\n",
      "Iteration 1488, the loss is 63.72622884477047, parameters k is 15.455756014517762 and b is -75.08691934734992\n",
      "Iteration 1489, the loss is 63.72526092298429, parameters k is 15.455603226929366 and b is -75.0859474474697\n",
      "Iteration 1490, the loss is 63.724293047749015, parameters k is 15.455450443015087 and b is -75.08497557096099\n",
      "Iteration 1491, the loss is 63.72332521906278, parameters k is 15.455297662774838 and b is -75.08400371782322\n",
      "Iteration 1492, the loss is 63.722357436923176, parameters k is 15.45514488620853 and b is -75.08303188805581\n",
      "Iteration 1493, the loss is 63.72138970132793, parameters k is 15.454992113316074 and b is -75.08206008165823\n",
      "Iteration 1494, the loss is 63.7204220122748, parameters k is 15.454839344097381 and b is -75.08108829862988\n",
      "Iteration 1495, the loss is 63.71945436976158, parameters k is 15.454686578552366 and b is -75.08011653897022\n",
      "Iteration 1496, the loss is 63.718486773786154, parameters k is 15.454533816680938 and b is -75.07914480267868\n",
      "Iteration 1497, the loss is 63.71751922434607, parameters k is 15.454381058483008 and b is -75.07817308975471\n",
      "Iteration 1498, the loss is 63.71655172143913, parameters k is 15.454228303958491 and b is -75.07720140019774\n",
      "Iteration 1499, the loss is 63.71558426506323, parameters k is 15.454075553107295 and b is -75.0762297340072\n",
      "Iteration 1500, the loss is 63.71461685521611, parameters k is 15.453922805929334 and b is -75.07525809118255\n",
      "Iteration 1501, the loss is 63.713649491895445, parameters k is 15.45377006242452 and b is -75.07428647172321\n",
      "Iteration 1502, the loss is 63.71268217509897, parameters k is 15.453617322592763 and b is -75.07331487562863\n",
      "Iteration 1503, the loss is 63.711714904824504, parameters k is 15.453464586433974 and b is -75.07234330289823\n",
      "Iteration 1504, the loss is 63.710747681069904, parameters k is 15.453311853948067 and b is -75.07137175353147\n",
      "Iteration 1505, the loss is 63.70978050383273, parameters k is 15.453159125134952 and b is -75.07040022752777\n",
      "Iteration 1506, the loss is 63.70881337311097, parameters k is 15.453006399994543 and b is -75.06942872488658\n",
      "Iteration 1507, the loss is 63.707846288902246, parameters k is 15.452853678526749 and b is -75.06845724560733\n",
      "Iteration 1508, the loss is 63.706879251204334, parameters k is 15.452700960731482 and b is -75.06748578968947\n",
      "Iteration 1509, the loss is 63.70591226001497, parameters k is 15.452548246608655 and b is -75.06651435713242\n",
      "Iteration 1510, the loss is 63.704945315332, parameters k is 15.45239553615818 and b is -75.06554294793563\n",
      "Iteration 1511, the loss is 63.70397841715315, parameters k is 15.452242829379967 and b is -75.06457156209854\n",
      "Iteration 1512, the loss is 63.7030115654762, parameters k is 15.452090126273928 and b is -75.06360019962058\n",
      "Iteration 1513, the loss is 63.70204476029876, parameters k is 15.451937426839976 and b is -75.06262886050119\n",
      "Iteration 1514, the loss is 63.70107800161889, parameters k is 15.451784731078021 and b is -75.06165754473982\n",
      "Iteration 1515, the loss is 63.7001112894341, parameters k is 15.451632038987976 and b is -75.0606862523359\n",
      "Iteration 1516, the loss is 63.69914462374231, parameters k is 15.451479350569752 and b is -75.05971498328887\n",
      "Iteration 1517, the loss is 63.69817800454113, parameters k is 15.451326665823261 and b is -75.05874373759816\n",
      "Iteration 1518, the loss is 63.69721143182848, parameters k is 15.451173984748415 and b is -75.05777251526322\n",
      "Iteration 1519, the loss is 63.696244905602086, parameters k is 15.451021307345124 and b is -75.05680131628348\n",
      "Iteration 1520, the loss is 63.69527842585956, parameters k is 15.450868633613302 and b is -75.05583014065839\n",
      "Iteration 1521, the loss is 63.69431199259889, parameters k is 15.45071596355286 and b is -75.05485898838737\n",
      "Iteration 1522, the loss is 63.6933456058177, parameters k is 15.45056329716371 and b is -75.05388785946987\n",
      "Iteration 1523, the loss is 63.692379265513786, parameters k is 15.450410634445761 and b is -75.05291675390532\n",
      "Iteration 1524, the loss is 63.69141297168496, parameters k is 15.450257975398928 and b is -75.05194567169318\n",
      "Iteration 1525, the loss is 63.690446724328986, parameters k is 15.450105320023123 and b is -75.05097461283286\n",
      "Iteration 1526, the loss is 63.68948052344351, parameters k is 15.449952668318256 and b is -75.05000357732382\n",
      "Iteration 1527, the loss is 63.68851436902637, parameters k is 15.449800020284238 and b is -75.04903256516549\n",
      "Iteration 1528, the loss is 63.68754826107538, parameters k is 15.449647375920982 and b is -75.04806157635731\n",
      "Iteration 1529, the loss is 63.68658219958825, parameters k is 15.4494947352284 and b is -75.04709061089872\n",
      "Iteration 1530, the loss is 63.68561618456279, parameters k is 15.449342098206404 and b is -75.04611966878916\n",
      "Iteration 1531, the loss is 63.6846502159967, parameters k is 15.449189464854905 and b is -75.04514875002806\n",
      "Iteration 1532, the loss is 63.68368429388774, parameters k is 15.449036835173814 and b is -75.04417785461486\n",
      "Iteration 1533, the loss is 63.68271841823384, parameters k is 15.448884209163044 and b is -75.04320698254901\n",
      "Iteration 1534, the loss is 63.68175258903259, parameters k is 15.448731586822506 and b is -75.04223613382993\n",
      "Iteration 1535, the loss is 63.680786806281766, parameters k is 15.44857896815211 and b is -75.04126530845707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1536, the loss is 63.67982106997924, parameters k is 15.448426353151772 and b is -75.04029450642987\n",
      "Iteration 1537, the loss is 63.67885538012265, parameters k is 15.448273741821401 and b is -75.03932372774777\n",
      "Iteration 1538, the loss is 63.67788973670988, parameters k is 15.44812113416091 and b is -75.03835297241021\n",
      "Iteration 1539, the loss is 63.676924139738595, parameters k is 15.44796853017021 and b is -75.03738224041662\n",
      "Iteration 1540, the loss is 63.675958589206665, parameters k is 15.447815929849211 and b is -75.03641153176643\n",
      "Iteration 1541, the loss is 63.67499308511177, parameters k is 15.447663333197829 and b is -75.0354408464591\n",
      "Iteration 1542, the loss is 63.67402762745168, parameters k is 15.447510740215971 and b is -75.03447018449405\n",
      "Iteration 1543, the loss is 63.67306221622419, parameters k is 15.447358150903552 and b is -75.03349954587074\n",
      "Iteration 1544, the loss is 63.672096851427156, parameters k is 15.447205565260482 and b is -75.0325289305886\n",
      "Iteration 1545, the loss is 63.671131533058144, parameters k is 15.447052983286675 and b is -75.03155833864706\n",
      "Iteration 1546, the loss is 63.6701662611151, parameters k is 15.44690040498204 and b is -75.03058777004556\n",
      "Iteration 1547, the loss is 63.66920103559572, parameters k is 15.44674783034649 and b is -75.02961722478354\n",
      "Iteration 1548, the loss is 63.66823585649773, parameters k is 15.446595259379938 and b is -75.02864670286044\n",
      "Iteration 1549, the loss is 63.6672707238189, parameters k is 15.446442692082293 and b is -75.0276762042757\n",
      "Iteration 1550, the loss is 63.666305637557116, parameters k is 15.44629012845347 and b is -75.02670572902878\n",
      "Iteration 1551, the loss is 63.665340597710156, parameters k is 15.446137568493377 and b is -75.02573527711908\n",
      "Iteration 1552, the loss is 63.664375604275584, parameters k is 15.445985012201929 and b is -75.02476484854606\n",
      "Iteration 1553, the loss is 63.663410657251305, parameters k is 15.445832459579036 and b is -75.02379444330916\n",
      "Iteration 1554, the loss is 63.662445756635066, parameters k is 15.44567991062461 and b is -75.0228240614078\n",
      "Iteration 1555, the loss is 63.66148090242466, parameters k is 15.445527365338565 and b is -75.02185370284144\n",
      "Iteration 1556, the loss is 63.66051609461778, parameters k is 15.44537482372081 and b is -75.02088336760951\n",
      "Iteration 1557, the loss is 63.65955133321232, parameters k is 15.445222285771258 and b is -75.01991305571146\n",
      "Iteration 1558, the loss is 63.65858661820593, parameters k is 15.445069751489822 and b is -75.01894276714671\n",
      "Iteration 1559, the loss is 63.65762194959642, parameters k is 15.44491722087641 and b is -75.01797250191471\n",
      "Iteration 1560, the loss is 63.65665732738153, parameters k is 15.444764693930939 and b is -75.0170022600149\n",
      "Iteration 1561, the loss is 63.65569275155914, parameters k is 15.444612170653317 and b is -75.01603204144672\n",
      "Iteration 1562, the loss is 63.65472822212689, parameters k is 15.444459651043456 and b is -75.0150618462096\n",
      "Iteration 1563, the loss is 63.65376373908261, parameters k is 15.444307135101269 and b is -75.01409167430299\n",
      "Iteration 1564, the loss is 63.65279930242402, parameters k is 15.444154622826666 and b is -75.01312152572632\n",
      "Iteration 1565, the loss is 63.65183491214891, parameters k is 15.444002114219561 and b is -75.01215140047903\n",
      "Iteration 1566, the loss is 63.65087056825514, parameters k is 15.443849609279866 and b is -75.01118129856056\n",
      "Iteration 1567, the loss is 63.649906270740374, parameters k is 15.443697108007491 and b is -75.01021121997036\n",
      "Iteration 1568, the loss is 63.64894201960242, parameters k is 15.443544610402348 and b is -75.00924116470786\n",
      "Iteration 1569, the loss is 63.647977814838995, parameters k is 15.44339211646435 and b is -75.00827113277249\n",
      "Iteration 1570, the loss is 63.64701365644793, parameters k is 15.443239626193408 and b is -75.0073011241637\n",
      "Iteration 1571, the loss is 63.64604954442703, parameters k is 15.443087139589435 and b is -75.00633113888094\n",
      "Iteration 1572, the loss is 63.645085478774, parameters k is 15.44293465665234 and b is -75.00536117692363\n",
      "Iteration 1573, the loss is 63.64412145948657, parameters k is 15.442782177382039 and b is -75.0043912382912\n",
      "Iteration 1574, the loss is 63.64315748656263, parameters k is 15.44262970177844 and b is -75.00342132298312\n",
      "Iteration 1575, the loss is 63.64219355999986, parameters k is 15.442477229841456 and b is -75.0024514309988\n",
      "Iteration 1576, the loss is 63.64122967979603, parameters k is 15.442324761571001 and b is -75.0014815623377\n",
      "Iteration 1577, the loss is 63.64026584594896, parameters k is 15.442172296966984 and b is -75.00051171699926\n",
      "Iteration 1578, the loss is 63.639302058456366, parameters k is 15.442019836029317 and b is -74.9995418949829\n",
      "Iteration 1579, the loss is 63.63833831731604, parameters k is 15.441867378757914 and b is -74.99857209628807\n",
      "Iteration 1580, the loss is 63.63737462252578, parameters k is 15.441714925152686 and b is -74.99760232091421\n",
      "Iteration 1581, the loss is 63.63641097408332, parameters k is 15.441562475213544 and b is -74.99663256886076\n",
      "Iteration 1582, the loss is 63.635447371986494, parameters k is 15.4414100289404 and b is -74.99566284012715\n",
      "Iteration 1583, the loss is 63.634483816232965, parameters k is 15.441257586333165 and b is -74.99469313471283\n",
      "Iteration 1584, the loss is 63.63352030682052, parameters k is 15.441105147391752 and b is -74.99372345261723\n",
      "Iteration 1585, the loss is 63.632556843747125, parameters k is 15.440952712116074 and b is -74.9927537938398\n",
      "Iteration 1586, the loss is 63.63159342701031, parameters k is 15.440800280506041 and b is -74.99178415837997\n",
      "Iteration 1587, the loss is 63.63063005660794, parameters k is 15.440647852561565 and b is -74.99081454623719\n",
      "Iteration 1588, the loss is 63.6296667325378, parameters k is 15.440495428282558 and b is -74.9898449574109\n",
      "Iteration 1589, the loss is 63.62870345479767, parameters k is 15.440343007668933 and b is -74.98887539190052\n",
      "Iteration 1590, the loss is 63.62774022338524, parameters k is 15.4401905907206 and b is -74.9879058497055\n",
      "Iteration 1591, the loss is 63.62677703829842, parameters k is 15.440038177437474 and b is -74.98693633082529\n",
      "Iteration 1592, the loss is 63.625813899534855, parameters k is 15.439885767819463 and b is -74.9859668352593\n",
      "Iteration 1593, the loss is 63.62485080709233, parameters k is 15.439733361866482 and b is -74.98499736300701\n",
      "Iteration 1594, the loss is 63.62388776096871, parameters k is 15.439580959578441 and b is -74.98402791406784\n",
      "Iteration 1595, the loss is 63.6229247611617, parameters k is 15.439428560955252 and b is -74.98305848844122\n",
      "Iteration 1596, the loss is 63.62196180766906, parameters k is 15.439276165996827 and b is -74.98208908612659\n",
      "Iteration 1597, the loss is 63.6209989004886, parameters k is 15.439123774703077 and b is -74.98111970712341\n",
      "Iteration 1598, the loss is 63.62003603961804, parameters k is 15.438971387073916 and b is -74.9801503514311\n",
      "Iteration 1599, the loss is 63.61907322505527, parameters k is 15.438819003109256 and b is -74.97918101904911\n",
      "Iteration 1600, the loss is 63.618110456797886, parameters k is 15.438666622809006 and b is -74.97821170997688\n",
      "Iteration 1601, the loss is 63.61714773484382, parameters k is 15.43851424617308 and b is -74.97724242421383\n",
      "Iteration 1602, the loss is 63.616185059190805, parameters k is 15.438361873201389 and b is -74.97627316175942\n",
      "Iteration 1603, the loss is 63.61522242983655, parameters k is 15.438209503893846 and b is -74.9753039226131\n",
      "Iteration 1604, the loss is 63.61425984677889, parameters k is 15.438057138250363 and b is -74.97433470677427\n",
      "Iteration 1605, the loss is 63.613297310015575, parameters k is 15.43790477627085 and b is -74.9733655142424\n",
      "Iteration 1606, the loss is 63.61233481954434, parameters k is 15.43775241795522 and b is -74.97239634501692\n",
      "Iteration 1607, the loss is 63.61137237536308, parameters k is 15.437600063303385 and b is -74.97142719909728\n",
      "Iteration 1608, the loss is 63.61040997746938, parameters k is 15.437447712315258 and b is -74.9704580764829\n",
      "Iteration 1609, the loss is 63.609447625861165, parameters k is 15.437295364990748 and b is -74.96948897717323\n",
      "Iteration 1610, the loss is 63.608485320536246, parameters k is 15.437143021329769 and b is -74.96851990116771\n",
      "Iteration 1611, the loss is 63.607523061492245, parameters k is 15.436990681332233 and b is -74.96755084846579\n",
      "Iteration 1612, the loss is 63.60656084872701, parameters k is 15.436838344998051 and b is -74.9665818190669\n",
      "Iteration 1613, the loss is 63.60559868223838, parameters k is 15.436686012327135 and b is -74.96561281297048\n",
      "Iteration 1614, the loss is 63.604636562024005, parameters k is 15.436533683319396 and b is -74.96464383017596\n",
      "Iteration 1615, the loss is 63.60367448808172, parameters k is 15.43638135797475 and b is -74.9636748706828\n",
      "Iteration 1616, the loss is 63.602712460409286, parameters k is 15.436229036293104 and b is -74.96270593449042\n",
      "Iteration 1617, the loss is 63.60175047900454, parameters k is 15.436076718274373 and b is -74.96173702159827\n",
      "Iteration 1618, the loss is 63.60078854386516, parameters k is 15.435924403918468 and b is -74.96076813200578\n",
      "Iteration 1619, the loss is 63.59982665498897, parameters k is 15.435772093225301 and b is -74.9597992657124\n",
      "Iteration 1620, the loss is 63.59886481237376, parameters k is 15.435619786194783 and b is -74.95883042271758\n",
      "Iteration 1621, the loss is 63.5979030160173, parameters k is 15.435467482826827 and b is -74.95786160302075\n",
      "Iteration 1622, the loss is 63.59694126591737, parameters k is 15.435315183121343 and b is -74.95689280662133\n",
      "Iteration 1623, the loss is 63.595979562071655, parameters k is 15.435162887078246 and b is -74.95592403351878\n",
      "Iteration 1624, the loss is 63.59501790447801, parameters k is 15.435010594697445 and b is -74.95495528371254\n",
      "Iteration 1625, the loss is 63.5940562931343, parameters k is 15.434858305978855 and b is -74.95398655720204\n",
      "Iteration 1626, the loss is 63.59309472803811, parameters k is 15.434706020922386 and b is -74.95301785398674\n",
      "Iteration 1627, the loss is 63.59213320918736, parameters k is 15.43455373952795 and b is -74.95204917406605\n",
      "Iteration 1628, the loss is 63.59117173657979, parameters k is 15.434401461795458 and b is -74.95108051743942\n",
      "Iteration 1629, the loss is 63.590210310213095, parameters k is 15.434249187724825 and b is -74.9501118841063\n",
      "Iteration 1630, the loss is 63.58924893008522, parameters k is 15.43409691731596 and b is -74.94914327406613\n",
      "Iteration 1631, the loss is 63.58828759619371, parameters k is 15.433944650568776 and b is -74.94817468731834\n",
      "Iteration 1632, the loss is 63.58732630853661, parameters k is 15.433792387483185 and b is -74.94720612386239\n",
      "Iteration 1633, the loss is 63.5863650671115, parameters k is 15.4336401280591 and b is -74.9462375836977\n",
      "Iteration 1634, the loss is 63.58540387191618, parameters k is 15.43348787229643 and b is -74.9452690668237\n",
      "Iteration 1635, the loss is 63.5844427229485, parameters k is 15.43333562019509 and b is -74.94430057323986\n",
      "Iteration 1636, the loss is 63.58348162020617, parameters k is 15.43318337175499 and b is -74.94333210294559\n",
      "Iteration 1637, the loss is 63.58252056368705, parameters k is 15.433031126976044 and b is -74.94236365594035\n",
      "Iteration 1638, the loss is 63.5815595533888, parameters k is 15.43287888585816 and b is -74.94139523222358\n",
      "Iteration 1639, the loss is 63.58059858930927, parameters k is 15.432726648401255 and b is -74.94042683179471\n",
      "Iteration 1640, the loss is 63.57963767144623, parameters k is 15.432574414605238 and b is -74.93945845465319\n",
      "Iteration 1641, the loss is 63.57867679979745, parameters k is 15.432422184470022 and b is -74.93849010079845\n",
      "Iteration 1642, the loss is 63.57771597436071, parameters k is 15.43226995799552 and b is -74.93752177022994\n",
      "Iteration 1643, the loss is 63.576755195133806, parameters k is 15.43211773518164 and b is -74.93655346294709\n",
      "Iteration 1644, the loss is 63.57579446211451, parameters k is 15.431965516028297 and b is -74.93558517894934\n",
      "Iteration 1645, the loss is 63.574833775300576, parameters k is 15.431813300535403 and b is -74.93461691823613\n",
      "Iteration 1646, the loss is 63.57387313468974, parameters k is 15.43166108870287 and b is -74.93364868080691\n",
      "Iteration 1647, the loss is 63.57291254027988, parameters k is 15.431508880530608 and b is -74.93268046666111\n",
      "Iteration 1648, the loss is 63.57195199206873, parameters k is 15.431356676018531 and b is -74.93171227579818\n",
      "Iteration 1649, the loss is 63.570991490054055, parameters k is 15.43120447516655 and b is -74.93074410821755\n",
      "Iteration 1650, the loss is 63.57003103423368, parameters k is 15.431052277974578 and b is -74.92977596391867\n",
      "Iteration 1651, the loss is 63.569070624605224, parameters k is 15.430900084442525 and b is -74.92880784290098\n",
      "Iteration 1652, the loss is 63.56811026116672, parameters k is 15.430747894570306 and b is -74.92783974516391\n",
      "Iteration 1653, the loss is 63.56714994391575, parameters k is 15.43059570835783 and b is -74.9268716707069\n",
      "Iteration 1654, the loss is 63.566189672850214, parameters k is 15.43044352580501 and b is -74.92590361952941\n",
      "Iteration 1655, the loss is 63.56522944796777, parameters k is 15.43029134691176 and b is -74.92493559163086\n",
      "Iteration 1656, the loss is 63.56426926926629, parameters k is 15.43013917167799 and b is -74.9239675870107\n",
      "Iteration 1657, the loss is 63.56330913674352, parameters k is 15.42998700010361 and b is -74.92299960566835\n",
      "Iteration 1658, the loss is 63.56234905039727, parameters k is 15.429834832188536 and b is -74.92203164760328\n",
      "Iteration 1659, the loss is 63.56138901022531, parameters k is 15.429682667932678 and b is -74.92106371281491\n",
      "Iteration 1660, the loss is 63.56042901622533, parameters k is 15.429530507335947 and b is -74.9200958013027\n",
      "Iteration 1661, the loss is 63.55946906839522, parameters k is 15.429378350398258 and b is -74.91912791306606\n",
      "Iteration 1662, the loss is 63.55850916673272, parameters k is 15.42922619711952 and b is -74.91816004810445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1663, the loss is 63.55754931123557, parameters k is 15.429074047499649 and b is -74.91719220641731\n",
      "Iteration 1664, the loss is 63.5565895019016, parameters k is 15.428921901538553 and b is -74.91622438800408\n",
      "Iteration 1665, the loss is 63.5556297387286, parameters k is 15.428769759236145 and b is -74.9152565928642\n",
      "Iteration 1666, the loss is 63.55467002171436, parameters k is 15.428617620592338 and b is -74.9142888209971\n",
      "Iteration 1667, the loss is 63.55371035085661, parameters k is 15.428465485607042 and b is -74.91332107240224\n",
      "Iteration 1668, the loss is 63.55275072615312, parameters k is 15.42831335428017 and b is -74.91235334707905\n",
      "Iteration 1669, the loss is 63.55179114760173, parameters k is 15.428161226611637 and b is -74.91138564502697\n",
      "Iteration 1670, the loss is 63.55083161520017, parameters k is 15.42800910260135 and b is -74.91041796624543\n",
      "Iteration 1671, the loss is 63.549872128946234, parameters k is 15.427856982249226 and b is -74.90945031073389\n",
      "Iteration 1672, the loss is 63.54891268883772, parameters k is 15.427704865555173 and b is -74.90848267849178\n",
      "Iteration 1673, the loss is 63.547953294872464, parameters k is 15.427552752519105 and b is -74.90751506951854\n",
      "Iteration 1674, the loss is 63.54699394704807, parameters k is 15.427400643140933 and b is -74.90654748381361\n",
      "Iteration 1675, the loss is 63.54603464536251, parameters k is 15.42724853742057 and b is -74.90557992137643\n",
      "Iteration 1676, the loss is 63.54507538981345, parameters k is 15.427096435357928 and b is -74.90461238220645\n",
      "Iteration 1677, the loss is 63.54411618039868, parameters k is 15.426944336952918 and b is -74.9036448663031\n",
      "Iteration 1678, the loss is 63.543157017116066, parameters k is 15.426792242205453 and b is -74.90267737366582\n",
      "Iteration 1679, the loss is 63.54219789996329, parameters k is 15.426640151115445 and b is -74.90170990429407\n",
      "Iteration 1680, the loss is 63.54123882893818, parameters k is 15.426488063682806 and b is -74.90074245818725\n",
      "Iteration 1681, the loss is 63.54027980403849, parameters k is 15.426335979907448 and b is -74.89977503534485\n",
      "Iteration 1682, the loss is 63.5393208252621, parameters k is 15.426183899789283 and b is -74.89880763576627\n",
      "Iteration 1683, the loss is 63.538361892606616, parameters k is 15.426031823328223 and b is -74.89784025945097\n",
      "Iteration 1684, the loss is 63.537403006070015, parameters k is 15.42587975052418 and b is -74.89687290639839\n",
      "Iteration 1685, the loss is 63.53644416564992, parameters k is 15.425727681377065 and b is -74.89590557660796\n",
      "Iteration 1686, the loss is 63.5354853713442, parameters k is 15.425575615886792 and b is -74.89493827007914\n",
      "Iteration 1687, the loss is 63.53452662315062, parameters k is 15.425423554053273 and b is -74.89397098681135\n",
      "Iteration 1688, the loss is 63.53356792106693, parameters k is 15.42527149587642 and b is -74.89300372680405\n",
      "Iteration 1689, the loss is 63.53260926509092, parameters k is 15.425119441356143 and b is -74.89203649005667\n",
      "Iteration 1690, the loss is 63.53165065522045, parameters k is 15.424967390492355 and b is -74.89106927656864\n",
      "Iteration 1691, the loss is 63.53069209145322, parameters k is 15.424815343284969 and b is -74.89010208633943\n",
      "Iteration 1692, the loss is 63.52973357378702, parameters k is 15.424663299733897 and b is -74.88913491936844\n",
      "Iteration 1693, the loss is 63.52877510221963, parameters k is 15.42451125983905 and b is -74.88816777565515\n",
      "Iteration 1694, the loss is 63.52781667674887, parameters k is 15.424359223600343 and b is -74.88720065519898\n",
      "Iteration 1695, the loss is 63.52685829737256, parameters k is 15.424207191017684 and b is -74.88623355799938\n",
      "Iteration 1696, the loss is 63.525899964088374, parameters k is 15.424055162090987 and b is -74.88526648405578\n",
      "Iteration 1697, the loss is 63.52494167689415, parameters k is 15.423903136820165 and b is -74.88429943336762\n",
      "Iteration 1698, the loss is 63.523983435787684, parameters k is 15.423751115205128 and b is -74.88333240593434\n",
      "Iteration 1699, the loss is 63.523025240766664, parameters k is 15.42359909724579 and b is -74.8823654017554\n",
      "Iteration 1700, the loss is 63.52206709182905, parameters k is 15.423447082942062 and b is -74.88139842083022\n",
      "Iteration 1701, the loss is 63.52110898897254, parameters k is 15.423295072293856 and b is -74.88043146315826\n",
      "Iteration 1702, the loss is 63.52015093219486, parameters k is 15.423143065301085 and b is -74.87946452873895\n",
      "Iteration 1703, the loss is 63.51919292149389, parameters k is 15.42299106196366 and b is -74.87849761757172\n",
      "Iteration 1704, the loss is 63.518234956867275, parameters k is 15.422839062281495 and b is -74.87753072965603\n",
      "Iteration 1705, the loss is 63.51727703831297, parameters k is 15.4226870662545 and b is -74.87656386499131\n",
      "Iteration 1706, the loss is 63.51631916582865, parameters k is 15.422535073882587 and b is -74.875597023577\n",
      "Iteration 1707, the loss is 63.51536133941212, parameters k is 15.42238308516567 and b is -74.87463020541254\n",
      "Iteration 1708, the loss is 63.514403559061236, parameters k is 15.422231100103659 and b is -74.87366341049739\n",
      "Iteration 1709, the loss is 63.51344582477361, parameters k is 15.422079118696468 and b is -74.87269663883096\n",
      "Iteration 1710, the loss is 63.51248813654724, parameters k is 15.421927140944007 and b is -74.87172989041271\n",
      "Iteration 1711, the loss is 63.511530494379784, parameters k is 15.42177516684619 and b is -74.87076316524208\n",
      "Iteration 1712, the loss is 63.51057289826903, parameters k is 15.42162319640293 and b is -74.86979646331851\n",
      "Iteration 1713, the loss is 63.50961534821276, parameters k is 15.421471229614136 and b is -74.86882978464143\n",
      "Iteration 1714, the loss is 63.50865784420885, parameters k is 15.421319266479722 and b is -74.8678631292103\n",
      "Iteration 1715, the loss is 63.50770038625492, parameters k is 15.4211673069996 and b is -74.86689649702456\n",
      "Iteration 1716, the loss is 63.50674297434889, parameters k is 15.421015351173681 and b is -74.86592988808363\n",
      "Iteration 1717, the loss is 63.50578560848851, parameters k is 15.42086339900188 and b is -74.86496330238697\n",
      "Iteration 1718, the loss is 63.50482828867162, parameters k is 15.420711450484106 and b is -74.86399673993401\n",
      "Iteration 1719, the loss is 63.50387101489594, parameters k is 15.420559505620272 and b is -74.8630302007242\n",
      "Iteration 1720, the loss is 63.50291378715921, parameters k is 15.42040756441029 and b is -74.86206368475698\n",
      "Iteration 1721, the loss is 63.50195660545925, parameters k is 15.420255626854074 and b is -74.86109719203178\n",
      "Iteration 1722, the loss is 63.500999469793946, parameters k is 15.420103692951534 and b is -74.86013072254806\n",
      "Iteration 1723, the loss is 63.50004238016098, parameters k is 15.419951762702583 and b is -74.85916427630525\n",
      "Iteration 1724, the loss is 63.49908533655813, parameters k is 15.419799836107133 and b is -74.8581978533028\n",
      "Iteration 1725, the loss is 63.49812833898323, parameters k is 15.419647913165097 and b is -74.85723145354014\n",
      "Iteration 1726, the loss is 63.497171387434044, parameters k is 15.419495993876387 and b is -74.8562650770167\n",
      "Iteration 1727, the loss is 63.496214481908424, parameters k is 15.419344078240915 and b is -74.85529872373195\n",
      "Iteration 1728, the loss is 63.49525762240405, parameters k is 15.419192166258592 and b is -74.85433239368531\n",
      "Iteration 1729, the loss is 63.49430080891874, parameters k is 15.41904025792933 and b is -74.85336608687622\n",
      "Iteration 1730, the loss is 63.49334404145038, parameters k is 15.418888353253044 and b is -74.85239980330414\n",
      "Iteration 1731, the loss is 63.49238731999661, parameters k is 15.418736452229643 and b is -74.8514335429685\n",
      "Iteration 1732, the loss is 63.49143064455523, parameters k is 15.41858455485904 and b is -74.85046730586873\n",
      "Iteration 1733, the loss is 63.4904740151241, parameters k is 15.418432661141146 and b is -74.84950109200429\n",
      "Iteration 1734, the loss is 63.48951743170108, parameters k is 15.418280771075876 and b is -74.8485349013746\n",
      "Iteration 1735, the loss is 63.48856089428377, parameters k is 15.418128884663142 and b is -74.84756873397913\n",
      "Iteration 1736, the loss is 63.48760440287014, parameters k is 15.417977001902853 and b is -74.84660258981731\n",
      "Iteration 1737, the loss is 63.48664795745777, parameters k is 15.417825122794925 and b is -74.84563646888857\n",
      "Iteration 1738, the loss is 63.48569155804471, parameters k is 15.417673247339268 and b is -74.84467037119236\n",
      "Iteration 1739, the loss is 63.48473520462851, parameters k is 15.417521375535793 and b is -74.84370429672812\n",
      "Iteration 1740, the loss is 63.48377889720705, parameters k is 15.417369507384414 and b is -74.84273824549528\n",
      "Iteration 1741, the loss is 63.4828226357781, parameters k is 15.417217642885044 and b is -74.8417722174933\n",
      "Iteration 1742, the loss is 63.48186642033959, parameters k is 15.417065782037593 and b is -74.84080621272162\n",
      "Iteration 1743, the loss is 63.480910250889075, parameters k is 15.416913924841975 and b is -74.83984023117966\n",
      "Iteration 1744, the loss is 63.47995412742439, parameters k is 15.4167620712981 and b is -74.83887427286689\n",
      "Iteration 1745, the loss is 63.47899804994351, parameters k is 15.416610221405882 and b is -74.83790833778274\n",
      "Iteration 1746, the loss is 63.478042018444015, parameters k is 15.416458375165233 and b is -74.83694242592664\n",
      "Iteration 1747, the loss is 63.47708603292385, parameters k is 15.416306532576064 and b is -74.83597653729804\n",
      "Iteration 1748, the loss is 63.476130093380675, parameters k is 15.416154693638289 and b is -74.83501067189638\n",
      "Iteration 1749, the loss is 63.475174199812365, parameters k is 15.416002858351819 and b is -74.83404482972112\n",
      "Iteration 1750, the loss is 63.47421835221671, parameters k is 15.415851026716567 and b is -74.83307901077168\n",
      "Iteration 1751, the loss is 63.47326255059145, parameters k is 15.415699198732444 and b is -74.83211321504751\n",
      "Iteration 1752, the loss is 63.472306794934354, parameters k is 15.415547374399363 and b is -74.83114744254804\n",
      "Iteration 1753, the loss is 63.471351085243334, parameters k is 15.415395553717238 and b is -74.83018169327273\n",
      "Iteration 1754, the loss is 63.47039542151595, parameters k is 15.415243736685978 and b is -74.829215967221\n",
      "Iteration 1755, the loss is 63.46943980375027, parameters k is 15.415091923305496 and b is -74.82825026439231\n",
      "Iteration 1756, the loss is 63.46848423194391, parameters k is 15.414940113575705 and b is -74.8272845847861\n",
      "Iteration 1757, the loss is 63.467528706094676, parameters k is 15.414788307496517 and b is -74.8263189284018\n",
      "Iteration 1758, the loss is 63.46657322620047, parameters k is 15.414636505067845 and b is -74.82535329523886\n",
      "Iteration 1759, the loss is 63.46561779225891, parameters k is 15.414484706289599 and b is -74.82438768529671\n",
      "Iteration 1760, the loss is 63.4646624042679, parameters k is 15.414332911161694 and b is -74.82342209857481\n",
      "Iteration 1761, the loss is 63.46370706222515, parameters k is 15.41418111968404 and b is -74.82245653507259\n",
      "Iteration 1762, the loss is 63.46275176612855, parameters k is 15.41402933185655 and b is -74.8214909947895\n",
      "Iteration 1763, the loss is 63.46179651597588, parameters k is 15.413877547679137 and b is -74.82052547772497\n",
      "Iteration 1764, the loss is 63.46084131176488, parameters k is 15.413725767151712 and b is -74.81955998387845\n",
      "Iteration 1765, the loss is 63.4598861534933, parameters k is 15.413573990274188 and b is -74.81859451324938\n",
      "Iteration 1766, the loss is 63.458931041158934, parameters k is 15.413422217046476 and b is -74.8176290658372\n",
      "Iteration 1767, the loss is 63.457975974759705, parameters k is 15.41327044746849 and b is -74.81666364164134\n",
      "Iteration 1768, the loss is 63.4570209542933, parameters k is 15.41311868154014 and b is -74.81569824066126\n",
      "Iteration 1769, the loss is 63.456065979757525, parameters k is 15.412966919261342 and b is -74.8147328628964\n",
      "Iteration 1770, the loss is 63.45511105115022, parameters k is 15.412815160632004 and b is -74.8137675083462\n",
      "Iteration 1771, the loss is 63.45415616846907, parameters k is 15.41266340565204 and b is -74.8128021770101\n",
      "Iteration 1772, the loss is 63.453201331711924, parameters k is 15.412511654321364 and b is -74.81183686888754\n",
      "Iteration 1773, the loss is 63.452246540876594, parameters k is 15.412359906639885 and b is -74.81087158397796\n",
      "Iteration 1774, the loss is 63.4512917959609, parameters k is 15.412208162607518 and b is -74.8099063222808\n",
      "Iteration 1775, the loss is 63.45033709696247, parameters k is 15.412056422224174 and b is -74.8089410837955\n",
      "Iteration 1776, the loss is 63.44938244387937, parameters k is 15.411904685489764 and b is -74.80797586852152\n",
      "Iteration 1777, the loss is 63.44842783670912, parameters k is 15.411752952404203 and b is -74.80701067645829\n",
      "Iteration 1778, the loss is 63.447473275449646, parameters k is 15.411601222967402 and b is -74.80604550760525\n",
      "Iteration 1779, the loss is 63.44651876009877, parameters k is 15.411449497179271 and b is -74.80508036196184\n",
      "Iteration 1780, the loss is 63.44556429065422, parameters k is 15.411297775039726 and b is -74.80411523952752\n",
      "Iteration 1781, the loss is 63.44460986711376, parameters k is 15.411146056548677 and b is -74.80315014030171\n",
      "Iteration 1782, the loss is 63.44365548947528, parameters k is 15.410994341706038 and b is -74.80218506428386\n",
      "Iteration 1783, the loss is 63.442701157736515, parameters k is 15.41084263051172 and b is -74.8012200114734\n",
      "Iteration 1784, the loss is 63.44174687189516, parameters k is 15.410690922965635 and b is -74.8002549818698\n",
      "Iteration 1785, the loss is 63.44079263194925, parameters k is 15.410539219067696 and b is -74.79928997547248\n",
      "Iteration 1786, the loss is 63.439838437896405, parameters k is 15.410387518817814 and b is -74.79832499228088\n",
      "Iteration 1787, the loss is 63.43888428973436, parameters k is 15.410235822215903 and b is -74.79736003229446\n",
      "Iteration 1788, the loss is 63.43793018746111, parameters k is 15.410084129261874 and b is -74.79639509551265\n",
      "Iteration 1789, the loss is 63.43697613107423, parameters k is 15.40993243995564 and b is -74.79543018193489\n",
      "Iteration 1790, the loss is 63.4360221205717, parameters k is 15.409780754297113 and b is -74.79446529156063\n",
      "Iteration 1791, the loss is 63.43506815595115, parameters k is 15.409629072286206 and b is -74.7935004243893\n",
      "Iteration 1792, the loss is 63.434114237210544, parameters k is 15.40947739392283 and b is -74.79253558042035\n",
      "Iteration 1793, the loss is 63.433160364347536, parameters k is 15.409325719206898 and b is -74.79157075965323\n",
      "Iteration 1794, the loss is 63.43220653735998, parameters k is 15.409174048138322 and b is -74.79060596208735\n",
      "Iteration 1795, the loss is 63.43125275624567, parameters k is 15.409022380717015 and b is -74.7896411877222\n",
      "Iteration 1796, the loss is 63.430299021002405, parameters k is 15.40887071694289 and b is -74.78867643655718\n",
      "Iteration 1797, the loss is 63.42934533162794, parameters k is 15.408719056815857 and b is -74.78771170859176\n",
      "Iteration 1798, the loss is 63.428391688120044, parameters k is 15.408567400335828 and b is -74.78674700382537\n",
      "Iteration 1799, the loss is 63.42743809047658, parameters k is 15.408415747502717 and b is -74.78578232225745\n",
      "Iteration 1800, the loss is 63.42648453869541, parameters k is 15.408264098316437 and b is -74.78481766388745\n",
      "Iteration 1801, the loss is 63.425531032774146, parameters k is 15.4081124527769 and b is -74.78385302871482\n",
      "Iteration 1802, the loss is 63.424577572710675, parameters k is 15.407960810884017 and b is -74.78288841673897\n",
      "Iteration 1803, the loss is 63.42362415850285, parameters k is 15.4078091726377 and b is -74.78192382795937\n",
      "Iteration 1804, the loss is 63.422670790148395, parameters k is 15.407657538037864 and b is -74.78095926237546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1805, the loss is 63.4217174676451, parameters k is 15.407505907084419 and b is -74.77999471998668\n",
      "Iteration 1806, the loss is 63.42076419099078, parameters k is 15.407354279777277 and b is -74.77903020079246\n",
      "Iteration 1807, the loss is 63.41981096018323, parameters k is 15.40720265611635 and b is -74.77806570479225\n",
      "Iteration 1808, the loss is 63.41885777522023, parameters k is 15.407051036101553 and b is -74.7771012319855\n",
      "Iteration 1809, the loss is 63.417904636099564, parameters k is 15.406899419732797 and b is -74.77613678237164\n",
      "Iteration 1810, the loss is 63.416951542819106, parameters k is 15.406747807009994 and b is -74.77517235595012\n",
      "Iteration 1811, the loss is 63.415998495376584, parameters k is 15.406596197933057 and b is -74.77420795272037\n",
      "Iteration 1812, the loss is 63.4150454937698, parameters k is 15.406444592501897 and b is -74.77324357268186\n",
      "Iteration 1813, the loss is 63.41409253799661, parameters k is 15.406292990716427 and b is -74.77227921583402\n",
      "Iteration 1814, the loss is 63.413139628054665, parameters k is 15.40614139257656 and b is -74.77131488217627\n",
      "Iteration 1815, the loss is 63.41218676394192, parameters k is 15.405989798082206 and b is -74.77035057170808\n",
      "Iteration 1816, the loss is 63.41123394565604, parameters k is 15.40583820723328 and b is -74.76938628442888\n",
      "Iteration 1817, the loss is 63.41028117319492, parameters k is 15.405686620029694 and b is -74.76842202033811\n",
      "Iteration 1818, the loss is 63.409328446556266, parameters k is 15.40553503647136 and b is -74.76745777943522\n",
      "Iteration 1819, the loss is 63.40837576573796, parameters k is 15.405383456558189 and b is -74.76649356171964\n",
      "Iteration 1820, the loss is 63.40742313073783, parameters k is 15.405231880290096 and b is -74.76552936719084\n",
      "Iteration 1821, the loss is 63.4064705415535, parameters k is 15.40508030766699 and b is -74.76456519584823\n",
      "Iteration 1822, the loss is 63.405517998183, parameters k is 15.404928738688787 and b is -74.76360104769128\n",
      "Iteration 1823, the loss is 63.40456550062391, parameters k is 15.404777173355397 and b is -74.76263692271941\n",
      "Iteration 1824, the loss is 63.40361304887418, parameters k is 15.404625611666733 and b is -74.76167282093208\n",
      "Iteration 1825, the loss is 63.40266064293151, parameters k is 15.404474053622707 and b is -74.76070874232872\n",
      "Iteration 1826, the loss is 63.40170828279366, parameters k is 15.404322499223232 and b is -74.75974468690877\n",
      "Iteration 1827, the loss is 63.400755968458654, parameters k is 15.40417094846822 and b is -74.75878065467168\n",
      "Iteration 1828, the loss is 63.399803699923986, parameters k is 15.404019401357584 and b is -74.7578166456169\n",
      "Iteration 1829, the loss is 63.398851477187655, parameters k is 15.403867857891235 and b is -74.75685265974386\n",
      "Iteration 1830, the loss is 63.397899300247424, parameters k is 15.403716318069087 and b is -74.755888697052\n",
      "Iteration 1831, the loss is 63.396947169101075, parameters k is 15.40356478189105 and b is -74.75492475754078\n",
      "Iteration 1832, the loss is 63.395995083746406, parameters k is 15.403413249357039 and b is -74.75396084120962\n",
      "Iteration 1833, the loss is 63.39504304418112, parameters k is 15.403261720466963 and b is -74.75299694805797\n",
      "Iteration 1834, the loss is 63.394091050403226, parameters k is 15.403110195220737 and b is -74.75203307808529\n",
      "Iteration 1835, the loss is 63.39313910241033, parameters k is 15.402958673618274 and b is -74.751069231291\n",
      "Iteration 1836, the loss is 63.392187200200325, parameters k is 15.402807155659485 and b is -74.75010540767455\n",
      "Iteration 1837, the loss is 63.391235343771015, parameters k is 15.402655641344282 and b is -74.74914160723539\n",
      "Iteration 1838, the loss is 63.39028353312006, parameters k is 15.402504130672579 and b is -74.74817782997296\n",
      "Iteration 1839, the loss is 63.38933176824549, parameters k is 15.402352623644287 and b is -74.7472140758867\n",
      "Iteration 1840, the loss is 63.38838004914491, parameters k is 15.402201120259319 and b is -74.74625034497605\n",
      "Iteration 1841, the loss is 63.38742837581623, parameters k is 15.402049620517587 and b is -74.74528663724045\n",
      "Iteration 1842, the loss is 63.38647674825721, parameters k is 15.401898124419004 and b is -74.74432295267935\n",
      "Iteration 1843, the loss is 63.385525166465555, parameters k is 15.401746631963482 and b is -74.7433592912922\n",
      "Iteration 1844, the loss is 63.38457363043929, parameters k is 15.401595143150933 and b is -74.74239565307842\n",
      "Iteration 1845, the loss is 63.38362214017595, parameters k is 15.40144365798127 and b is -74.74143203803747\n",
      "Iteration 1846, the loss is 63.38267069567359, parameters k is 15.401292176454405 and b is -74.74046844616879\n",
      "Iteration 1847, the loss is 63.38171929692978, parameters k is 15.40114069857025 and b is -74.73950487747183\n",
      "Iteration 1848, the loss is 63.38076794394251, parameters k is 15.400989224328718 and b is -74.73854133194602\n",
      "Iteration 1849, the loss is 63.37981663670934, parameters k is 15.400837753729721 and b is -74.73757780959082\n",
      "Iteration 1850, the loss is 63.378865375228415, parameters k is 15.400686286773173 and b is -74.73661431040564\n",
      "Iteration 1851, the loss is 63.37791415949722, parameters k is 15.400534823458985 and b is -74.73565083438996\n",
      "Iteration 1852, the loss is 63.3769629895137, parameters k is 15.40038336378707 and b is -74.7346873815432\n",
      "Iteration 1853, the loss is 63.3760118652756, parameters k is 15.40023190775734 and b is -74.7337239518648\n",
      "Iteration 1854, the loss is 63.37506078678082, parameters k is 15.400080455369705 and b is -74.73276054535422\n",
      "Iteration 1855, the loss is 63.37410975402708, parameters k is 15.399929006624083 and b is -74.73179716201089\n",
      "Iteration 1856, the loss is 63.37315876701216, parameters k is 15.39977756152038 and b is -74.73083380183427\n",
      "Iteration 1857, the loss is 63.372207825733895, parameters k is 15.399626120058514 and b is -74.72987046482378\n",
      "Iteration 1858, the loss is 63.37125693019006, parameters k is 15.399474682238395 and b is -74.72890715097887\n",
      "Iteration 1859, the loss is 63.3703060803785, parameters k is 15.399323248059936 and b is -74.72794386029899\n",
      "Iteration 1860, the loss is 63.369355276296986, parameters k is 15.399171817523047 and b is -74.72698059278358\n",
      "Iteration 1861, the loss is 63.36840451794337, parameters k is 15.399020390627644 and b is -74.72601734843208\n",
      "Iteration 1862, the loss is 63.367453805315364, parameters k is 15.398868967373637 and b is -74.72505412724394\n",
      "Iteration 1863, the loss is 63.366503138410785, parameters k is 15.39871754776094 and b is -74.72409092921859\n",
      "Iteration 1864, the loss is 63.365552517227464, parameters k is 15.398566131789465 and b is -74.72312775435549\n",
      "Iteration 1865, the loss is 63.36460194176321, parameters k is 15.398414719459124 and b is -74.72216460265406\n",
      "Iteration 1866, the loss is 63.36365141201588, parameters k is 15.39826331076983 and b is -74.72120147411377\n",
      "Iteration 1867, the loss is 63.36270092798311, parameters k is 15.398111905721494 and b is -74.72023836873404\n",
      "Iteration 1868, the loss is 63.361750489662896, parameters k is 15.39796050431403 and b is -74.71927528651433\n",
      "Iteration 1869, the loss is 63.36080009705285, parameters k is 15.39780910654735 and b is -74.71831222745408\n",
      "Iteration 1870, the loss is 63.35984975015091, parameters k is 15.397657712421365 and b is -74.71734919155271\n",
      "Iteration 1871, the loss is 63.358899448954816, parameters k is 15.39750632193599 and b is -74.7163861788097\n",
      "Iteration 1872, the loss is 63.35794919346243, parameters k is 15.397354935091137 and b is -74.71542318922447\n",
      "Iteration 1873, the loss is 63.356998983671495, parameters k is 15.397203551886717 and b is -74.71446022279646\n",
      "Iteration 1874, the loss is 63.35604881957974, parameters k is 15.397052172322642 and b is -74.71349727952513\n",
      "Iteration 1875, the loss is 63.35509870118518, parameters k is 15.396900796398826 and b is -74.71253435940991\n",
      "Iteration 1876, the loss is 63.354148628485454, parameters k is 15.396749424115182 and b is -74.71157146245025\n",
      "Iteration 1877, the loss is 63.353198601478404, parameters k is 15.396598055471621 and b is -74.7106085886456\n",
      "Iteration 1878, the loss is 63.35224862016181, parameters k is 15.396446690468055 and b is -74.70964573799539\n",
      "Iteration 1879, the loss is 63.35129868453352, parameters k is 15.3962953291044 and b is -74.70868291049906\n",
      "Iteration 1880, the loss is 63.35034879459132, parameters k is 15.396143971380564 and b is -74.70772010615607\n",
      "Iteration 1881, the loss is 63.34939895033299, parameters k is 15.395992617296463 and b is -74.70675732496585\n",
      "Iteration 1882, the loss is 63.34844915175643, parameters k is 15.395841266852006 and b is -74.70579456692785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1883, the loss is 63.347499398859206, parameters k is 15.395689920047108 and b is -74.7048318320415\n",
      "Iteration 1884, the loss is 63.34654969163941, parameters k is 15.39553857688168 and b is -74.70386912030627\n",
      "Iteration 1885, the loss is 63.3456000300947, parameters k is 15.395387237355637 and b is -74.70290643172157\n",
      "Iteration 1886, the loss is 63.344650414222826, parameters k is 15.395235901468888 and b is -74.70194376628687\n",
      "Iteration 1887, the loss is 63.343700844021676, parameters k is 15.39508456922135 and b is -74.7009811240016\n",
      "Iteration 1888, the loss is 63.34275131948907, parameters k is 15.39493324061293 and b is -74.70001850486521\n",
      "Iteration 1889, the loss is 63.341801840622765, parameters k is 15.394781915643545 and b is -74.69905590887714\n",
      "Iteration 1890, the loss is 63.34085240742057, parameters k is 15.394630594313107 and b is -74.69809333603683\n",
      "Iteration 1891, the loss is 63.33990301988037, parameters k is 15.394479276621526 and b is -74.69713078634373\n",
      "Iteration 1892, the loss is 63.33895367799978, parameters k is 15.394327962568715 and b is -74.69616825979729\n",
      "Iteration 1893, the loss is 63.33800438177683, parameters k is 15.394176652154588 and b is -74.69520575639693\n",
      "Iteration 1894, the loss is 63.33705513120917, parameters k is 15.394025345379056 and b is -74.69424327614212\n",
      "Iteration 1895, the loss is 63.336105926294564, parameters k is 15.393874042242032 and b is -74.69328081903228\n",
      "Iteration 1896, the loss is 63.33515676703097, parameters k is 15.39372274274343 and b is -74.69231838506687\n",
      "Iteration 1897, the loss is 63.33420765341612, parameters k is 15.393571446883161 and b is -74.69135597424533\n",
      "Iteration 1898, the loss is 63.33325858544782, parameters k is 15.393420154661138 and b is -74.6903935865671\n",
      "Iteration 1899, the loss is 63.33230956312388, parameters k is 15.393268866077273 and b is -74.68943122203162\n",
      "Iteration 1900, the loss is 63.33136058644213, parameters k is 15.393117581131479 and b is -74.68846888063833\n",
      "Iteration 1901, the loss is 63.330411655400276, parameters k is 15.39296629982367 and b is -74.68750656238669\n",
      "Iteration 1902, the loss is 63.32946276999623, parameters k is 15.392815022153755 and b is -74.68654426727613\n",
      "Iteration 1903, the loss is 63.32851393022776, parameters k is 15.392663748121649 and b is -74.68558199530611\n",
      "Iteration 1904, the loss is 63.327565136092645, parameters k is 15.392512477727264 and b is -74.68461974647605\n",
      "Iteration 1905, the loss is 63.32661638758876, parameters k is 15.392361210970511 and b is -74.6836575207854\n",
      "Iteration 1906, the loss is 63.325667684713835, parameters k is 15.392209947851306 and b is -74.68269531823363\n",
      "Iteration 1907, the loss is 63.32471902746572, parameters k is 15.39205868836956 and b is -74.68173313882015\n",
      "Iteration 1908, the loss is 63.323770415842226, parameters k is 15.391907432525183 and b is -74.68077098254442\n",
      "Iteration 1909, the loss is 63.32282184984111, parameters k is 15.39175618031809 and b is -74.67980884940587\n",
      "Iteration 1910, the loss is 63.32187332946018, parameters k is 15.391604931748192 and b is -74.67884673940397\n",
      "Iteration 1911, the loss is 63.32092485469736, parameters k is 15.391453686815405 and b is -74.67788465253813\n",
      "Iteration 1912, the loss is 63.31997642555025, parameters k is 15.391302445519637 and b is -74.67692258880781\n",
      "Iteration 1913, the loss is 63.31902804201684, parameters k is 15.391151207860803 and b is -74.67596054821246\n",
      "Iteration 1914, the loss is 63.31807970409495, parameters k is 15.390999973838815 and b is -74.67499853075152\n",
      "Iteration 1915, the loss is 63.31713141178218, parameters k is 15.390848743453587 and b is -74.67403653642444\n",
      "Iteration 1916, the loss is 63.316183165076474, parameters k is 15.39069751670503 and b is -74.67307456523065\n",
      "Iteration 1917, the loss is 63.315234963975655, parameters k is 15.390546293593056 and b is -74.67211261716959\n",
      "Iteration 1918, the loss is 63.31428680847745, parameters k is 15.39039507411758 and b is -74.67115069224072\n",
      "Iteration 1919, the loss is 63.313338698579855, parameters k is 15.390243858278511 and b is -74.67018879044348\n",
      "Iteration 1920, the loss is 63.31239063428041, parameters k is 15.390092646075765 and b is -74.6692269117773\n",
      "Iteration 1921, the loss is 63.31144261557712, parameters k is 15.389941437509252 and b is -74.66826505624164\n",
      "Iteration 1922, the loss is 63.31049464246765, parameters k is 15.389790232578886 and b is -74.66730322383593\n",
      "Iteration 1923, the loss is 63.30954671494997, parameters k is 15.38963903128458 and b is -74.66634141455962\n",
      "Iteration 1924, the loss is 63.30859883302177, parameters k is 15.389487833626244 and b is -74.66537962841217\n",
      "Iteration 1925, the loss is 63.307650996680806, parameters k is 15.389336639603794 and b is -74.664417865393\n",
      "Iteration 1926, the loss is 63.30670320592501, parameters k is 15.38918544921714 and b is -74.66345612550157\n",
      "Iteration 1927, the loss is 63.30575546075224, parameters k is 15.389034262466195 and b is -74.66249440873732\n",
      "Iteration 1928, the loss is 63.30480776116004, parameters k is 15.388883079350872 and b is -74.66153271509968\n",
      "Iteration 1929, the loss is 63.30386010714651, parameters k is 15.388731899871084 and b is -74.66057104458811\n",
      "Iteration 1930, the loss is 63.30291249870927, parameters k is 15.388580724026744 and b is -74.65960939720205\n",
      "Iteration 1931, the loss is 63.301964935846215, parameters k is 15.388429551817763 and b is -74.65864777294094\n",
      "Iteration 1932, the loss is 63.30101741855517, parameters k is 15.388278383244055 and b is -74.65768617180423\n",
      "Iteration 1933, the loss is 63.300069946833815, parameters k is 15.38812721830553 and b is -74.65672459379135\n",
      "Iteration 1934, the loss is 63.29912252068008, parameters k is 15.387976057002104 and b is -74.65576303890177\n",
      "Iteration 1935, the loss is 63.29817514009176, parameters k is 15.387824899333689 and b is -74.6548015071349\n",
      "Iteration 1936, the loss is 63.297227805066626, parameters k is 15.387673745300196 and b is -74.65383999849021\n",
      "Iteration 1937, the loss is 63.29628051560252, parameters k is 15.387522594901538 and b is -74.65287851296713\n",
      "Iteration 1938, the loss is 63.2953332716972, parameters k is 15.387371448137628 and b is -74.65191705056512\n",
      "Iteration 1939, the loss is 63.2943860733485, parameters k is 15.387220305008379 and b is -74.6509556112836\n",
      "Iteration 1940, the loss is 63.29343892055436, parameters k is 15.387069165513703 and b is -74.64999419512205\n",
      "Iteration 1941, the loss is 63.29249181331236, parameters k is 15.386918029653511 and b is -74.64903280207987\n",
      "Iteration 1942, the loss is 63.291544751620414, parameters k is 15.386766897427718 and b is -74.64807143215654\n",
      "Iteration 1943, the loss is 63.29059773547633, parameters k is 15.386615768836236 and b is -74.64711008535149\n",
      "Iteration 1944, the loss is 63.28965076487795, parameters k is 15.386464643878979 and b is -74.64614876166415\n",
      "Iteration 1945, the loss is 63.28870383982307, parameters k is 15.386313522555856 and b is -74.64518746109398\n",
      "Iteration 1946, the loss is 63.287756960309416, parameters k is 15.386162404866782 and b is -74.64422618364043\n",
      "Iteration 1947, the loss is 63.28681012633493, parameters k is 15.38601129081167 and b is -74.64326492930293\n",
      "Iteration 1948, the loss is 63.28586333789734, parameters k is 15.38586018039043 and b is -74.64230369808094\n",
      "Iteration 1949, the loss is 63.28491659499452, parameters k is 15.385709073602978 and b is -74.6413424899739\n",
      "Iteration 1950, the loss is 63.28396989762416, parameters k is 15.385557970449225 and b is -74.64038130498123\n",
      "Iteration 1951, the loss is 63.28302324578426, parameters k is 15.385406870929083 and b is -74.63942014310241\n",
      "Iteration 1952, the loss is 63.28207663947237, parameters k is 15.385255775042467 and b is -74.63845900433687\n",
      "Iteration 1953, the loss is 63.28113007868649, parameters k is 15.385104682789287 and b is -74.63749788868404\n",
      "Iteration 1954, the loss is 63.280183563424416, parameters k is 15.384953594169456 and b is -74.63653679614337\n",
      "Iteration 1955, the loss is 63.279237093683896, parameters k is 15.384802509182888 and b is -74.63557572671432\n",
      "Iteration 1956, the loss is 63.27829066946283, parameters k is 15.384651427829494 and b is -74.63461468039633\n",
      "Iteration 1957, the loss is 63.27734429075897, parameters k is 15.384500350109189 and b is -74.63365365718883\n",
      "Iteration 1958, the loss is 63.27639795757007, parameters k is 15.384349276021883 and b is -74.63269265709127\n",
      "Iteration 1959, the loss is 63.27545166989399, parameters k is 15.38419820556749 and b is -74.6317316801031\n",
      "Iteration 1960, the loss is 63.274505427728606, parameters k is 15.384047138745922 and b is -74.63077072622376\n",
      "Iteration 1961, the loss is 63.27355923107164, parameters k is 15.383896075557093 and b is -74.6298097954527\n",
      "Iteration 1962, the loss is 63.27261307992095, parameters k is 15.383745016000914 and b is -74.62884888778936\n",
      "Iteration 1963, the loss is 63.27166697427431, parameters k is 15.383593960077299 and b is -74.62788800323318\n",
      "Iteration 1964, the loss is 63.270720914129605, parameters k is 15.38344290778616 and b is -74.62692714178361\n",
      "Iteration 1965, the loss is 63.26977489948453, parameters k is 15.383291859127409 and b is -74.6259663034401\n",
      "Iteration 1966, the loss is 63.26882893033703, parameters k is 15.38314081410096 and b is -74.62500548820208\n",
      "Iteration 1967, the loss is 63.26788300668484, parameters k is 15.382989772706724 and b is -74.62404469606899\n",
      "Iteration 1968, the loss is 63.26693712852575, parameters k is 15.382838734944615 and b is -74.6230839270403\n",
      "Iteration 1969, the loss is 63.265991295857695, parameters k is 15.382687700814545 and b is -74.62212318111544\n",
      "Iteration 1970, the loss is 63.265045508678334, parameters k is 15.382536670316426 and b is -74.62116245829385\n",
      "Iteration 1971, the loss is 63.26409976698549, parameters k is 15.382385643450172 and b is -74.62020175857498\n",
      "Iteration 1972, the loss is 63.26315407077706, parameters k is 15.382234620215696 and b is -74.61924108195828\n",
      "Iteration 1973, the loss is 63.26220842005087, parameters k is 15.38208360061291 and b is -74.61828042844319\n",
      "Iteration 1974, the loss is 63.26126281480464, parameters k is 15.381932584641726 and b is -74.61731979802914\n",
      "Iteration 1975, the loss is 63.26031725503626, parameters k is 15.381781572302058 and b is -74.6163591907156\n",
      "Iteration 1976, the loss is 63.25937174074351, parameters k is 15.381630563593818 and b is -74.615398606502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1977, the loss is 63.258426271924264, parameters k is 15.381479558516919 and b is -74.61443804538777\n",
      "Iteration 1978, the loss is 63.25748084857612, parameters k is 15.381328557071273 and b is -74.61347750737238\n",
      "Iteration 1979, the loss is 63.2565354706972, parameters k is 15.381177559256793 and b is -74.61251699245527\n",
      "Iteration 1980, the loss is 63.25559013828507, parameters k is 15.381026565073391 and b is -74.61155650063587\n",
      "Iteration 1981, the loss is 63.25464485133765, parameters k is 15.38087557452098 and b is -74.61059603191364\n",
      "Iteration 1982, the loss is 63.253699609852795, parameters k is 15.380724587599474 and b is -74.60963558628802\n",
      "Iteration 1983, the loss is 63.2527544138282, parameters k is 15.380573604308784 and b is -74.60867516375845\n",
      "Iteration 1984, the loss is 63.2518092632618, parameters k is 15.380422624648824 and b is -74.60771476432438\n",
      "Iteration 1985, the loss is 63.25086415815139, parameters k is 15.380271648619505 and b is -74.60675438798526\n",
      "Iteration 1986, the loss is 63.24991909849462, parameters k is 15.380120676220741 and b is -74.60579403474053\n",
      "Iteration 1987, the loss is 63.24897408428955, parameters k is 15.379969707452446 and b is -74.60483370458962\n",
      "Iteration 1988, the loss is 63.248029115533726, parameters k is 15.37981874231453 and b is -74.60387339753198\n",
      "Iteration 1989, the loss is 63.24708419222523, parameters k is 15.379667780806907 and b is -74.60291311356707\n",
      "Iteration 1990, the loss is 63.246139314361734, parameters k is 15.379516822929489 and b is -74.60195285269432\n",
      "Iteration 1991, the loss is 63.24519448194105, parameters k is 15.37936586868219 and b is -74.6009926149132\n",
      "Iteration 1992, the loss is 63.244249694961155, parameters k is 15.379214918064921 and b is -74.60003240022311\n",
      "Iteration 1993, the loss is 63.24330495341953, parameters k is 15.379063971077596 and b is -74.59907220862354\n",
      "Iteration 1994, the loss is 63.24236025731432, parameters k is 15.378913027720127 and b is -74.5981120401139\n",
      "Iteration 1995, the loss is 63.24141560664319, parameters k is 15.378762087992428 and b is -74.59715189469365\n",
      "Iteration 1996, the loss is 63.24047100140388, parameters k is 15.37861115189441 and b is -74.59619177236225\n",
      "Iteration 1997, the loss is 63.23952644159439, parameters k is 15.378460219425987 and b is -74.59523167311912\n",
      "Iteration 1998, the loss is 63.238581927212344, parameters k is 15.37830929058707 and b is -74.59427159696371\n",
      "Iteration 1999, the loss is 63.23763745825569, parameters k is 15.378158365377574 and b is -74.59331154389547\n"
     ]
    }
   ],
   "source": [
    "#initialized parameters\n",
    "\n",
    "k = random.random() * 200 - 100  # -100 100\n",
    "b = random.random() * 200 - 100  # -100 100\n",
    "# learning_rate looks like the length of step\n",
    "learning_rate = 1e-3\n",
    "\n",
    "iteration_num = 2000 \n",
    "losses = []\n",
    "for i in range(iteration_num):\n",
    "    \n",
    "    price_use_current_parameters = [price(r, k, b) for r in X_rm]  # \\hat{y}\n",
    "    \n",
    "    current_loss = loss(y, price_use_current_parameters)\n",
    "    losses.append(current_loss)\n",
    "    print(\"Iteration {}, the loss is {}, parameters k is {} and b is {}\".format(i,current_loss,k,b))\n",
    "    \n",
    "    k_gradient = partial_derivative_k(X_rm, y, price_use_current_parameters)\n",
    "    b_gradient = partial_derivative_b(y, price_use_current_parameters)\n",
    "    \n",
    "    k = k + (-1 * k_gradient) * learning_rate\n",
    "    b = b + (-1 * b_gradient) * learning_rate\n",
    "best_k = k\n",
    "best_b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bd7ea23c18>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(iteration_num)),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, the loss is 1855.4480437909158, parameters k is -10.877029520322552 and b is 50.701653970230666\n",
      "Iteration 1, the loss is 1585.0849189020198, parameters k is -10.352192078038744 and b is 50.782032582449744\n",
      "Iteration 2, the loss is 1357.220194545316, parameters k is -9.870340725817853 and b is 50.85565361456929\n",
      "Iteration 3, the loss is 1165.1734346745627, parameters k is -9.427952556401822 and b is 50.92307088546908\n",
      "Iteration 4, the loss is 1003.3143186698057, parameters k is -9.021793380994692 and b is 50.98479282602293\n",
      "Iteration 5, the loss is 866.89757091369, parameters k is -8.648894067455966 and b is 51.04128619885467\n",
      "Iteration 6, the loss is 751.9238382246435, parameters k is -8.306528817687902 and b is 51.09297951324297\n",
      "Iteration 7, the loss is 655.0224363346282, parameters k is -7.992195225290897 and b is 51.14026616015905\n",
      "Iteration 8, the loss is 573.3525277584267, parameters k is -7.703595967585786 and b is 51.18350729037354\n",
      "Iteration 9, the loss is 504.5198337752754, parameters k is -7.438621998059156 and b is 51.22303445668933\n"
     ]
    }
   ],
   "source": [
    "#initialized parameters\n",
    "\n",
    "k = random.random() * 200 - 100  # -100 100\n",
    "b = random.random() * 200 - 100  # -100 100\n",
    "# learning_rate looks like the length of step\n",
    "learning_rate = 1e-3\n",
    "\n",
    "iteration_num = 10 \n",
    "losses = []\n",
    "for i in range(iteration_num):\n",
    "    \n",
    "    price_use_current_parameters = [price(r, k, b) for r in X_rm]  # \\hat{y}\n",
    "    \n",
    "    current_loss = loss(y, price_use_current_parameters)\n",
    "    losses.append(current_loss)\n",
    "    print(\"Iteration {}, the loss is {}, parameters k is {} and b is {}\".format(i,current_loss,k,b))\n",
    "    \n",
    "    k_gradient = partial_derivative_k(X_rm, y, price_use_current_parameters)\n",
    "    b_gradient = partial_derivative_b(y, price_use_current_parameters)\n",
    "    \n",
    "    k = k + (-1 * k_gradient) * learning_rate\n",
    "    b = b + (-1 * b_gradient) * learning_rate\n",
    "best_k = k\n",
    "best_b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bd7e8ed240>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(iteration_num)),losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 和迭代次数和学习率有关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bd7e9b2f98>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "price_use_best_parameters = [price(r, best_k, best_b) for r in X_rm]\n",
    "\n",
    "plt.scatter(X_rm,y)\n",
    "plt.scatter(X_rm,price_use_current_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
